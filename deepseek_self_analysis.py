"""
üîç DeepSeek AI Robot - –ì–ª—É–±–æ–∫–∏–π –°–∞–º–æ–∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ DeepSeek API
==============================================================

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –≤—ã–ø–æ–ª–Ω—è–µ—Ç:
1. –ê–Ω–∞–ª–∏–∑ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ —á–µ—Ä–µ–∑ DeepSeek API
2. –í—ã—è–≤–ª–µ–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–æ–≤ –∏ –ø—Ä–æ–±–ª–µ–º
3. –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é —Å Perplexity –¥–ª—è best practices
4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—é —É–ª—É—á—à–µ–Ω–∏–π
5. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π
"""

import asyncio
import json
from pathlib import Path
from typing import Dict, Any, List
from automation.deepseek_robot.ai_integrations import DeepSeekClient, PerplexityClient


async def analyze_robot_code_with_deepseek() -> Dict[str, Any]:
    """
    –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —Ä–æ–±–æ—Ç–∞ —á–µ—Ä–µ–∑ DeepSeek API
    """
    print("\n" + "="*80)
    print("üîç –®–ê–ì 1: –ì–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ DeepSeek Robot —á–µ—Ä–µ–∑ DeepSeek API")
    print("="*80)
    
    client = DeepSeekClient()
    robot_file = Path("d:/bybit_strategy_tester_v2/automation/deepseek_robot/robot.py")
    
    if not robot_file.exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {robot_file}")
        return {"success": False, "error": "File not found"}
    
    # –ß–∏—Ç–∞–µ–º –∫–æ–¥
    code = robot_file.read_text(encoding='utf-8')
    print(f"\nüìÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–π —Ñ–∞–π–ª: {robot_file}")
    print(f"üìä –†–∞–∑–º–µ—Ä –∫–æ–¥–∞: {len(code)} —Å–∏–º–≤–æ–ª–æ–≤ ({len(code.splitlines())} —Å—Ç—Ä–æ–∫)")
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –∫–æ–¥ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (DeepSeek –∏–º–µ–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è)
    # –ë–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏: –∫–ª–∞—Å—Å—ã –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    lines = code.splitlines()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    code_summary = []
    in_class = False
    indent_level = 0
    
    for line in lines:
        stripped = line.strip()
        
        # –ö–ª–∞—Å—Å—ã –∏ –∏—Ö –º–µ—Ç–æ–¥—ã
        if stripped.startswith('class ') or stripped.startswith('async def ') or stripped.startswith('def '):
            code_summary.append(line)
            in_class = True
        # Docstrings
        elif in_class and ('"""' in stripped or "'''" in stripped):
            code_summary.append(line)
        # –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç–æ–¥–æ–≤
        elif in_class and stripped and not stripped.startswith('#'):
            if len(code_summary) < 500:  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
                code_summary.append(line)
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –∫–æ–¥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    code_for_analysis = '\n'.join(code_summary[:400])  # –ü–µ—Ä–≤—ã–µ 400 —Å—Ç—Ä–æ–∫
    
    print(f"üìä –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–æ–±—Ä–∞–Ω–æ: {len(code_for_analysis)} —Å–∏–º–≤–æ–ª–æ–≤ ({len(code_summary[:400])} —Å—Ç—Ä–æ–∫)")
    
    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ DeepSeek
    analysis_instruction = """
–ü—Ä–æ–≤–µ–¥–∏ –ß–ï–°–¢–ù–´–ô –∏ –ö–†–ò–¢–ò–ß–ù–´–ô –∞–Ω–∞–ª–∏–∑ —ç—Ç–æ–≥–æ –∫–æ–¥–∞ DeepSeek AI Robot.

–û—Ü–µ–Ω–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:

1. –ê–†–•–ò–¢–ï–ö–¢–£–†–ê (0-10):
   - –ß–∏—Å—Ç–æ—Ç–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
   - Separation of concerns
   - SOLID –ø—Ä–∏–Ω—Ü–∏–ø—ã
   - –°–ª–∞–±—ã–µ –º–µ—Å—Ç–∞ –≤ –¥–∏–∑–∞–π–Ω–µ

2. –ö–û–î-–ö–ê–ß–ï–°–¢–í–û (0-10):
   - –ß–∏—Ç–∞–µ–º–æ—Å—Ç—å
   - –°–ª–æ–∂–Ω–æ—Å—Ç—å (cyclomatic complexity)
   - –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞
   - Naming conventions
   - Type hints coverage

3. –ê–í–¢–û–ù–û–ú–ù–û–°–¢–¨ (0-10):
   - –ù–∞—Å–∫–æ–ª—å–∫–æ —Ä–æ–±–æ—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∞–≤—Ç–æ–Ω–æ–º–µ–Ω?
   - –ï—Å—Ç—å –ª–∏ manual interventions?
   - Self-healing capabilities
   - Error recovery

4. –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ (0-10):
   - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
   - Async/await usage
   - Memory efficiency
   - Scalability

5. –ù–ê–î–Å–ñ–ù–û–°–¢–¨ (0-10):
   - Error handling
   - Edge cases coverage
   - Logging and monitoring
   - Rollback mechanisms

6. –§–£–ù–ö–¶–ò–û–ù–ê–õ–¨–ù–û–°–¢–¨ (0-10):
   - –ü–æ–ª–Ω–æ—Ç–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏
   - Missing features
   - Bugs and limitations
   - API design

–í—ã–¥–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON:
{
  "overall_score": 0-10,
  "scores": {
    "architecture": {"score": 0-10, "issues": [...]},
    "code_quality": {"score": 0-10, "issues": [...]},
    "autonomy": {"score": 0-10, "issues": [...]},
    "performance": {"score": 0-10, "issues": [...]},
    "reliability": {"score": 0-10, "issues": [...]},
    "functionality": {"score": 0-10, "issues": [...]}
  },
  "critical_issues": [...],
  "high_priority_issues": [...],
  "medium_priority_issues": [...],
  "recommendations": [...]
}

–ë–£–î–¨ –ß–ï–°–¢–ù–´–ú! –ù–µ –∑–∞–Ω–∏–∂–∞–π –∏ –Ω–µ –∑–∞–≤—ã—à–∞–π –æ—Ü–µ–Ω–∫–∏. –ù–∞–π–¥–∏ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã!
"""
    
    print("\nü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ DeepSeek API...")
    print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 30-60 —Å–µ–∫—É–Ω–¥)...")
    
    result = await client.analyze_code(
        code=code_for_analysis,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –∫–æ–¥
        instruction=analysis_instruction,
        context={
            "file": str(robot_file),
            "purpose": "Self-analysis and improvement",
            "language": "Python 3.13",
            "framework": "asyncio",
            "note": "Analyzing key components and architecture"
        }
    )
    
    if result.success:
        print(f"\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
        print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used}")
        print(f"üìù –†–∞–∑–º–µ—Ä –æ—Ç–≤–µ—Ç–∞: {len(result.content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        output_file = Path("d:/bybit_strategy_tester_v2/deepseek_self_analysis_result.json")
        output_file.write_text(json.dumps({
            "timestamp": "2025-11-08",
            "tokens_used": result.tokens_used,
            "analysis": result.content
        }, indent=2, ensure_ascii=False), encoding='utf-8')
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            content = result.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            analysis_data = json.loads(content.strip())
            
            print("\n" + "="*80)
            print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê DeepSeek")
            print("="*80)
            
            # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞
            overall = analysis_data.get("overall_score", 0)
            print(f"\nüéØ –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê: {overall}/10")
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
            scores = analysis_data.get("scores", {})
            print("\nüìà –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏:")
            for category, data in scores.items():
                score = data.get("score", 0)
                emoji = "üü¢" if score >= 8 else "üü°" if score >= 6 else "üî¥"
                print(f"  {emoji} {category.title()}: {score}/10")
                if data.get("issues"):
                    for issue in data["issues"][:3]:  # –ü–µ—Ä–≤—ã–µ 3
                        print(f"    ‚Ä¢ {issue}")
            
            # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
            critical = analysis_data.get("critical_issues", [])
            if critical:
                print(f"\nüö® –ö–†–ò–¢–ò–ß–ù–´–ï –ü–†–û–ë–õ–ï–ú–´ ({len(critical)}):")
                for i, issue in enumerate(critical, 1):
                    print(f"  {i}. {issue}")
            
            # High priority
            high = analysis_data.get("high_priority_issues", [])
            if high:
                print(f"\n‚ö†Ô∏è  HIGH PRIORITY ({len(high)}):")
                for i, issue in enumerate(high[:5], 1):  # –ü–µ—Ä–≤—ã–µ 5
                    print(f"  {i}. {issue}")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = analysis_data.get("recommendations", [])
            if recommendations:
                print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò ({len(recommendations)}):")
                for i, rec in enumerate(recommendations[:5], 1):
                    print(f"  {i}. {rec}")
            
            return {
                "success": True,
                "analysis": analysis_data,
                "raw_content": result.content
            }
            
        except json.JSONDecodeError as e:
            print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {e}")
            print("\nüìÑ –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(result.content[:1000])
            return {
                "success": True,
                "analysis": None,
                "raw_content": result.content
            }
    else:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {result.error}")
        return {"success": False, "error": result.error}


async def consult_perplexity_for_improvements() -> Dict[str, Any]:
    """
    –®–∞–≥ 2: –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å Perplexity –¥–ª—è best practices
    """
    print("\n" + "="*80)
    print("üîç –®–ê–ì 2: –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å Perplexity AI –¥–ª—è —É–ª—É—á—à–µ–Ω–∏–π")
    print("="*80)
    
    client = PerplexityClient()
    
    # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ DeepSeek
    analysis_file = Path("d:/bybit_strategy_tester_v2/deepseek_self_analysis_result.json")
    if analysis_file.exists():
        analysis_data = json.loads(analysis_file.read_text(encoding='utf-8'))
        analysis_content = analysis_data.get("analysis", "")
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ DeepSeek")
    else:
        analysis_content = "No previous analysis available"
        print(f"‚ö†Ô∏è  –ê–Ω–∞–ª–∏–∑ DeepSeek –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    # –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 1: Autonomous AI Agents
    print("\nüîç –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 1: Advanced Autonomous AI Agent Patterns...")
    query1 = """
Latest 2025 best practices for building truly autonomous AI code analysis agents:

1. Self-improvement algorithms
2. Multi-AI collaboration patterns (DeepSeek + Perplexity + Copilot)
3. Cyclic analysis until 100% quality
4. Advanced error recovery and self-healing
5. Production-grade architecture patterns
6. Performance optimization for AI agents

Focus on: Python asyncio, production deployment, real-world challenges.
"""
    
    result1 = await client.search(query1, focus="detailed_technical")
    
    if result1.success:
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ! Tokens: {result1.tokens_used}")
        consultation1 = result1.content
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result1.error}")
        consultation1 = ""
    
    # –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 2: Code Quality
    print("\nüîç –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 2: Production-Grade Python Code Quality...")
    query2 = """
Python 3.13+ production code quality best practices for autonomous systems:

1. Architecture patterns (Clean Architecture, Hexagonal, DDD)
2. Async/await optimization patterns
3. Error handling and resilience patterns
4. Type safety and static analysis
5. Performance profiling and optimization
6. Testing strategies for AI systems

Real-world production examples from 2025.
"""
    
    result2 = await client.search(query2, focus="code_examples")
    
    if result2.success:
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ! Tokens: {result2.tokens_used}")
        consultation2 = result2.content
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result2.error}")
        consultation2 = ""
    
    # –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 3: Specific Improvements
    print("\nüîç –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è 3: How to improve autonomous code robot...")
    query3 = f"""
Based on this code analysis, how to improve autonomous AI code analysis robot?

Analysis summary:
{str(analysis_content)[:1000]}

Specific questions:
1. How to achieve TRUE autonomy (no manual interventions)?
2. How to implement effective self-healing?
3. How to optimize async/await for AI API calls?
4. How to improve error recovery and rollback?
5. Architecture improvements for scalability?

Provide concrete Python 3.13 code examples and patterns.
"""
    
    result3 = await client.search(query3, focus="specific_solutions")
    
    if result3.success:
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ! Tokens: {result3.tokens_used}")
        consultation3 = result3.content
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞: {result3.error}")
        consultation3 = ""
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    perplexity_results = {
        "timestamp": "2025-11-08",
        "consultations": {
            "autonomous_patterns": consultation1,
            "code_quality": consultation2,
            "specific_improvements": consultation3
        },
        "total_tokens": (
            result1.tokens_used if result1.success else 0 +
            result2.tokens_used if result2.success else 0 +
            result3.tokens_used if result3.success else 0
        )
    }
    
    output_file = Path("d:/bybit_strategy_tester_v2/perplexity_consultation_result.json")
    output_file.write_text(
        json.dumps(perplexity_results, indent=2, ensure_ascii=False),
        encoding='utf-8'
    )
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    
    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
    print("\n" + "="*80)
    print("üìä –ö–†–ê–¢–ö–ê–Ø –°–í–û–î–ö–ê –ö–û–ù–°–£–õ–¨–¢–ê–¶–ò–ò PERPLEXITY")
    print("="*80)
    
    for title, content in [
        ("Autonomous Patterns", consultation1),
        ("Code Quality", consultation2),
        ("Specific Improvements", consultation3)
    ]:
        print(f"\nüìö {title}:")
        preview = content[:300].replace('\n', ' ') if content else "–ù–µ –ø–æ–ª—É—á–µ–Ω–æ"
        print(f"  {preview}...")
    
    return {
        "success": True,
        "consultations": perplexity_results
    }


async def generate_improvements_with_deepseek() -> Dict[str, Any]:
    """
    –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ DeepSeek –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏
    """
    print("\n" + "="*80)
    print("üîß –®–ê–ì 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ DeepSeek API")
    print("="*80)
    
    client = DeepSeekClient()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é
    analysis_file = Path("d:/bybit_strategy_tester_v2/deepseek_self_analysis_result.json")
    perplexity_file = Path("d:/bybit_strategy_tester_v2/perplexity_consultation_result.json")
    
    analysis_data = json.loads(analysis_file.read_text(encoding='utf-8')) if analysis_file.exists() else {}
    perplexity_data = json.loads(perplexity_file.read_text(encoding='utf-8')) if perplexity_file.exists() else {}
    
    # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–¥
    robot_file = Path("d:/bybit_strategy_tester_v2/automation/deepseek_robot/robot.py")
    current_code = robot_file.read_text(encoding='utf-8')
    
    print(f"üìÑ –¢–µ–∫—É—â–∏–π –∫–æ–¥: {len(current_code)} —Å–∏–º–≤–æ–ª–æ–≤")
    print(f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω: {'‚úÖ' if analysis_data else '‚ùå'}")
    print(f"üìä –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {'‚úÖ' if perplexity_data else '‚ùå'}")
    
    # –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π
    improvement_instruction = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å Perplexity, —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ö–û–ù–ö–†–ï–¢–ù–´–ï —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞.

–ê–ù–ê–õ–ò–ó DeepSeek:
{json.dumps(analysis_data.get('analysis', {}), indent=2, ensure_ascii=False)[:2000]}

–ö–û–ù–°–£–õ–¨–¢–ê–¶–ò–Ø Perplexity:
{str(perplexity_data.get('consultations', {}))[:2000]}

–ó–ê–î–ê–ß–ò:
1. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –≤—Å–µ critical issues
2. –£–ª—É—á—à–∏—Ç—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å –¥–æ 10/10
3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
4. –£–ª—É—á—à–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É (SOLID, Clean Architecture)
5. –î–æ–±–∞–≤–∏—Ç—å advanced error recovery
6. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å true self-healing

–í—ã–¥–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

{{
  "improvements": [
    {{
      "priority": "critical|high|medium",
      "category": "architecture|autonomy|performance|reliability",
      "title": "Short title",
      "description": "Detailed description",
      "implementation": {{
        "file": "path/to/file.py",
        "method": "method_name or 'new_class'",
        "code": "Full implementation code",
        "explanation": "Why this improves the code"
      }}
    }}
  ],
  "expected_improvements": {{
    "architecture": "+X points",
    "autonomy": "+X points",
    "performance": "+X points",
    "overall": "+X points"
  }}
}}

–ì–µ–Ω–µ—Ä–∏—Ä—É–π –†–ï–ê–õ–¨–ù–´–ô, –†–ê–ë–û–¢–ê–Æ–©–ò–ô –ö–û–î! –ù–µ placeholders!
"""
    
    print("\nü§ñ –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —É–ª—É—á—à–µ–Ω–∏–π...")
    print("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 60-90 —Å–µ–∫—É–Ω–¥)...")
    
    result = await client.analyze_code(
        code=current_code[:10000],  # –ü–µ—Ä–≤—ã–µ 10k —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        instruction=improvement_instruction,
        context={
            "analysis": str(analysis_data)[:1000],
            "consultation": str(perplexity_data)[:1000]
        }
    )
    
    if result.success:
        print(f"\n‚úÖ –£–ª—É—á—à–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã!")
        print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {result.tokens_used}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        output_file = Path("d:/bybit_strategy_tester_v2/deepseek_improvements.json")
        output_file.write_text(json.dumps({
            "timestamp": "2025-11-08",
            "tokens_used": result.tokens_used,
            "improvements": result.content
        }, indent=2, ensure_ascii=False), encoding='utf-8')
        print(f"üíæ –£–ª—É—á—à–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
        
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
        try:
            content = result.content
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            improvements_data = json.loads(content.strip())
            
            print("\n" + "="*80)
            print("üîß –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø")
            print("="*80)
            
            improvements_list = improvements_data.get("improvements", [])
            print(f"\nüìä –í—Å–µ–≥–æ —É–ª—É—á—à–µ–Ω–∏–π: {len(improvements_list)}")
            
            # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
            by_priority = {"critical": [], "high": [], "medium": []}
            for imp in improvements_list:
                priority = imp.get("priority", "medium")
                by_priority.get(priority, []).append(imp)
            
            for priority in ["critical", "high", "medium"]:
                items = by_priority[priority]
                if items:
                    emoji = "üö®" if priority == "critical" else "‚ö†Ô∏è" if priority == "high" else "‚ÑπÔ∏è"
                    print(f"\n{emoji} {priority.upper()} ({len(items)}):")
                    for i, imp in enumerate(items, 1):
                        print(f"  {i}. [{imp.get('category', 'other')}] {imp.get('title', 'Untitled')}")
            
            # –û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è
            expected = improvements_data.get("expected_improvements", {})
            if expected:
                print(f"\nüìà –û–ñ–ò–î–ê–ï–ú–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
                for category, improvement in expected.items():
                    print(f"  ‚Ä¢ {category.title()}: {improvement}")
            
            return {
                "success": True,
                "improvements": improvements_data,
                "raw_content": result.content
            }
            
        except json.JSONDecodeError as e:
            print(f"\n‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON: {e}")
            print("\nüìÑ –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤):")
            print(result.content[:500])
            return {
                "success": True,
                "improvements": None,
                "raw_content": result.content
            }
    else:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {result.error}")
        return {"success": False, "error": result.error}


async def create_comprehensive_report() -> None:
    """
    –®–∞–≥ 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞
    """
    print("\n" + "="*80)
    print("üìä –®–ê–ì 4: –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
    analysis_file = Path("d:/bybit_strategy_tester_v2/deepseek_self_analysis_result.json")
    perplexity_file = Path("d:/bybit_strategy_tester_v2/perplexity_consultation_result.json")
    improvements_file = Path("d:/bybit_strategy_tester_v2/deepseek_improvements.json")
    
    analysis_data = json.loads(analysis_file.read_text(encoding='utf-8')) if analysis_file.exists() else {}
    perplexity_data = json.loads(perplexity_file.read_text(encoding='utf-8')) if perplexity_file.exists() else {}
    improvements_data = json.loads(improvements_file.read_text(encoding='utf-8')) if improvements_file.exists() else {}
    
    # –°–æ–∑–¥–∞—ë–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
    report = f"""# üîç DeepSeek AI Robot - –ì–ª—É–±–æ–∫–∏–π –°–∞–º–æ–∞–Ω–∞–ª–∏–∑ –∏ –£–ª—É—á—à–µ–Ω–∏—è

**–î–∞—Ç–∞**: 8 –Ω–æ—è–±—Ä—è 2025  
**–¶–µ–ª—å**: –ß–µ—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –¥–æ–≤–µ–¥–µ–Ω–∏–µ –¥–æ —Å–æ–≤–µ—Ä—à–µ–Ω—Å—Ç–≤–∞

---

## üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê DeepSeek

{json.dumps(analysis_data.get('analysis', {}), indent=2, ensure_ascii=False)}

---

## üí° –ö–û–ù–°–£–õ–¨–¢–ê–¶–ò–Ø Perplexity

### Autonomous Patterns
{perplexity_data.get('consultations', {}).get('autonomous_patterns', 'N/A')[:1000]}...

### Code Quality
{perplexity_data.get('consultations', {}).get('code_quality', 'N/A')[:1000]}...

### Specific Improvements
{perplexity_data.get('consultations', {}).get('specific_improvements', 'N/A')[:1000]}...

---

## üîß –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø

{json.dumps(improvements_data.get('improvements', {}), indent=2, ensure_ascii=False)}

---

## üìà –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò

1. –ü—Ä–∏–º–µ–Ω–∏—Ç—å critical —É–ª—É—á—à–µ–Ω–∏—è
2. –ü—Ä–∏–º–µ–Ω–∏—Ç—å high priority —É–ª—É—á—à–µ–Ω–∏—è
3. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
4. –ü–æ–≤—Ç–æ—Ä–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

---

**–°—Ç–∞—Ç—É—Å**: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω, —É–ª—É—á—à–µ–Ω–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã, –≥–æ—Ç–æ–≤—ã –∫ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—é
"""
    
    report_file = Path("d:/bybit_strategy_tester_v2/DEEPSEEK_SELF_IMPROVEMENT_REPORT.md")
    report_file.write_text(report, encoding='utf-8')
    
    print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ–∑–¥–∞–Ω: {report_file}")
    print(f"üìä –†–∞–∑–º–µ—Ä –æ—Ç—á—ë—Ç–∞: {len(report)} —Å–∏–º–≤–æ–ª–æ–≤")


async def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Å–∞–º–æ–∞–Ω–∞–ª–∏–∑–∞ –∏ —É–ª—É—á—à–µ–Ω–∏–π
    """
    print("\n" + "="*80)
    print("üöÄ DeepSeek AI Robot - –ì–ª—É–±–æ–∫–∏–π –°–∞–º–æ–∞–Ω–∞–ª–∏–∑ –∏ –£–ª—É—á—à–µ–Ω–∏–µ")
    print("="*80)
    print("\n–≠—Ç–æ—Ç –ø—Ä–æ—Ü–µ—Å—Å –≤–∫–ª—é—á–∞–µ—Ç:")
    print("  1Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞ —á–µ—Ä–µ–∑ DeepSeek API")
    print("  2Ô∏è‚É£ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å Perplexity AI")
    print("  3Ô∏è‚É£ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π —á–µ—Ä–µ–∑ DeepSeek")
    print("  4Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞")
    print("\n‚è≥ –≠—Ç–æ –∑–∞–π–º—ë—Ç 3-5 –º–∏–Ω—É—Ç...")
    
    try:
        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑
        analysis_result = await analyze_robot_code_with_deepseek()
        if not analysis_result["success"]:
            print("\n‚ùå –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
            return
        
        # –®–∞–≥ 2: –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è
        consultation_result = await consult_perplexity_for_improvements()
        if not consultation_result["success"]:
            print("\n‚ö†Ô∏è  –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —á–∞—Å—Ç–∏—á–Ω–æ –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
        
        # –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π
        improvements_result = await generate_improvements_with_deepseek()
        if not improvements_result["success"]:
            print("\n‚ùå –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–∏–π –ø—Ä–æ–≤–∞–ª–∏–ª–∞—Å—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞")
            return
        
        # –®–∞–≥ 4: –û—Ç—á—ë—Ç
        await create_comprehensive_report()
        
        print("\n" + "="*80)
        print("‚úÖ –°–ê–ú–û–ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
        print("="*80)
        print("\nüìÑ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        print("  ‚Ä¢ deepseek_self_analysis_result.json")
        print("  ‚Ä¢ perplexity_consultation_result.json")
        print("  ‚Ä¢ deepseek_improvements.json")
        print("  ‚Ä¢ DEEPSEEK_SELF_IMPROVEMENT_REPORT.md")
        
        print("\nüîß –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: –ü—Ä–∏–º–µ–Ω–∏—Ç—å —É–ª—É—á—à–µ–Ω–∏—è")
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
