"""
–ó–∞–≥—Ä—É–∑–∫–∞ 6 –º–µ—Å—è—Ü–µ–≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤: 5, 15, 30 –º–∏–Ω—É—Ç
–° –¥–æ–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã—Ö (–Ω–µ –æ—á–∏—â–∞–µ—Ç –±–∞–∑—É)
"""

import logging
import sys
import time
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Dict, Optional

import pandas as pd
from pybit.unified_trading import HTTP
from sqlalchemy import select
from sqlalchemy.orm import Session

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from backend.database import SessionLocal, Base
from backend.models.bybit_kline_audit import BybitKlineAudit

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('logs/load_ml_data.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class MLDataLoader:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –¥–æ–≥—Ä—É–∑–∫–æ–π
    
    Features:
    - –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã (5, 15, 30 –º–∏–Ω—É—Ç)
    - –î–æ–≥—Ä—É–∑–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    - –ù–µ –æ—á–∏—â–∞–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    - –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    """
    
    def __init__(
        self,
        symbol: str = 'BTCUSDT',
        months: int = 6,
        batch_size: int = 1000
    ):
        """
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (BTCUSDT)
            months: –ü–µ—Ä–∏–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ (6 –º–µ—Å—è—Ü–µ–≤)
            batch_size: –ë–∞—Ä–æ–≤ –∑–∞ –∑–∞–ø—Ä–æ—Å (–º–∞–∫—Å 1000)
        """
        self.symbol = symbol
        self.months = months
        self.batch_size = min(batch_size, 1000)
        
        # Bybit client
        self.session = HTTP(testnet=False)
        
        # –í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
        self.end_time = datetime.now(timezone.utc)
        self.start_time = self.end_time - timedelta(days=months * 30)
        
        logger.info(f"üìä ML Data Loader initialized")
        logger.info(f"   Symbol: {symbol}")
        logger.info(f"   Period: {self.start_time.date()} ‚Üí {self.end_time.date()}")
        logger.info(f"   Duration: {months} months (~{months * 30} days)")
    
    def get_existing_data_range(
        self, 
        interval: str,
        db: Session
    ) -> Optional[tuple]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            (min_timestamp, max_timestamp) –∏–ª–∏ None
        """
        try:
            stmt = select(
                BybitKlineAudit.open_time_dt
            ).where(
                BybitKlineAudit.symbol == self.symbol,
                BybitKlineAudit.interval == interval
            ).order_by(
                BybitKlineAudit.open_time_dt
            )
            
            result = db.execute(stmt).all()
            
            if not result:
                return None
            
            timestamps = [row[0] for row in result if row[0]]
            if not timestamps:
                return None
            
            min_ts = min(timestamps)
            max_ts = max(timestamps)
            
            return (min_ts, max_ts)
            
        except Exception as e:
            logger.error(f"Error getting existing range: {e}")
            return None
    
    def load_interval_data(
        self,
        interval: str,
        rate_limit_delay: float = 0.2
    ) -> Dict:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ —Å –¥–æ–≥—Ä—É–∑–∫–æ–π
        
        Args:
            interval: '5', '15', '30' (–º–∏–Ω—É—Ç—ã)
            rate_limit_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫)
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"üìà Loading {interval}-minute data for {self.symbol}")
        logger.info(f"{'='*80}")
        
        db = SessionLocal()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            existing_range = self.get_existing_data_range(interval, db)
            
            if existing_range:
                min_ts, max_ts = existing_range
                
                # Ensure timezone awareness for comparison
                if min_ts.tzinfo is None:
                    min_ts = min_ts.replace(tzinfo=timezone.utc)
                if max_ts.tzinfo is None:
                    max_ts = max_ts.replace(tzinfo=timezone.utc)
                
                logger.info(f"‚úì Existing data found:")
                logger.info(f"  Range: {min_ts} ‚Üí {max_ts}")
                logger.info(f"  Duration: {(max_ts - min_ts).days} days")
                
                # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á—Ç–æ –Ω—É–∂–Ω–æ –¥–æ–≥—Ä—É–∑–∏—Ç—å
                gaps_to_load = []
                
                # –î–æ–≥—Ä—É–∑–∏—Ç—å –≤ –Ω–∞—á–∞–ª–æ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                if min_ts > self.start_time:
                    gaps_to_load.append(('backward', self.start_time, min_ts))
                    logger.info(f"  Need to load backward: {self.start_time.date()} ‚Üí {min_ts.date()}")
                
                # –î–æ–≥—Ä—É–∑–∏—Ç—å –≤ –∫–æ–Ω–µ—Ü (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
                if max_ts < self.end_time:
                    gaps_to_load.append(('forward', max_ts, self.end_time))
                    logger.info(f"  Need to load forward: {max_ts.date()} ‚Üí {self.end_time.date()}")
                
                if not gaps_to_load:
                    logger.info(f"‚úÖ Data is up to date! No loading needed.")
                    
                    # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                    count_stmt = select(BybitKlineAudit).where(
                        BybitKlineAudit.symbol == self.symbol,
                        BybitKlineAudit.interval == interval
                    )
                    total_count = len(db.execute(count_stmt).all())
                    
                    return {
                        'interval': interval,
                        'loaded': 0,
                        'existing': total_count,
                        'total': total_count,
                        'skipped': 0
                    }
            else:
                logger.info(f"‚ÑπÔ∏è  No existing data found, loading full range")
                gaps_to_load = [('full', self.start_time, self.end_time)]
            
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            total_loaded = 0
            total_skipped = 0
            
            for gap_type, start, end in gaps_to_load:
                logger.info(f"\nüîÑ Loading {gap_type} gap: {start.date()} ‚Üí {end.date()}")
                
                current_time = end
                batch_count = 0
                
                while current_time > start:
                    batch_count += 1
                    
                    # –ó–∞–ø—Ä–æ—Å–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
                    try:
                        response = self.session.get_kline(
                            category='spot',
                            symbol=self.symbol,
                            interval=interval,
                            end=int(current_time.timestamp() * 1000),
                            limit=self.batch_size
                        )
                        
                        if response['retCode'] != 0:
                            logger.error(f"API error: {response['retMsg']}")
                            break
                        
                        klines = response['result']['list']
                        
                        if not klines:
                            logger.info(f"No more data available before {current_time.date()}")
                            break
                        
                        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
                        records_added = 0
                        records_skipped = 0
                        
                        for kline in klines:
                            open_time_ms = int(kline[0])
                            open_time_dt = datetime.fromtimestamp(
                                open_time_ms / 1000, 
                                tz=timezone.utc
                            )
                            
                            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
                            exists = db.query(BybitKlineAudit).filter_by(
                                symbol=self.symbol,
                                interval=interval,
                                open_time=open_time_ms
                            ).first()
                            
                            if exists:
                                records_skipped += 1
                                continue
                            
                            # –°–æ–∑–¥–∞—Ç—å –∑–∞–ø–∏—Å—å
                            record = BybitKlineAudit(
                                symbol=self.symbol,
                                interval=interval,
                                open_time=open_time_ms,
                                open_time_dt=open_time_dt,
                                open_price=float(kline[1]),
                                high_price=float(kline[2]),
                                low_price=float(kline[3]),
                                close_price=float(kline[4]),
                                volume=float(kline[5]),
                                turnover=float(kline[6])
                            )
                            record.set_raw(kline)
                            
                            db.add(record)
                            records_added += 1
                        
                        db.commit()
                        
                        total_loaded += records_added
                        total_skipped += records_skipped
                        
                        # –û–±–Ω–æ–≤–∏—Ç—å –≤—Ä–µ–º—è
                        oldest_kline_ms = int(klines[-1][0])
                        current_time = datetime.fromtimestamp(
                            oldest_kline_ms / 1000,
                            tz=timezone.utc
                        )
                        
                        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
                        if batch_count % 10 == 0:
                            progress = (end - current_time) / (end - start) * 100
                            logger.info(
                                f"  Batch {batch_count}: {progress:.1f}% | "
                                f"Added: {records_added} | Skipped: {records_skipped} | "
                                f"Current: {current_time.date()}"
                            )
                        
                        # Rate limiting
                        time.sleep(rate_limit_delay)
                        
                    except Exception as e:
                        logger.error(f"Error loading batch {batch_count}: {e}")
                        db.rollback()
                        break
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            count_stmt = select(BybitKlineAudit).where(
                BybitKlineAudit.symbol == self.symbol,
                BybitKlineAudit.interval == interval
            )
            final_count = len(db.execute(count_stmt).all())
            
            logger.info(f"\n‚úÖ Loading complete for {interval}-minute data!")
            logger.info(f"   Loaded: {total_loaded:,} new records")
            logger.info(f"   Skipped: {total_skipped:,} duplicates")
            logger.info(f"   Total in DB: {final_count:,} records")
            
            return {
                'interval': interval,
                'loaded': total_loaded,
                'existing': final_count - total_loaded,
                'total': final_count,
                'skipped': total_skipped
            }
            
        finally:
            db.close()
    
    def load_all_timeframes(
        self,
        intervals: List[str] = ['5', '15', '30'],
        rate_limit_delay: float = 0.2
    ) -> Dict:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã
        
        Args:
            intervals: –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ ['5', '15', '30']
            rate_limit_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        Returns:
            –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        """
        start_time = time.time()
        
        logger.info(f"\n{'='*80}")
        logger.info(f"üöÄ Starting ML data loading for {self.symbol}")
        logger.info(f"{'='*80}")
        logger.info(f"Timeframes: {', '.join(intervals)} minutes")
        logger.info(f"Period: {self.months} months")
        logger.info(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        results = {}
        
        for interval in intervals:
            try:
                stats = self.load_interval_data(interval, rate_limit_delay)
                results[f'{interval}min'] = stats
            except Exception as e:
                logger.error(f"‚ùå Failed to load {interval}-minute data: {e}")
                results[f'{interval}min'] = {'error': str(e)}
        
        elapsed = time.time() - start_time
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info(f"\n{'='*80}")
        logger.info(f"üìä FINAL STATISTICS")
        logger.info(f"{'='*80}")
        
        total_loaded = 0
        total_existing = 0
        total_records = 0
        
        for tf, stats in results.items():
            if 'error' not in stats:
                total_loaded += stats['loaded']
                total_existing += stats['existing']
                total_records += stats['total']
                
                logger.info(f"\n{tf}:")
                logger.info(f"  New records:      {stats['loaded']:,}")
                logger.info(f"  Existing records: {stats['existing']:,}")
                logger.info(f"  Total records:    {stats['total']:,}")
        
        logger.info(f"\nOverall:")
        logger.info(f"  Total loaded:     {total_loaded:,} new records")
        logger.info(f"  Total existing:   {total_existing:,} records")
        logger.info(f"  Total in DB:      {total_records:,} records")
        logger.info(f"  Elapsed time:     {elapsed/60:.1f} minutes")
        logger.info(f"  Finished:         {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        logger.info(f"\n{'='*80}")
        logger.info(f"‚úÖ ML DATA LOADING COMPLETE!")
        logger.info(f"{'='*80}\n")
        
        return {
            'results': results,
            'total_loaded': total_loaded,
            'total_existing': total_existing,
            'total_records': total_records,
            'elapsed_minutes': elapsed / 60
        }


def main():
    """Main entry point"""
    # Create logs directory
    Path('logs').mkdir(exist_ok=True)
    
    logger.info(f"\n{'='*80}")
    logger.info(f"ML DATA LOADER - 6 MONTHS HISTORICAL DATA")
    logger.info(f"{'='*80}")
    logger.info(f"Purpose: Load data for ML-optimization")
    logger.info(f"Timeframes: 5, 15, 30 minutes")
    logger.info(f"Period: 6 months from {datetime.now().date()}")
    logger.info(f"Mode: INCREMENTAL (dogruzka - –Ω–µ –æ—á–∏—â–∞–µ—Ç –±–∞–∑—É)")
    logger.info(f"{'='*80}\n")
    
    # Configuration
    SYMBOL = 'BTCUSDT'
    MONTHS = 6
    INTERVALS = ['5', '15', '30']
    RATE_LIMIT = 0.2  # 5 req/sec
    
    # Create loader
    loader = MLDataLoader(
        symbol=SYMBOL,
        months=MONTHS
    )
    
    try:
        # Load all timeframes
        stats = loader.load_all_timeframes(
            intervals=INTERVALS,
            rate_limit_delay=RATE_LIMIT
        )
        
        # Success
        logger.info("\nüéâ SUCCESS! Data ready for ML-optimization")
        logger.info(f"Total records in database: {stats['total_records']:,}")
        logger.info(f"Time taken: {stats['elapsed_minutes']:.1f} minutes")
        
        return 0
        
    except KeyboardInterrupt:
        logger.warning("\n‚ö†Ô∏è  Loading interrupted by user")
        return 1
        
    except Exception as e:
        logger.error(f"\n‚ùå Loading failed: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    sys.exit(main())
