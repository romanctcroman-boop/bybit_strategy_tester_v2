"""
DeepSeek Test Runner and TZ Compliance Analysis
–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –∏ –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤—Å–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏—è–º
"""

import subprocess
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

PROJECT_ROOT = Path(__file__).parent
TESTS_DIR = PROJECT_ROOT / "tests"

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
RESULTS = {
    "timestamp": datetime.now().isoformat(),
    "test_results": {},
    "tz_compliance": {},
    "recommendations": []
}


def run_pytest_tests(test_path: str, test_name: str) -> Dict[str, Any]:
    """–ó–∞–ø—É—Å–∫ pytest —Ç–µ—Å—Ç–æ–≤"""
    print(f"\n{'='*80}")
    print(f"üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤: {test_name}")
    print(f"{'='*80}\n")
    
    try:
        result = subprocess.run(
            [
                sys.executable, "-m", "pytest",
                str(test_path),
                "-v",
                "--tb=short",
                "--maxfail=5",
                "-x"  # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –æ—à–∏–±–∫–µ
            ],
            cwd=PROJECT_ROOT,
            capture_output=True,
            text=True,
            timeout=300
        )
        
        return {
            "name": test_name,
            "returncode": result.returncode,
            "passed": result.returncode == 0,
            "stdout": result.stdout[-5000:] if result.stdout else "",
            "stderr": result.stderr[-2000:] if result.stderr else "",
            "summary": extract_test_summary(result.stdout)
        }
    except subprocess.TimeoutExpired:
        return {
            "name": test_name,
            "error": "Timeout after 300s",
            "passed": False
        }
    except Exception as e:
        return {
            "name": test_name,
            "error": str(e),
            "passed": False
        }


def extract_test_summary(stdout: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤–æ–¥–∫–∏ –∏–∑ –≤—ã–≤–æ–¥–∞ pytest"""
    summary = {
        "total": 0,
        "passed": 0,
        "failed": 0,
        "errors": 0,
        "skipped": 0
    }
    
    if not stdout:
        return summary
    
    # –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏ —Å –∏—Ç–æ–≥–∞–º–∏
    for line in stdout.split('\n'):
        if 'passed' in line or 'failed' in line:
            parts = line.split()
            for i, part in enumerate(parts):
                if 'passed' in part and i > 0:
                    try:
                        summary['passed'] = int(parts[i-1])
                    except:
                        pass
                if 'failed' in part and i > 0:
                    try:
                        summary['failed'] = int(parts[i-1])
                    except:
                        pass
    
    summary['total'] = summary['passed'] + summary['failed']
    return summary


def analyze_tz1_compliance() -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó —á–∞—Å—Ç—å 1: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"""
    print("\n" + "="*80)
    print("üìò –ê–Ω–∞–ª–∏–∑ –¢–ó –ß–∞—Å—Ç—å 1: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ü—Ä–æ—Ç–æ–∫–æ–ª—ã, –û—á–µ—Ä–µ–¥–∏")
    print("="*80 + "\n")
    
    compliance = {
        "score": 0,
        "max_score": 100,
        "sections": {}
    }
    
    # 1.1 JSON-RPC 2.0
    print("üîç 1.1 JSON-RPC 2.0 Protocol...")
    json_rpc = check_json_rpc_implementation()
    compliance["sections"]["json_rpc"] = json_rpc
    print(f"   –û—Ü–µ–Ω–∫–∞: {json_rpc['score']}/25")
    
    # 2.1 Redis Streams
    print("üîç 2.1 Redis Streams...")
    redis_streams = check_redis_streams()
    compliance["sections"]["redis_streams"] = redis_streams
    print(f"   –û—Ü–µ–Ω–∫–∞: {redis_streams['score']}/25")
    
    # 3.1-3.2 Workers & Autoscaling
    print("üîç 3.1-3.2 Workers & Autoscaling...")
    workers = check_workers_autoscaling()
    compliance["sections"]["workers"] = workers
    print(f"   –û—Ü–µ–Ω–∫–∞: {workers['score']}/25")
    
    # 4.1-4.3 Signal Routing & Saga
    print("üîç 4.1-4.3 Signal Routing & Saga...")
    routing = check_signal_routing()
    compliance["sections"]["routing"] = routing
    print(f"   –û—Ü–µ–Ω–∫–∞: {routing['score']}/25")
    
    # –ü–æ–¥—Å—á—ë—Ç –æ–±—â–µ–≥–æ –±–∞–ª–ª–∞
    compliance["score"] = sum(s["score"] for s in compliance["sections"].values())
    
    print(f"\n‚úÖ –ò–¢–û–ì–û –¢–ó-1: {compliance['score']}/{compliance['max_score']} –±–∞–ª–ª–æ–≤")
    return compliance


def check_json_rpc_implementation() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ JSON-RPC 2.0"""
    result = {"score": 0, "max": 25, "findings": []}
    
    # –ü–æ–∏—Å–∫ FastAPI endpoints
    backend_files = list((PROJECT_ROOT / "backend").rglob("*.py"))
    
    has_fastapi = False
    has_endpoints = {
        "/run_task": False,
        "/status": False,
        "/analytics": False,
        "/inject": False,
        "/control": False
    }
    
    for file in backend_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "FastAPI" in content or "@app" in content or "@router" in content:
                has_fastapi = True
                
            for endpoint in has_endpoints.keys():
                if endpoint in content:
                    has_endpoints[endpoint] = True
        except:
            pass
    
    if has_fastapi:
        result["score"] += 5
        result["findings"].append("‚úÖ FastAPI –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è")
    else:
        result["findings"].append("‚ùå FastAPI –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    for endpoint, found in has_endpoints.items():
        if found:
            result["score"] += 4
            result["findings"].append(f"‚úÖ Endpoint {endpoint} –Ω–∞–π–¥–µ–Ω")
        else:
            result["findings"].append(f"‚ùå Endpoint {endpoint} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    return result


def check_redis_streams() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Redis Streams"""
    result = {"score": 0, "max": 25, "findings": []}
    
    backend_files = list((PROJECT_ROOT / "backend").rglob("*.py"))
    
    redis_found = False
    xadd_found = False
    xreadgroup_found = False
    xpending_found = False
    
    for file in backend_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "redis" in content.lower():
                redis_found = True
            if "xadd" in content.lower():
                xadd_found = True
            if "xreadgroup" in content.lower():
                xreadgroup_found = True
            if "xpending" in content.lower():
                xpending_found = True
        except:
            pass
    
    if redis_found:
        result["score"] += 5
        result["findings"].append("‚úÖ Redis –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è")
    else:
        result["findings"].append("‚ùå Redis –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if xadd_found:
        result["score"] += 7
        result["findings"].append("‚úÖ XADD (–¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ stream)")
    else:
        result["findings"].append("‚ùå XADD –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    if xreadgroup_found:
        result["score"] += 7
        result["findings"].append("‚úÖ XREADGROUP (consumer groups)")
    else:
        result["findings"].append("‚ùå Consumer Groups –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã")
    
    if xpending_found:
        result["score"] += 6
        result["findings"].append("‚úÖ XPENDING (recovery)")
    else:
        result["findings"].append("‚ùå XPENDING recovery –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    return result


def check_workers_autoscaling() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Workers –∏ Autoscaling"""
    result = {"score": 0, "max": 25, "findings": []}
    
    backend_files = list((PROJECT_ROOT / "backend").rglob("*.py"))
    
    async_workers = False
    celery_found = False
    autoscaling = False
    sla_monitor = False
    
    for file in backend_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "async def" in content and "worker" in content.lower():
                async_workers = True
            if "celery" in content.lower():
                celery_found = True
            if "autoscal" in content.lower():
                autoscaling = True
            if "sla" in content.lower() and "monitor" in content.lower():
                sla_monitor = True
        except:
            pass
    
    if async_workers:
        result["score"] += 8
        result["findings"].append("‚úÖ Async workers –Ω–∞–π–¥–µ–Ω—ã")
    else:
        result["findings"].append("‚ùå Async workers –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    
    if celery_found:
        result["score"] += 5
        result["findings"].append("‚úÖ Celery –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
    
    if sla_monitor:
        result["score"] += 7
        result["findings"].append("‚úÖ SLA monitoring –µ—Å—Ç—å")
    else:
        result["findings"].append("‚ùå SLA monitoring –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    if autoscaling:
        result["score"] += 5
        result["findings"].append("‚úÖ Autoscaling –∫–æ–¥ –Ω–∞–π–¥–µ–Ω")
    else:
        result["findings"].append("‚ùå Autoscaling –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
    
    return result


def check_signal_routing() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Signal Routing –∏ Saga"""
    result = {"score": 0, "max": 25, "findings": []}
    
    mcp_files = list((PROJECT_ROOT / "mcp-server").rglob("*.py"))
    backend_files = list((PROJECT_ROOT / "backend").rglob("*.py"))
    all_files = mcp_files + backend_files
    
    routing_found = False
    saga_found = False
    fsm_found = False
    preemption_found = False
    checkpoint_found = False
    
    for file in all_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "route" in content.lower() and ("task" in content.lower() or "signal" in content.lower()):
                routing_found = True
            if "saga" in content.lower():
                saga_found = True
            if "fsm" in content.lower() or "state machine" in content.lower():
                fsm_found = True
            if "preempt" in content.lower():
                preemption_found = True
            if "checkpoint" in content.lower():
                checkpoint_found = True
        except:
            pass
    
    if routing_found:
        result["score"] += 6
        result["findings"].append("‚úÖ Signal routing –Ω–∞–π–¥–µ–Ω")
    else:
        result["findings"].append("‚ùå Signal routing –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    if saga_found:
        result["score"] += 5
        result["findings"].append("‚úÖ Saga pattern –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
    
    if fsm_found:
        result["score"] += 5
        result["findings"].append("‚úÖ FSM implementation –µ—Å—Ç—å")
    
    if preemption_found:
        result["score"] += 5
        result["findings"].append("‚úÖ Preemption –ª–æ–≥–∏–∫–∞ –Ω–∞–π–¥–µ–Ω–∞")
    
    if checkpoint_found:
        result["score"] += 4
        result["findings"].append("‚úÖ Checkpoint recovery –µ—Å—Ç—å")
    
    return result


def analyze_tz2_compliance() -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó —á–∞—Å—Ç—å 2: Security & Monitoring"""
    print("\n" + "="*80)
    print("üîí –ê–Ω–∞–ª–∏–∑ –¢–ó –ß–∞—Å—Ç—å 2: Sandbox, Security, SLA/–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
    print("="*80 + "\n")
    
    compliance = {
        "score": 0,
        "max_score": 100,
        "sections": {}
    }
    
    # 5.1 Sandbox Security
    print("üîç 5.1 Sandbox Security...")
    sandbox = check_sandbox_security()
    compliance["sections"]["sandbox"] = sandbox
    print(f"   –û—Ü–µ–Ω–∫–∞: {sandbox['score']}/30")
    
    # 6.1 Monitoring
    print("üîç 6.1 Prometheus + Grafana...")
    monitoring = check_monitoring()
    compliance["sections"]["monitoring"] = monitoring
    print(f"   –û—Ü–µ–Ω–∫–∞: {monitoring['score']}/30")
    
    # 8.1 Multi-tenancy
    print("üîç 8.1 Multi-tenancy...")
    tenancy = check_multitenancy()
    compliance["sections"]["multitenancy"] = tenancy
    print(f"   –û—Ü–µ–Ω–∫–∞: {tenancy['score']}/40")
    
    compliance["score"] = sum(s["score"] for s in compliance["sections"].values())
    
    print(f"\n‚úÖ –ò–¢–û–ì–û –¢–ó-2: {compliance['score']}/{compliance['max_score']} –±–∞–ª–ª–æ–≤")
    return compliance


def check_sandbox_security() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Sandbox Security"""
    result = {"score": 0, "max": 30, "findings": []}
    
    docker_files = [
        PROJECT_ROOT / "docker-compose.yml",
        PROJECT_ROOT / "Dockerfile",
        PROJECT_ROOT / "docker" / "Dockerfile"
    ]
    
    docker_found = any(f.exists() for f in docker_files)
    network_isolation = False
    resource_limits = False
    
    for file in docker_files:
        if file.exists():
            try:
                content = file.read_text(encoding='utf-8')
                if "network" in content.lower():
                    network_isolation = True
                if "mem_limit" in content or "cpus" in content:
                    resource_limits = True
            except:
                pass
    
    if docker_found:
        result["score"] += 10
        result["findings"].append("‚úÖ Docker isolation –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
    else:
        result["findings"].append("‚ùå Docker –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    if network_isolation:
        result["score"] += 10
        result["findings"].append("‚úÖ Network restrictions –µ—Å—Ç—å")
    
    if resource_limits:
        result["score"] += 10
        result["findings"].append("‚úÖ Resource limits —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    
    return result


def check_monitoring() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Monitoring"""
    result = {"score": 0, "max": 30, "findings": []}
    
    prometheus_file = PROJECT_ROOT / "monitoring_prometheus.py"
    grafana_dir = PROJECT_ROOT / "grafana"
    alerts_file = PROJECT_ROOT / "prometheus_alerts.yml"
    
    if prometheus_file.exists():
        result["score"] += 10
        result["findings"].append("‚úÖ Prometheus metrics")
    
    if grafana_dir.exists():
        result["score"] += 10
        result["findings"].append("‚úÖ Grafana dashboards")
    
    if alerts_file.exists():
        result["score"] += 10
        result["findings"].append("‚úÖ Alerting rules")
    
    return result


def check_multitenancy() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Multi-tenancy"""
    result = {"score": 0, "max": 40, "findings": []}
    
    backend_files = list((PROJECT_ROOT / "backend").rglob("*.py"))
    
    rbac_found = False
    rate_limit_found = False
    tenant_isolation = False
    
    for file in backend_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "rbac" in content.lower():
                rbac_found = True
            if "rate_limit" in content.lower():
                rate_limit_found = True
            if "tenant" in content.lower():
                tenant_isolation = True
        except:
            pass
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ test_rbac.py
    rbac_test = TESTS_DIR / "test_rbac.py"
    if rbac_test.exists():
        rbac_found = True
    
    if rbac_found:
        result["score"] += 15
        result["findings"].append("‚úÖ RBAC —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")
    
    if rate_limit_found:
        result["score"] += 15
        result["findings"].append("‚úÖ Rate limiting –µ—Å—Ç—å")
    
    if tenant_isolation:
        result["score"] += 10
        result["findings"].append("‚úÖ Tenant isolation —á–∞—Å—Ç–∏—á–Ω–æ")
    
    return result


def analyze_tz3_compliance() -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó —á–∞—Å—Ç—å 3: Multi-Agent System"""
    print("\n" + "="*80)
    print("ü§ñ –ê–Ω–∞–ª–∏–∑ –¢–ó –ß–∞—Å—Ç—å 3: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è")
    print("="*80 + "\n")
    
    compliance = {
        "score": 0,
        "max_score": 100,
        "sections": {}
    }
    
    # 2.2 Reasoning Agents
    print("üîç 2.2 Reasoning Agents (Perplexity)...")
    reasoning = check_reasoning_agents()
    compliance["sections"]["reasoning"] = reasoning
    print(f"   –û—Ü–µ–Ω–∫–∞: {reasoning['score']}/20")
    
    # 2.3 CodeGen Agents
    print("üîç 2.3 CodeGen Agents (DeepSeek)...")
    codegen = check_codegen_agents()
    compliance["sections"]["codegen"] = codegen
    print(f"   –û—Ü–µ–Ω–∫–∞: {codegen['score']}/20")
    
    # 2.4 ML Agents
    print("üîç 2.4 ML Agents/AutoML...")
    ml_agents = check_ml_agents()
    compliance["sections"]["ml_agents"] = ml_agents
    print(f"   –û—Ü–µ–Ω–∫–∞: {ml_agents['score']}/20")
    
    # 2.6 User Control
    print("üîç 2.6 User Control Interface...")
    user_control = check_user_control()
    compliance["sections"]["user_control"] = user_control
    print(f"   –û—Ü–µ–Ω–∫–∞: {user_control['score']}/20")
    
    # 3. Pipeline
    print("üîç 3. Pipeline Workflow...")
    pipeline = check_pipeline()
    compliance["sections"]["pipeline"] = pipeline
    print(f"   –û—Ü–µ–Ω–∫–∞: {pipeline['score']}/20")
    
    compliance["score"] = sum(s["score"] for s in compliance["sections"].values())
    
    print(f"\n‚úÖ –ò–¢–û–ì–û –¢–ó-3: {compliance['score']}/{compliance['max_score']} –±–∞–ª–ª–æ–≤")
    return compliance


def check_reasoning_agents() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Reasoning Agents"""
    result = {"score": 0, "max": 20, "findings": []}
    
    mcp_server = PROJECT_ROOT / "mcp-server" / "server.py"
    reasoning_logger = PROJECT_ROOT / "mcp-server" / "reasoning_logger.py"
    
    perplexity_found = False
    chain_of_thought = False
    
    if mcp_server.exists():
        content = mcp_server.read_text(encoding='utf-8')
        if "perplexity" in content.lower():
            perplexity_found = True
            result["score"] += 10
            result["findings"].append("‚úÖ Perplexity AI –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω")
        
        if "chain" in content.lower() or "reasoning" in content.lower():
            chain_of_thought = True
            result["score"] += 5
            result["findings"].append("‚úÖ Chain-of-thought –Ω–∞–π–¥–µ–Ω")
    
    if reasoning_logger.exists():
        result["score"] += 5
        result["findings"].append("‚úÖ Reasoning logger –µ—Å—Ç—å")
    
    return result


def check_codegen_agents() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ CodeGen Agents"""
    result = {"score": 0, "max": 20, "findings": []}
    
    deepseek_files = list((PROJECT_ROOT / "mcp-server").glob("deepseek*.py"))
    
    if deepseek_files:
        result["score"] += 10
        result["findings"].append(f"‚úÖ DeepSeek integration ({len(deepseek_files)} —Ñ–∞–π–ª–æ–≤)")
    
    codegen_found = False
    for file in deepseek_files:
        try:
            content = file.read_text(encoding='utf-8')
            if "code" in content.lower() and "generat" in content.lower():
                codegen_found = True
                break
        except:
            pass
    
    if codegen_found:
        result["score"] += 10
        result["findings"].append("‚úÖ Code generation –∞–∫—Ç–∏–≤–Ω–∞")
    
    return result


def check_ml_agents() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ ML Agents"""
    result = {"score": 0, "max": 20, "findings": []}
    
    ml_optimizer = PROJECT_ROOT / "ml_optimizer_perplexity.py"
    backend_ml = PROJECT_ROOT / "backend" / "ml"
    backend_opt = PROJECT_ROOT / "backend" / "optimization"
    
    if ml_optimizer.exists():
        result["score"] += 7
        result["findings"].append("‚úÖ ML optimizer –Ω–∞–π–¥–µ–Ω")
    
    if backend_ml.exists() and backend_ml.is_dir():
        result["score"] += 7
        result["findings"].append("‚úÖ ML –º–æ–¥—É–ª—å –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
    
    if backend_opt.exists() and backend_opt.is_dir():
        result["score"] += 6
        result["findings"].append("‚úÖ Optimization –º–æ–¥—É–ª—å –µ—Å—Ç—å")
    
    return result


def check_user_control() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ User Control Interface"""
    result = {"score": 0, "max": 20, "findings": []}
    
    frontend = PROJECT_ROOT / "frontend"
    vscode_integration = PROJECT_ROOT / "mcp-server" / "vscode_integration.py"
    
    if frontend.exists() and frontend.is_dir():
        result["score"] += 10
        result["findings"].append("‚úÖ Web UI (frontend)")
    
    if vscode_integration.exists():
        result["score"] += 10
        result["findings"].append("‚úÖ VS Code extension")
    
    return result


def check_pipeline() -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ Pipeline Workflow"""
    result = {"score": 0, "max": 20, "findings": []}
    
    orchestrator = PROJECT_ROOT / "mcp-server" / "orchestrator"
    deployment = PROJECT_ROOT / "deployment"
    scripts = PROJECT_ROOT / "scripts"
    
    if orchestrator.exists():
        result["score"] += 7
        result["findings"].append("‚úÖ Orchestrator –º–æ–¥—É–ª—å")
    
    if deployment.exists():
        result["score"] += 7
        result["findings"].append("‚úÖ Deployment automation")
    
    if scripts.exists():
        result["score"] += 6
        result["findings"].append("‚úÖ Scripts –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è")
    
    return result


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "="*80)
    print("üöÄ DEEPSEEK TEST RUNNER & TZ COMPLIANCE ANALYSIS")
    print("="*80)
    print(f"–î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80 + "\n")
    
    # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó (–±–µ–∑ –∑–∞–ø—É—Å–∫–∞ —Ç–µ—Å—Ç–æ–≤ –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –∏–º–ø–æ—Ä—Ç–∞)
    print("üìã –ó–∞–ø—É—Å–∫–∞—é –∞–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏—è–º...\n")
    
    tz1 = analyze_tz1_compliance()
    RESULTS["tz_compliance"]["tz1"] = tz1
    
    tz2 = analyze_tz2_compliance()
    RESULTS["tz_compliance"]["tz2"] = tz2
    
    tz3 = analyze_tz3_compliance()
    RESULTS["tz_compliance"]["tz3"] = tz3
    
    # –û–±—â–∏–π –±–∞–ª–ª
    total_score = tz1["score"] + tz2["score"] + tz3["score"]
    max_total = tz1["max_score"] + tz2["max_score"] + tz3["max_score"]
    percentage = (total_score / max_total * 100) if max_total > 0 else 0
    
    print("\n" + "="*80)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê")
    print("="*80)
    print(f"\nüéØ –û–ë–©–ò–ô –ë–ê–õ–õ: {total_score}/{max_total} ({percentage:.1f}%)")
    print(f"\n   –¢–ó-1 (–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞):     {tz1['score']}/{tz1['max_score']} ({tz1['score']/tz1['max_score']*100:.1f}%)")
    print(f"   –¢–ó-2 (Security):        {tz2['score']}/{tz2['max_score']} ({tz2['score']/tz2['max_score']*100:.1f}%)")
    print(f"   –¢–ó-3 (Multi-Agent):     {tz3['score']}/{tz3['max_score']} ({tz3['score']/tz3['max_score']*100:.1f}%)")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("\n" + "="*80)
    print("üìã –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò")
    print("="*80 + "\n")
    
    if tz1["score"] < 50:
        print("üî¥ –ö–†–ò–¢–ò–ß–ù–û: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å JSON-RPC 2.0 –∏ Redis Streams (–¢–ó-1)")
        RESULTS["recommendations"].append("CRITICAL: Implement JSON-RPC 2.0 and Redis Streams")
    
    if tz2["score"] < 50:
        print("üü° –í–ê–ñ–ù–û: –£–ª—É—á—à–∏—Ç—å sandbox security –∏ monitoring (–¢–ó-2)")
        RESULTS["recommendations"].append("HIGH: Enhance sandbox security and monitoring")
    
    if tz3["score"] < 70:
        print("üü° –í–ê–ñ–ù–û: –†–∞–∑–≤–∏—Ç—å multi-agent capabilities (–¢–ó-3)")
        RESULTS["recommendations"].append("MEDIUM: Develop multi-agent capabilities")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_file = PROJECT_ROOT / "DEEPSEEK_TEST_ANALYSIS.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(RESULTS, f, indent=2, ensure_ascii=False)
    
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    print("\n" + "="*80)
    print("üéâ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù!")
    print("="*80 + "\n")


if __name__ == "__main__":
    main()
