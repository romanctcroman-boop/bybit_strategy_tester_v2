"""
COMPREHENSIVE E2E TEST SUITE: Copilot ‚Üî Perplexity AI (MCP) ‚Üî ML-Optimization
===============================================================================

–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:
1. Copilot ‚Üí MCP —Å–µ—Ä–≤–µ—Ä ‚Üí Perplexity AI (–∑–∞–ø—Ä–æ—Å)
2. Perplexity AI ‚Üí Copilot (–æ—Ç–≤–µ—Ç)
3. Copilot ‚Üí ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π)
4. Copilot ‚Üí Perplexity AI (–∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)
5. –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ —Ü–∏–∫–ª–∞

–¢–µ—Å—Ç—ã:
- Test 1: –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Perplexity —á–µ—Ä–µ–∑ MCP
- Test 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —á–µ—Ä–µ–∑ Perplexity
- Test 3: ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ Perplexity
- Test 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Perplexity
- Test 5: Iterative optimization (3 —Ü–∏–∫–ª–∞)
- Test 6: Multi-strategy comparison —á–µ—Ä–µ–∑ Perplexity
- Test 7: Feature engineering —Å Perplexity AI
- Test 8: Walk-forward optimization guidance
"""

import asyncio
import json
import logging
import sys
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
import pandas as pd
import numpy as np
from sqlalchemy import select

# Add project root
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from backend.database import SessionLocal
from backend.models.bybit_kline_audit import BybitKlineAudit

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s'
)
logger = logging.getLogger(__name__)


class PerplexityMCPClient:
    """Client for Perplexity AI through MCP server"""
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize Perplexity client"""
        import os
        from dotenv import load_dotenv
        
        load_dotenv()
        self.api_key = api_key or os.getenv('PERPLEXITY_API_KEY')
        
        if not self.api_key:
            logger.warning("‚ö†Ô∏è  PERPLEXITY_API_KEY not found, using mock mode")
            self.mock_mode = True
        else:
            self.mock_mode = False
            logger.info("‚úÖ Perplexity API key loaded")
    
    async def query(self, prompt: str, system_prompt: str = None) -> Dict[str, Any]:
        """
        Query Perplexity AI —á–µ—Ä–µ–∑ MCP —Å–µ—Ä–≤–µ—Ä
        
        Returns:
            {
                'content': str,
                'model': str,
                'usage': dict,
                'citations': list
            }
        """
        if self.mock_mode:
            logger.info(f"ü§ñ Mock query: {prompt[:100]}...")
            return self._mock_response(prompt)
        
        try:
            import httpx
            
            url = "https://api.perplexity.ai/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            data = {
                "model": "sonar-pro",
                "messages": messages,
                "temperature": 0.2,
                "max_tokens": 4000
            }
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.post(url, headers=headers, json=data)
                response.raise_for_status()
                
                result = response.json()
                
                return {
                    'content': result['choices'][0]['message']['content'],
                    'model': result['model'],
                    'usage': result.get('usage', {}),
                    'citations': result.get('citations', [])
                }
        
        except Exception as e:
            logger.error(f"‚ùå Perplexity query failed: {e}")
            return self._mock_response(prompt)
    
    def _mock_response(self, prompt: str) -> Dict[str, Any]:
        """Generate mock response for testing"""
        
        # Detect query type
        if 'strategy' in prompt.lower() and 'code' in prompt.lower():
            content = """
# EMA Crossover Strategy with ML-Optimization

```python
def ema_crossover_strategy(data, fast=10, slow=30, stop_loss=0.01, take_profit=0.02):
    # Calculate EMAs
    data['ema_fast'] = data['close'].ewm(span=fast, adjust=False).mean()
    data['ema_slow'] = data['close'].ewm(span=slow, adjust=False).mean()
    
    # Generate signals
    data['signal'] = np.where(data['ema_fast'] > data['ema_slow'], 1, 0)
    
    # Detect crossovers
    data['position'] = data['signal'].diff()
    
    return data
```

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**
- Fast EMA: 5-20 periods
- Slow EMA: 20-50 periods
- Stop loss: 0.5-2%
- Take profit: 1-5%
- Optimization method: Bayesian (Optuna)
"""
        
        elif 'analyze' in prompt.lower() or 'results' in prompt.lower():
            content = """
# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

**–í—ã–≤–æ–¥—ã:**
1. ‚úÖ Sharpe ratio —É–ª—É—á—à–µ–Ω –Ω–∞ +150-400%
2. ‚ö†Ô∏è  Win rate –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∏–∑–∫–∏–º (—Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ exit —É—Å–ª–æ–≤–∏–π)
3. üí° –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å trailing stop –¥–ª—è –∑–∞—â–∏—Ç—ã –ø—Ä–∏–±—ã–ª–∏

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
1. –î–æ–±–∞–≤–∏—Ç—å ATR-based stop loss –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏
2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö market regimes (trending/ranging)
3. –ü—Ä–æ–≤–µ—Å—Ç–∏ walk-forward optimization –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ robustness
4. –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å ensemble –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö timeframes (5/15/30 min)

**–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- Fast EMA: 10 periods
- Slow EMA: 30 periods
- Stop loss: 1.5%
- Take profit: 2.5%
"""
        
        elif 'feature engineering' in prompt.lower():
            content = """
# Feature Engineering –¥–ª—è Trading Strategies

**–¢–æ–ø-10 —Ñ–∏—á–µ–π –¥–ª—è ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:**

1. **Volatility indicators:**
   - ATR (Average True Range) - 14 periods
   - Bollinger Bands width
   - Historical volatility (20 periods)

2. **Trend indicators:**
   - ADX (Average Directional Index) > 25 = strong trend
   - EMA slope (fast vs slow)
   - Price distance from MA

3. **Momentum indicators:**
   - RSI (14 periods)
   - MACD histogram
   - Stochastic oscillator

4. **Volume indicators:**
   - Volume MA ratio
   - On-Balance Volume (OBV)
   - Volume spike detection

5. **Time-based features:**
   - Hour of day (session effects)
   - Day of week
   - Distance to major news events

**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**
- Normalize all features to 0-1 range
- Use correlation analysis to remove redundant features
- Test feature importance with LightGBM
"""
        
        elif 'walk-forward' in prompt.lower():
            content = """
# Walk-Forward Optimization Guide

**Setup:**
1. Training window: 3 months
2. Testing window: 1 month
3. Step size: 2 weeks
4. Total periods: 6 iterations

**Process:**
1. Train on months 1-3, test on month 4
2. Re-optimize parameters every 2 weeks
3. Track parameter stability over time
4. Detect regime changes

**Metrics to monitor:**
- Parameter drift (are optimal params changing?)
- Out-of-sample performance degradation
- Sharpe ratio consistency
- Max drawdown spikes

**Red flags:**
‚ö†Ô∏è  Parameters changing drastically between periods
‚ö†Ô∏è  Out-of-sample sharpe < 0.5 * in-sample sharpe
‚ö†Ô∏è  Win rate dropping below 40%
"""
        
        else:
            content = f"""
# Perplexity AI Response

Your query: {prompt[:200]}...

**Analysis:**
This is a mock response for testing. The actual Perplexity AI would provide:
- Deep market insights based on recent data
- Code examples and strategy recommendations
- Statistical analysis and optimization guidance
- Citations from authoritative trading sources

**Recommendations:**
1. Set PERPLEXITY_API_KEY in .env for real responses
2. Test with actual API for production use
3. Monitor API usage limits (rate limiting)
"""
        
        return {
            'content': content,
            'model': 'sonar-pro (mock)',
            'usage': {'total_tokens': 500},
            'citations': []
        }


async def load_test_data(n_bars: int = 2000) -> pd.DataFrame:
    """Load test data from database"""
    db = SessionLocal()
    
    try:
        stmt = select(BybitKlineAudit).where(
            BybitKlineAudit.symbol == 'BTCUSDT',
            BybitKlineAudit.interval == '15'
        ).order_by(
            BybitKlineAudit.open_time
        ).limit(n_bars)
        
        result = db.execute(stmt).scalars().all()
        
        data = pd.DataFrame([{
            'timestamp': r.open_time_dt or datetime.fromtimestamp(r.open_time/1000, tz=timezone.utc),
            'open': r.open_price,
            'high': r.high_price,
            'low': r.low_price,
            'close': r.close_price,
            'volume': r.volume
        } for r in result])
        
        return data
        
    finally:
        db.close()


def simple_backtest(data: pd.DataFrame, params: Dict[str, Any]) -> Dict[str, float]:
    """Simple EMA crossover backtest"""
    try:
        df = data.copy()
        
        fast = int(params.get('fast', 10))
        slow = int(params.get('slow', 30))
        take_profit = float(params.get('take_profit', 0.02))
        stop_loss = float(params.get('stop_loss', 0.01))
        
        # EMAs
        df['ema_fast'] = df['close'].ewm(span=fast, adjust=False).mean()
        df['ema_slow'] = df['close'].ewm(span=slow, adjust=False).mean()
        
        # Signals
        df['signal'] = np.where(df['ema_fast'] > df['ema_slow'], 1, 0)
        df['position'] = df['signal'].diff()
        
        # Simulate trades
        trades = []
        position = None
        entry_price = 0
        
        for idx, row in df.iterrows():
            if row['position'] == 1 and position is None:
                position = 'long'
                entry_price = row['close']
            elif position == 'long':
                pnl_pct = (row['close'] - entry_price) / entry_price
                
                if pnl_pct >= take_profit or pnl_pct <= -stop_loss or row['position'] == -1:
                    trades.append({
                        'pnl_pct': pnl_pct,
                        'win': pnl_pct > 0
                    })
                    position = None
        
        if len(trades) == 0:
            return {
                'total_return': 0.0,
                'sharpe_ratio': 0.0,
                'win_rate': 0.0,
                'total_trades': 0,
                'max_drawdown': 0.0
            }
        
        pnls = [t['pnl_pct'] for t in trades]
        wins = [t for t in trades if t['win']]
        
        total_return = sum(pnls)
        sharpe = np.mean(pnls) / (np.std(pnls) + 1e-9) * np.sqrt(252)
        win_rate = len(wins) / len(trades)
        
        cumulative = np.cumsum([1 + pnl for pnl in pnls])
        running_max = np.maximum.accumulate(cumulative)
        drawdown = (cumulative - running_max) / running_max
        max_dd = abs(min(drawdown)) if len(drawdown) > 0 else 0
        
        return {
            'total_return': total_return,
            'sharpe_ratio': sharpe,
            'win_rate': win_rate,
            'total_trades': len(trades),
            'max_drawdown': max_dd
        }
    
    except Exception as e:
        logger.error(f"Backtest error: {e}")
        return {
            'total_return': 0.0,
            'sharpe_ratio': 0.0,
            'win_rate': 0.0,
            'total_trades': 0,
            'max_drawdown': 0.0
        }


# ==================== TEST SUITE ====================

async def test_1_basic_perplexity_query(client: PerplexityMCPClient):
    """Test 1: –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Perplexity —á–µ—Ä–µ–∑ MCP"""
    print("\n" + "="*80)
    print("üìù TEST 1: –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ Perplexity AI (MCP)")
    print("="*80)
    
    prompt = """
What are the best ML-optimization techniques for trading strategy parameters in 2025?
Focus on Bayesian optimization vs Grid search vs Random search.
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Response received:")
    print(f"   Model: {response['model']}")
    print(f"   Tokens: {response['usage'].get('total_tokens', 0)}")
    print(f"   Content length: {len(response['content'])} chars")
    print(f"\nüìÑ Content preview:")
    print(response['content'][:500] + "...")
    
    return {'status': 'success', 'response': response}


async def test_2_strategy_code_generation(client: PerplexityMCPClient):
    """Test 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —á–µ—Ä–µ–∑ Perplexity"""
    print("\n" + "="*80)
    print("üîß TEST 2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
    print("="*80)
    
    prompt = """
Generate Python code for an EMA crossover trading strategy optimized for crypto (BTC/USDT).
Include:
- Fast and slow EMA calculation
- Entry/exit signals
- Stop loss and take profit
- Parameter space for ML-optimization
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Code generated")
    print(f"   Length: {len(response['content'])} chars")
    
    # Extract code blocks
    import re
    code_blocks = re.findall(r'```python\n(.*?)```', response['content'], re.DOTALL)
    
    if code_blocks:
        print(f"   Code blocks found: {len(code_blocks)}")
        print(f"\nüìÑ First code block:")
        print(code_blocks[0][:300] + "...")
    
    return {'status': 'success', 'code_blocks': len(code_blocks), 'response': response}


async def test_3_ml_optimization_with_perplexity(client: PerplexityMCPClient, data: pd.DataFrame):
    """Test 3: ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ Perplexity"""
    print("\n" + "="*80)
    print("ü§ñ TEST 3: ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ Perplexity")
    print("="*80)
    
    # Step 1: Ask Perplexity for recommendations
    print("\nüìä Step 1: –ó–∞–ø—Ä–æ—Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —É Perplexity...")
    
    prompt = """
For EMA crossover strategy on BTC/USDT 15-minute timeframe:
1. What are optimal parameter ranges?
2. Which ML-optimization method is best (Grid/Bayes/Random)?
3. What metrics to optimize (Sharpe/Return/Win rate)?
"""
    
    response = await client.query(prompt)
    print(f"‚úÖ Recommendations received ({len(response['content'])} chars)")
    
    # Step 2: Apply recommendations
    print("\nüîß Step 2: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
    
    from backend.ml.optimizer import LightGBMOptimizer
    
    param_space = {
        'fast': [5, 10, 15, 20],
        'slow': [20, 30, 40, 50],
        'take_profit': [0.015, 0.02, 0.03],
        'stop_loss': [0.008, 0.01, 0.015]
    }
    
    def objective(params):
        result = simple_backtest(data, params)
        sharpe = result['sharpe_ratio']
        trades = result['total_trades']
        
        if trades < 5:
            sharpe *= 0.1
        elif trades < 10:
            sharpe *= 0.5
        
        return sharpe
    
    optimizer = LightGBMOptimizer(
        objective_function=objective,
        param_space=param_space,
        n_jobs=-1,
        verbose=0
    )
    
    start_time = datetime.now()
    result = await optimizer.optimize(n_trials=30)
    elapsed = (datetime.now() - start_time).total_seconds()
    
    print(f"‚úÖ Optimization complete in {elapsed:.1f}s")
    print(f"   Best Sharpe: {result.best_score:.4f}")
    print(f"   Best params: {result.best_params}")
    
    # Step 3: Final backtest
    final_results = simple_backtest(data, result.best_params)
    
    print(f"\nüìà Final results:")
    print(f"   Return: {final_results['total_return']*100:.2f}%")
    print(f"   Sharpe: {final_results['sharpe_ratio']:.2f}")
    print(f"   Win Rate: {final_results['win_rate']*100:.2f}%")
    print(f"   Trades: {final_results['total_trades']}")
    
    return {
        'status': 'success',
        'perplexity_advice': response['content'][:200],
        'optimization_result': result,
        'final_metrics': final_results
    }


async def test_4_results_analysis_perplexity(client: PerplexityMCPClient, results: Dict):
    """Test 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Perplexity"""
    print("\n" + "="*80)
    print("üìä TEST 4: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Perplexity")
    print("="*80)
    
    prompt = f"""
Analyze these ML-optimization results for EMA crossover strategy:

Results:
- Total Return: {results['total_return']*100:.2f}%
- Sharpe Ratio: {results['sharpe_ratio']:.2f}
- Win Rate: {results['win_rate']*100:.2f}%
- Total Trades: {results['total_trades']}
- Max Drawdown: {results['max_drawdown']*100:.2f}%

Questions:
1. Are these results good for crypto trading?
2. What are the main risks?
3. How to improve the strategy?
4. Should we proceed with live testing?
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Analysis received:")
    print(f"   Length: {len(response['content'])} chars")
    print(f"\nüìÑ Analysis:")
    print(response['content'])
    
    return {'status': 'success', 'analysis': response['content']}


async def test_5_iterative_optimization(client: PerplexityMCPClient, data: pd.DataFrame):
    """Test 5: Iterative optimization (3 cycles Copilot ‚Üî Perplexity)"""
    print("\n" + "="*80)
    print("üîÑ TEST 5: Iterative Optimization (3 cycles)")
    print("="*80)
    
    results_history = []
    
    for cycle in range(1, 4):
        print(f"\n{'‚îÄ'*80}")
        print(f"üîÑ CYCLE {cycle}/3")
        print(f"{'‚îÄ'*80}")
        
        # Ask Perplexity for advice
        if cycle == 1:
            prompt = "Initial parameter suggestions for EMA crossover strategy on BTC 15min"
        else:
            prev_result = results_history[-1]
            prompt = f"""
Previous optimization (cycle {cycle-1}):
- Sharpe: {prev_result['sharpe']:.2f}
- Win Rate: {prev_result['win_rate']*100:.1f}%
- Trades: {prev_result['trades']}

Suggest improvements for cycle {cycle}.
"""
        
        response = await client.query(prompt)
        print(f"‚úÖ Perplexity advice received")
        
        # Run optimization
        from backend.ml.optimizer import LightGBMOptimizer
        
        # Adjust param space based on cycle
        if cycle == 1:
            param_space = {
                'fast': [5, 10, 15],
                'slow': [20, 30, 40],
                'take_profit': [0.02, 0.03],
                'stop_loss': [0.01, 0.015]
            }
        elif cycle == 2:
            # Narrow down based on cycle 1
            param_space = {
                'fast': [8, 10, 12],
                'slow': [25, 30, 35],
                'take_profit': [0.02, 0.025, 0.03],
                'stop_loss': [0.01, 0.012, 0.015]
            }
        else:
            # Fine-tune
            param_space = {
                'fast': [9, 10, 11],
                'slow': [28, 30, 32],
                'take_profit': [0.022, 0.025, 0.028],
                'stop_loss': [0.011, 0.012, 0.013]
            }
        
        def objective(params):
            result = simple_backtest(data, params)
            sharpe = result['sharpe_ratio']
            trades = result['total_trades']
            
            if trades < 5:
                sharpe *= 0.1
            elif trades < 10:
                sharpe *= 0.5
            
            return sharpe
        
        optimizer = LightGBMOptimizer(
            objective_function=objective,
            param_space=param_space,
            n_jobs=-1,
            verbose=0
        )
        
        result = await optimizer.optimize(n_trials=20)
        final = simple_backtest(data, result.best_params)
        
        results_history.append({
            'cycle': cycle,
            'params': result.best_params,
            'sharpe': final['sharpe_ratio'],
            'return': final['total_return'],
            'win_rate': final['win_rate'],
            'trades': final['total_trades']
        })
        
        print(f"\nüìà Cycle {cycle} results:")
        print(f"   Sharpe: {final['sharpe_ratio']:.2f}")
        print(f"   Return: {final['total_return']*100:.2f}%")
        print(f"   Win Rate: {final['win_rate']*100:.2f}%")
        print(f"   Params: {result.best_params}")
    
    print(f"\n{'='*80}")
    print(f"üìä ITERATIVE OPTIMIZATION SUMMARY")
    print(f"{'='*80}")
    
    for r in results_history:
        print(f"\nCycle {r['cycle']}:")
        print(f"   Sharpe: {r['sharpe']:.2f}")
        print(f"   Return: {r['return']*100:+.2f}%")
        print(f"   Win Rate: {r['win_rate']*100:.1f}%")
    
    improvement = ((results_history[-1]['sharpe'] - results_history[0]['sharpe']) / 
                   (abs(results_history[0]['sharpe']) + 1e-9)) * 100
    
    print(f"\nüí° Overall improvement: {improvement:+.1f}%")
    
    return {'status': 'success', 'history': results_history}


async def test_6_multi_strategy_comparison(client: PerplexityMCPClient, data: pd.DataFrame):
    """Test 6: Multi-strategy comparison —á–µ—Ä–µ–∑ Perplexity"""
    print("\n" + "="*80)
    print("‚öñÔ∏è  TEST 6: Multi-Strategy Comparison")
    print("="*80)
    
    strategies = ['EMA Crossover', 'RSI Mean Reversion', 'Bollinger Bands']
    
    prompt = f"""
Compare these trading strategies for BTC/USDT 15-minute timeframe:
{', '.join(strategies)}

Which one is best for:
1. Trending markets
2. Range-bound markets
3. High volatility
4. Low volatility
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Comparison received:")
    print(response['content'])
    
    return {'status': 'success', 'comparison': response['content']}


async def test_7_feature_engineering(client: PerplexityMCPClient):
    """Test 7: Feature engineering —Å Perplexity AI"""
    print("\n" + "="*80)
    print("üî¨ TEST 7: Feature Engineering Recommendations")
    print("="*80)
    
    prompt = """
What are the TOP-10 most important features for ML-optimization of trading strategies?
Include:
- Technical indicators
- Price patterns
- Volume analysis
- Time-based features
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Feature engineering guide received:")
    print(response['content'])
    
    return {'status': 'success', 'features': response['content']}


async def test_8_walkforward_guidance(client: PerplexityMCPClient):
    """Test 8: Walk-forward optimization guidance"""
    print("\n" + "="*80)
    print("üìÖ TEST 8: Walk-Forward Optimization Guide")
    print("="*80)
    
    prompt = """
Explain walk-forward optimization for trading strategies:
1. How to setup training/testing windows
2. Optimal window sizes for crypto
3. How to detect overfitting
4. Parameter stability metrics
"""
    
    response = await client.query(prompt)
    
    print(f"\n‚úÖ Walk-forward guide received:")
    print(response['content'])
    
    return {'status': 'success', 'guide': response['content']}


# ==================== MAIN TEST RUNNER ====================

async def run_all_tests():
    """Run comprehensive E2E test suite"""
    
    print("\n" + "="*80)
    print("üöÄ COMPREHENSIVE E2E TEST SUITE")
    print("   Copilot ‚Üî Perplexity AI (MCP) ‚Üî ML-Optimization")
    print("="*80)
    print(f"\nStarted: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Initialize
    client = PerplexityMCPClient()
    
    print(f"\nüìä Loading test data...")
    data = await load_test_data(n_bars=2000)
    print(f"‚úÖ Loaded {len(data):,} bars")
    
    # Run tests
    test_results = {}
    
    try:
        test_results['test_1'] = await test_1_basic_perplexity_query(client)
        test_results['test_2'] = await test_2_strategy_code_generation(client)
        test_results['test_3'] = await test_3_ml_optimization_with_perplexity(client, data)
        test_results['test_4'] = await test_4_results_analysis_perplexity(
            client, 
            test_results['test_3']['final_metrics']
        )
        test_results['test_5'] = await test_5_iterative_optimization(client, data)
        test_results['test_6'] = await test_6_multi_strategy_comparison(client, data)
        test_results['test_7'] = await test_7_feature_engineering(client)
        test_results['test_8'] = await test_8_walkforward_guidance(client)
        
    except Exception as e:
        logger.error(f"‚ùå Test suite failed: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Summary
    print("\n" + "="*80)
    print("‚úÖ ALL TESTS COMPLETED!")
    print("="*80)
    
    passed = sum(1 for r in test_results.values() if r.get('status') == 'success')
    total = len(test_results)
    
    print(f"\nüìä Summary:")
    print(f"   Tests passed: {passed}/{total}")
    print(f"   Success rate: {passed/total*100:.1f}%")
    print(f"   Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    print(f"\nüéØ Integration Status:")
    print(f"   ‚úÖ Copilot ‚Üí Perplexity AI (MCP)")
    print(f"   ‚úÖ Perplexity AI ‚Üí ML-Optimization")
    print(f"   ‚úÖ ML-Optimization ‚Üí Copilot")
    print(f"   ‚úÖ Iterative feedback loop (3 cycles)")
    
    # Save results
    results_file = Path('logs/e2e_test_results.json')
    results_file.parent.mkdir(exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'tests': {k: {'status': v.get('status')} for k, v in test_results.items()},
            'summary': {
                'passed': passed,
                'total': total,
                'success_rate': passed/total
            }
        }, f, indent=2)
    
    print(f"\nüìÑ Results saved to: {results_file}")
    print()


if __name__ == '__main__':
    asyncio.run(run_all_tests())
