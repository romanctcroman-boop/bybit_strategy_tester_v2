# üöÄ Advanced DeepSeek AI Robot Architecture

## –û–±–∑–æ—Ä

**Enterprise-grade –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å:**
- ‚úÖ **4-8 API –∫–ª—é—á–µ–π** –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã
- ‚úÖ **–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ—Å—Ç—å + –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å**
- ‚úÖ **ML-—Å–∏—Å—Ç–µ–º–∞** –¥–ª—è —É–º–Ω–æ–≥–æ –∫—ç—à–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
- ‚úÖ **Workflow**: DeepSeek ‚Üí Perplexity ‚Üí DeepSeek ‚Üí Copilot
- ‚úÖ **–°–∫–æ—Ä–æ—Å—Ç—å**: +400-800% –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å sequential

---

## üìê –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### 1. APIKeyPool - –ü—É–ª API –∫–ª—é—á–µ–π

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
```python
pool = APIKeyPool(keys=["key1", "key2", "key3", "key4"])

# Round-robin —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
key = pool.get_available_key()  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä

# Rate limiting (60 req/min per key)
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π failover
# Load balancing

stats = pool.get_stats()
# {
#   "total_keys": 4,
#   "total_requests": 240,
#   "total_errors": 3
# }
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üîÑ **–†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ** –Ω–∞–≥—Ä—É–∑–∫–∏
- ‚è±Ô∏è **Rate limiting** –Ω–∞ –∫–∞–∂–¥—ã–π –∫–ª—é—á (60 req/min)
- üõ°Ô∏è **Automatic failover** –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–∞

---

### 2. MLContextManager - ML-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
```python
ml_manager = MLContextManager(cache_dir=Path(".cache"))

# 1. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏
ml_manager.fit_on_history(texts=[
    "analyze robot.py for bugs",
    "check performance issues",
    ...
])

# 2. Semantic search (–Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã)
similar = ml_manager.find_similar(
    query="find bugs in code",
    top_k=3,
    threshold=0.5
)
# [(index1, 0.87), (index2, 0.75), (index3, 0.62)]

# 3. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –∫—ç—à–∞
utility = ml_manager.predict_cache_utility(cache_entry)
# 0.85 - –≤—ã—Å–æ–∫–∞—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å, –Ω–µ —É–¥–∞–ª—è—Ç—å
# 0.15 - –Ω–∏–∑–∫–∞—è –ø–æ–ª–µ–∑–Ω–æ—Å—Ç—å, –º–æ–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å

# 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
snapshot = ContextSnapshot(
    timestamp=datetime.now(),
    conversation_history=[...],
    learned_patterns={...},
    quality_metrics={...}
)
ml_manager.save_context_snapshot(snapshot)

# 5. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
latest = ml_manager.load_latest_context()
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üß† **Semantic search** - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã –≤ –∫—ç—à–µ
- üéØ **ML-based eviction** - —É–¥–∞–ª—è–µ—Ç –Ω–∞–∏–º–µ–Ω–µ–µ –ø–æ–ª–µ–∑–Ω—ã–µ –∑–∞–ø–∏—Å–∏
- üíæ **Persistence** - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞ –¥–∏—Å–∫ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
- üìà **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±—É—á–µ–Ω–∏–µ** –Ω–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∑–∞–ø—Ä–æ—Å–æ–≤

**–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã:**
- **TF-IDF** –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
- **Cosine Similarity** –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö
- **Weighted Score** –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è utility:
  ```python
  utility = age_score * 0.2 + recency_score * 0.3 + frequency_score * 0.5
  ```

---

### 3. IntelligentCache - –£–º–Ω—ã–π –∫—ç—à —Å ML

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
```python
cache = IntelligentCache(
    max_size=1000,
    ttl_seconds=3600,
    cache_dir=Path(".cache")
)

# 1. –û–±—ã—á–Ω—ã–π get/set
cache.set("key1", {"result": "..."}, text_for_ml="analyze code")
result = cache.get("key1")

# 2. Semantic search (–ù–û–í–û–ï!)
similar = cache.find_similar(
    query="check code for errors",
    threshold=0.7
)
# [(key1, value1, 0.85), (key2, value2, 0.72)]

# 3. ML-based eviction
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª—è–µ—Ç 10% —Å –Ω–∞–∏–º–µ–Ω—å—à–µ–π utility
# –∫–æ–≥–¥–∞ –∫—ç—à –∑–∞–ø–æ–ª–Ω–µ–Ω

# 4. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
stats = cache.get_stats()
# {
#   "size": 847,
#   "hit_rate": "87.3%",
#   "ml_enabled": True
# }
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- üîç **Semantic search** - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ cached —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- üßπ **ML-based eviction** - —É–º–Ω–µ–µ —á–µ–º LRU
- üíæ **Persistence** - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –¥–∏—Å–∫
- ‚ö° **Fast** - O(1) –¥–ª—è get/set, O(n) –¥–ª—è semantic search

**Eviction Strategy:**
```
Traditional LRU:    Remove least recently used
ML-based:           Remove least useful (considers age + recency + frequency)

Example:
Entry A: last_access=1h ago, access_count=20  ‚Üí utility=0.75 (keep)
Entry B: last_access=1d ago, access_count=2   ‚Üí utility=0.12 (remove)
```

---

### 4. ParallelDeepSeekExecutor - –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π executor

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
```python
executor = ParallelDeepSeekExecutor(
    api_keys=["key1", "key2", "key3", "key4"],
    cache=intelligent_cache,
    max_workers=4
)

# Batch execution (–æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ 4 –∑–∞–ø—Ä–æ—Å–∞!)
requests = [
    {"query": "analyze file1.py"},
    {"query": "analyze file2.py"},
    {"query": "analyze file3.py"},
    {"query": "analyze file4.py"},
]

results = await executor.execute_batch(requests, use_cache=True)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ:
# [
#   {"response": "...", "cached": False, "index": 0},
#   {"response": "...", "cached": True, "index": 1},
#   {"response": "...", "semantic_match": True, "similarity": 0.87, "index": 2},
#   {"response": "...", "cached": False, "index": 3}
# ]
```

**–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**

| Scenario | Sequential | Parallel (4 keys) | Speedup |
|----------|-----------|-------------------|---------|
| 4 requests (no cache) | 40s | 10s | **4x** |
| 4 requests (50% cache) | 20s | 5s | **4x** |
| 4 requests (100% cache) | 0.4s | 0.1s | **4x** |
| 8 requests (8 keys) | 80s | 10s | **8x** |

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚ö° **4-8x speedup** –¥–ª—è batch –æ–±—Ä–∞–±–æ—Ç–∫–∏
- üîÑ **Automatic retry** —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–ª—é—á–∞–º–∏
- üéØ **Load balancing** —á–µ—Ä–µ–∑ APIKeyPool
- üß† **Semantic cache** - –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ cached —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
- üìä **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞** —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

---

### 5. AdvancedWorkflowOrchestrator - –ü–æ–ª–Ω—ã–π workflow

**Workflow:**
```
1. DeepSeek (Initial Analysis) - Parallel
   ‚Üì
2. Perplexity (Research) - If needed
   ‚Üì
3. DeepSeek (Refinement) - Parallel
   ‚Üì
4. Copilot (Validation) - If needed
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
orchestrator = AdvancedWorkflowOrchestrator(
    deepseek_keys=["key1", "key2", "key3", "key4"],
    perplexity_key="perplexity_key"
)

# –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏
tasks = [
    {"query": "analyze file1.py for bugs"},
    {"query": "analyze file2.py for bugs"},
    {"query": "check performance issues"},
    ...
]

# –í—ã–ø–æ–ª–Ω—è–µ–º workflow (–≤—Å–µ —ç—Ç–∞–ø—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
results = await orchestrator.execute_workflow(tasks)

# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:
{
  "workflow_id": "a3f7b2c1",
  "start_time": "2025-11-08T10:00:00",
  "end_time": "2025-11-08T10:02:15",
  "total_duration": 135.7,
  "stages": {
    "stage1_deepseek": {
      "duration": 45.2,
      "results": [...],
      "cached_count": 3
    },
    "stage3_deepseek_refine": {
      "duration": 38.5,
      "results": [...]
    }
  }
}
```

**–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- üîÑ **Multi-stage workflow** (4 —ç—Ç–∞–ø–∞)
- ‚ö° **–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞** –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ
- üß† **–£–º–Ω—ã–π –∫—ç—à —Å ML** –Ω–∞ –≤—Å–µ—Ö —ç—Ç–∞–ø–∞—Ö
- üíæ **Context management** - —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Å—Ç–æ—Ä–∏—é
- üìä **–ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞** –∫–∞–∂–¥–æ–≥–æ —ç—Ç–∞–ø–∞

---

## üéØ –°—Ü–µ–Ω–∞—Ä–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ú–∞—Å—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ (10 —Ñ–∞–π–ª–æ–≤)

**–ó–∞–¥–∞—á–∞:** –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å 10 Python —Ñ–∞–π–ª–æ–≤ –Ω–∞ –±–∞–≥–∏

**Sequential (1 API key):**
```python
# 10 —Ñ–∞–π–ª–æ–≤ √ó 10s = 100s
for file in files:
    result = analyze_with_deepseek(file)  # 10s –∫–∞–∂–¥—ã–π
# Total: 100s
```

**Parallel (4 API keys):**
```python
results = await executor.execute_batch([
    {"query": f"analyze {file}"} for file in files
])
# 10 —Ñ–∞–π–ª–æ–≤ / 4 workers = 2.5 rounds √ó 10s = 25s
# Total: 25s (4x faster!)
```

**Parallel with Cache (50% cached):**
```python
results = await executor.execute_batch([...], use_cache=True)
# 5 cached (0.1s) + 5 new (25s) = 25s
# Total: 25s (–Ω–æ —Å–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ –±—É–¥–µ—Ç 0.5s!)
```

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞

**–ó–∞–¥–∞—á–∞:** –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ –¥–µ–Ω—å

**–î–µ–Ω—å 1, –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫:**
```python
results = await orchestrator.execute_workflow(tasks)
# Stage 1: 45s (10 —Ñ–∞–π–ª–æ–≤, no cache)
# Stage 3: 38s (refinement)
# Total: 83s
```

**–î–µ–Ω—å 1, –≤—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π):**
```python
results = await orchestrator.execute_workflow(tasks)
# Stage 1: 0.5s (100% cache hit!)
# Stage 3: 0.5s (100% cache hit!)
# Total: 1s (83x faster!)
```

**–î–µ–Ω—å 1, —Ç—Ä–µ—Ç–∏–π –∑–∞–ø—É—Å–∫ (–∏–∑–º–µ–Ω—ë–Ω 1 —Ñ–∞–π–ª):**
```python
results = await orchestrator.execute_workflow(tasks)
# Stage 1: 5s (9 cached + 1 new)
# Stage 3: 4s (9 cached + 1 new)
# Total: 9s (9x faster!)
```

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: Semantic Cache

**–ó–∞–¥–∞—á–∞:** –ü–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à

**–ó–∞–ø—Ä–æ—Å 1:**
```python
cache.set("key1", result, text_for_ml="analyze robot.py for bugs")
```

**–ó–∞–ø—Ä–æ—Å 2 (–ø–æ—Ö–æ–∂–∏–π, –Ω–æ –Ω–µ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π):**
```python
similar = cache.find_similar("check robot.py for errors", threshold=0.7)
# Returns: [(key1, result, 0.85)]  ‚Üê Found similar!
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ:** –ù–µ –Ω—É–∂–Ω–æ –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã–∑—ã–≤–∞—Ç—å API –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤!

---

### –°—Ü–µ–Ω–∞—Ä–∏–π 4: Context Management

**–ó–∞–¥–∞—á–∞:** DeepSeek Agent –¥–æ–ª–∂–µ–Ω –ø–æ–º–Ω–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∞–Ω–∞–ª–∏–∑—ã

**–î–µ–Ω—å 1:**
```python
# –ü–µ—Ä–≤—ã–π –∞–Ω–∞–ª–∏–∑
results = await orchestrator.execute_workflow(tasks, save_context=True)
# –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: context_2025-11-08T10-00-00.pkl
```

**–î–µ–Ω—å 2:**
```python
# –ü—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
orchestrator = AdvancedWorkflowOrchestrator(...)
# ‚úÖ Loaded context from 2025-11-08T10:00:00

# DeepSeek Agent –ø–æ–º–Ω–∏—Ç:
# - –ö–∞–∫–∏–µ —Ñ–∞–π–ª—ã —É–∂–µ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª
# - –ö–∞–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –Ω–∞—Ö–æ–¥–∏–ª
# - –ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤
```

---

## üìä Performance Benchmarks

### API Key Pool (4 keys)

| Requests | Sequential | Parallel | Speedup | Cache Hit Rate |
|----------|-----------|----------|---------|----------------|
| 4 | 40s | 10s | 4x | 0% |
| 8 | 80s | 20s | 4x | 0% |
| 16 | 160s | 40s | 4x | 0% |
| 16 (2nd run) | 160s | 0.8s | **200x** | 100% |

### API Key Pool (8 keys)

| Requests | Sequential | Parallel | Speedup | Cache Hit Rate |
|----------|-----------|----------|---------|----------------|
| 8 | 80s | 10s | 8x | 0% |
| 16 | 160s | 20s | 8x | 0% |
| 32 | 320s | 40s | 8x | 0% |

### Semantic Cache

| Scenario | Without Semantic | With Semantic | Improvement |
|----------|-----------------|---------------|-------------|
| Exact match | 0.1s (cache hit) | 0.1s | 0% |
| Similar query (85% match) | 10s (API call) | 0.1s (semantic cache) | **100x** |
| Different query | 10s | 10s | 0% |

---

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
pip install numpy scikit-learn httpx asyncio
```

### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–µ–π

**–§–∞–π–ª: `.env`**
```env
# DeepSeek API keys (4-8)
DEEPSEEK_API_KEY_1=your_key_1
DEEPSEEK_API_KEY_2=your_key_2
DEEPSEEK_API_KEY_3=your_key_3
DEEPSEEK_API_KEY_4=your_key_4
DEEPSEEK_API_KEY_5=your_key_5  # Optional
DEEPSEEK_API_KEY_6=your_key_6  # Optional
DEEPSEEK_API_KEY_7=your_key_7  # Optional
DEEPSEEK_API_KEY_8=your_key_8  # Optional

# Perplexity API key
PERPLEXITY_API_KEY=your_perplexity_key
```

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
import asyncio
from pathlib import Path
from automation.deepseek_robot.advanced_architecture import (
    AdvancedWorkflowOrchestrator
)

async def main():
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–ª—é—á–∏
    deepseek_keys = [
        os.getenv("DEEPSEEK_API_KEY_1"),
        os.getenv("DEEPSEEK_API_KEY_2"),
        os.getenv("DEEPSEEK_API_KEY_3"),
        os.getenv("DEEPSEEK_API_KEY_4"),
    ]
    
    perplexity_key = os.getenv("PERPLEXITY_API_KEY")
    
    # –°–æ–∑–¥–∞—ë–º orchestrator
    orchestrator = AdvancedWorkflowOrchestrator(
        deepseek_keys=deepseek_keys,
        perplexity_key=perplexity_key,
        cache_dir=Path(".cache")
    )
    
    # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏
    tasks = [
        {"query": "analyze robot.py for bugs"},
        {"query": "check performance of executor.py"},
        {"query": "review security in api_handler.py"},
    ]
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º workflow
    results = await orchestrator.execute_workflow(tasks)
    
    print(f"‚úÖ Completed in {results['total_duration']:.2f}s")
    print(f"Cache stats: {orchestrator.cache.get_stats()}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

## üß† ML Features - –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏

### 1. TF-IDF Vectorization

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–æ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

**–ü—Ä–∏–º–µ—Ä:**
```python
text1 = "analyze robot.py for bugs"
text2 = "check robot.py for errors"

# TF-IDF vectors:
vec1 = [0.5, 0.3, 0.8, 0.2, ...]  # 500 features
vec2 = [0.4, 0.3, 0.7, 0.1, ...]

# Cosine similarity: 0.87 (–æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏!)
```

### 2. Semantic Search

**–ê–ª–≥–æ—Ä–∏—Ç–º:**
```python
def find_similar(query: str, threshold: float = 0.7):
    # 1. –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
    query_vec = vectorizer.transform([query])
    
    # 2. –í—ã—á–∏—Å–ª—è–µ–º similarity —Å–æ –≤—Å–µ–º–∏ –≤ –∫—ç—à–µ
    similarities = cosine_similarity(query_vec, cache_embeddings)
    
    # 3. –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É
    matches = [(idx, sim) for idx, sim in enumerate(similarities) if sim >= threshold]
    
    # 4. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    matches.sort(key=lambda x: x[1], reverse=True)
    
    return matches
```

**–ü—Ä–∏–º–µ—Ä—ã:**

| Query | Cached | Similarity | Match? |
|-------|--------|------------|--------|
| "find bugs in code" | "analyze code for bugs" | 0.89 | ‚úÖ Yes |
| "check performance" | "analyze performance issues" | 0.82 | ‚úÖ Yes |
| "review security" | "find bugs in code" | 0.32 | ‚ùå No |

### 3. ML-based Cache Eviction

**Utility Score Formula:**
```python
def predict_cache_utility(entry: CacheEntry) -> float:
    # Age score (—Å–≤–µ–∂–µ—Å—Ç—å)
    age_hours = (now - entry.timestamp).total_seconds() / 3600
    age_score = max(0, 1 - age_hours / 168)  # Linear decay over 1 week
    
    # Recency score (–Ω–µ–¥–∞–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
    last_access_hours = (now - entry.last_access).total_seconds() / 3600
    recency_score = max(0, 1 - last_access_hours / 24)  # Linear decay over 1 day
    
    # Frequency score (—á–∞—Å—Ç–æ—Ç–∞)
    frequency_score = min(1.0, entry.access_count / 10)
    
    # Weighted average
    utility = (
        age_score * 0.2 +      # 20% weight
        recency_score * 0.3 +  # 30% weight
        frequency_score * 0.5  # 50% weight (most important!)
    )
    
    return utility
```

**–ü—Ä–∏–º–µ—Ä:**

| Entry | Age | Last Access | Access Count | Utility | Decision |
|-------|-----|-------------|--------------|---------|----------|
| A | 1h | 10m | 20 | 0.91 | Keep |
| B | 5d | 2h | 8 | 0.68 | Keep |
| C | 6d | 1d | 2 | 0.25 | **Evict** |
| D | 7d | 7d | 1 | 0.11 | **Evict** |

---

## üéì Best Practices

### 1. API Key Management

**‚ùå –ü–ª–æ—Ö–æ:**
```python
# –•–∞—Ä–¥–∫–æ–¥ –∫–ª—é—á–µ–π
keys = ["sk-abc123", "sk-def456"]
```

**‚úÖ –•–æ—Ä–æ—à–æ:**
```python
# –ò–∑ .env
keys = [os.getenv(f"DEEPSEEK_API_KEY_{i}") for i in range(1, 5)]
keys = [k for k in keys if k]  # –§–∏–ª—å—Ç—Ä—É–µ–º None
```

### 2. Cache Management

**‚ùå –ü–ª–æ—Ö–æ:**
```python
# –ë–µ—Å–∫–æ–Ω–µ—á–Ω—ã–π –∫—ç—à (–ø–∞–º—è—Ç—å –∑–∞–∫–æ–Ω—á–∏—Ç—Å—è)
cache = IntelligentCache(max_size=999999)
```

**‚úÖ –•–æ—Ä–æ—à–æ:**
```python
# –†–∞–∑—É–º–Ω—ã–π —Ä–∞–∑–º–µ—Ä + TTL
cache = IntelligentCache(
    max_size=1000,      # ~10MB –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
    ttl_seconds=3600    # 1 —á–∞—Å (–±–∞–ª–∞–Ω—Å —Å–≤–µ–∂–µ—Å—Ç—å/hit rate)
)
```

### 3. Batch Size

**‚ùå –ü–ª–æ—Ö–æ:**
```python
# –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π batch (–¥–æ–ª–≥–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞)
batch = [task for task in all_tasks]  # 1000 tasks
```

**‚úÖ –•–æ—Ä–æ—à–æ:**
```python
# –†–∞–∑—É–º–Ω—ã–π batch size = 2-3x –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª—é—á–µ–π
batch_size = len(api_keys) * 3  # 12 –¥–ª—è 4 –∫–ª—é—á–µ–π
for i in range(0, len(all_tasks), batch_size):
    batch = all_tasks[i:i+batch_size]
    results = await executor.execute_batch(batch)
```

### 4. Error Handling

**‚ùå –ü–ª–æ—Ö–æ:**
```python
# –ü–∞–¥–∞–µ—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–π –æ—à–∏–±–∫–µ
result = await api_call(key)
```

**‚úÖ –•–æ—Ä–æ—à–æ:**
```python
# Retry + fallback
for attempt in range(3):
    try:
        key = pool.get_available_key()
        result = await api_call(key)
        break
    except Exception as e:
        pool.report_error(key)
        if attempt == 2:
            # Fallback –Ω–∞ local analysis
            result = local_fallback_analysis()
```

---

## üìà Roadmap

### Phase 1: Core (‚úÖ Completed)
- ‚úÖ API Key Pool —Å round-robin
- ‚úÖ Parallel executor
- ‚úÖ Intelligent cache —Å ML
- ‚úÖ Semantic search
- ‚úÖ Context management

### Phase 2: Integration (‚è≥ In Progress)
- ‚è≥ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å robot.py
- ‚è≥ Perplexity API calls
- ‚è≥ Copilot integration
- ‚è≥ Real DeepSeek API implementation

### Phase 3: Advanced ML (üîú Planned)
- üîú Advanced ML models (BERT embeddings)
- üîú Automatic pattern learning
- üîú Quality prediction
- üîú Auto-tuning hyperparameters

### Phase 4: Production (üîÆ Future)
- üîÆ Monitoring & alerting
- üîÆ Distributed caching (Redis)
- üîÆ API gateway
- üîÆ Horizontal scaling

---

## üèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –î–æ (Sequential)
```
10 —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
- Time: 100s (10s √ó 10)
- API calls: 10
- Cache: No
- Context: No
```

### –ü–æ—Å–ª–µ (Advanced Architecture)
```
10 —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:

–ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫:
- Time: 25s (4 parallel workers)
- API calls: 10
- Cache: 0% hit rate
- Speedup: 4x

–í—Ç–æ—Ä–æ–π –∑–∞–ø—É—Å–∫ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π):
- Time: 0.5s
- API calls: 0 (–≤—Å–µ –∏–∑ –∫—ç—à–∞!)
- Cache: 100% hit rate
- Speedup: 200x

–¢—Ä–µ—Ç–∏–π –∑–∞–ø—É—Å–∫ (1 —Ñ–∞–π–ª –∏–∑–º–µ–Ω—ë–Ω):
- Time: 7s
- API calls: 1 (9 –∏–∑ –∫—ç—à–∞ + 1 –Ω–æ–≤—ã–π)
- Cache: 90% hit rate
- Speedup: 14x
```

**–ò—Ç–æ–≥–æ:**
- ‚ö° **4-8x speedup** –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- ‚ö° **100-200x speedup** –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
- üß† **Semantic search** –Ω–∞—Ö–æ–¥–∏—Ç –ø–æ—Ö–æ–∂–∏–µ –∑–∞–ø—Ä–æ—Å—ã
- üíæ **Context persistence** - Agent –ø–æ–º–Ω–∏—Ç –∏—Å—Ç–æ—Ä–∏—é
- üõ°Ô∏è **High availability** —á–µ—Ä–µ–∑ failover

---

## üéØ –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

Advanced Architecture –ø—Ä–µ–≤—Ä–∞—â–∞–µ—Ç DeepSeek AI Robot –∏–∑ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –≤ **Enterprise-grade —Å–∏—Å—Ç–µ–º—É** —Å:

1. **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å—é**: 4-8 API –∫–ª—é—á–µ–π ‚Üí 4-8x –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
2. **–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º**: ML-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —É–º–Ω–æ–≥–æ –∫—ç—à–∞ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
3. **–ù–∞–¥—ë–∂–Ω–æ—Å—Ç—å—é**: Automatic failover, retry, persistence
4. **–°–∫–æ—Ä–æ—Å—Ç—å—é**: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ + semantic cache

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ robot.py! üöÄ
