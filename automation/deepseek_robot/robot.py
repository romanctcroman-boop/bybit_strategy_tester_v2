"""
ü§ñ DeepSeek AI Robot - Autonomous Code Improvement Agent

–ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º –∏ self-improvement
–¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100% –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞.

Features:
- Cyclic analysis: Analyze ‚Üí Fix ‚Üí Test ‚Üí Repeat
- Self-validation —á–µ—Ä–µ–∑ –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
- Integration with Copilot, Perplexity, DeepSeek
- Extended permissions: files, git, tests, DB
- Quality metrics –¥–æ 100%
- Autonomous operation with human escalation

Author: DeepSeek AI + GitHub Copilot + Perplexity AI
Date: 2025-11-08
"""

import asyncio
import json
import subprocess
import sys
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import httpx
from dotenv import load_dotenv
import os
import logging

# Advanced Architecture Components
from automation.deepseek_robot.advanced_architecture import (
    APIKeyPool,
    IntelligentCache,
    ParallelDeepSeekExecutor,
    AdvancedWorkflowOrchestrator,
    MLContextManager,
    ContextSnapshot
)

# Load environment
load_dotenv()

# Setup logger
logger = logging.getLogger(__name__)


class AutonomyLevel(Enum):
    """–£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏ —Ä–æ–±–æ—Ç–∞"""
    MANUAL = "manual"  # –¢—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∫–∞–∂–¥—ã–π —à–∞–≥
    SEMI_AUTO = "semi-auto"  # Batch approval
    FULL_AUTO = "full-auto"  # –ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å


class ProblemSeverity(Enum):
    """–°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã"""
    CRITICAL = "critical"  # –ë–ª–æ–∫–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É
    HIGH = "high"  # –í–∞–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞
    MEDIUM = "medium"  # –£–ª—É—á—à–µ–Ω–∏–µ
    LOW = "low"  # –ö–æ—Å–º–µ—Ç–∏–∫–∞


class FixStatus(Enum):
    """–°—Ç–∞—Ç—É—Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
    PENDING = "pending"
    APPLIED = "applied"
    VALIDATED = "validated"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class Problem:
    """–ü—Ä–æ–±–ª–µ–º–∞ –≤ –∫–æ–¥–µ"""
    id: str
    file: Path
    line: int
    severity: ProblemSeverity
    category: str  # lint, test, type, style, logic
    description: str
    suggested_fix: Optional[str] = None


@dataclass
class Fix:
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã"""
    problem_id: str
    file: Path
    old_content: str
    new_content: str
    backup_path: Optional[Path] = None
    status: FixStatus = FixStatus.PENDING
    validation_result: Optional[Dict] = None


@dataclass
class QualityMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞"""
    code_quality: float = 0.0  # 0-100, –≤–µ—Å 40%
    test_quality: float = 0.0  # 0-100, –≤–µ—Å 30%
    architecture_quality: float = 0.0  # 0-100, –≤–µ—Å 20%
    documentation_quality: float = 0.0  # 0-100, –≤–µ—Å 10%
    
    @property
    def total(self) -> float:
        """–û–±—â–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ 0-100"""
        return (
            self.code_quality * 0.4 +
            self.test_quality * 0.3 +
            self.architecture_quality * 0.2 +
            self.documentation_quality * 0.1
        )


@dataclass
class CycleResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ü–∏–∫–ª–∞ –∞–Ω–∞–ª–∏–∑–∞"""
    cycle_number: int
    problems_found: int
    fixes_applied: int
    fixes_failed: int
    quality_before: float
    quality_after: float
    duration_seconds: float
    timestamp: datetime = field(default_factory=datetime.now)


class DeepSeekRobot:
    """
    ü§ñ –ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π AI —Ä–æ–±–æ—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–æ–¥–∞
    
    –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    - Analyzer: —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
    - Executor: –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
    - Validator: –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç—ã –∏ –ª–∏–Ω—Ç–µ—Ä—ã
    - Quality Engine: —Ä–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ü–∏–∫–ª–∞–º–∏
    
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:
    - DeepSeek: –≥–ª—É–±–æ–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
    - Copilot: –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π (—á–µ—Ä–µ–∑ VS Code API)
    - Perplexity: –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –∏ best practices
    
    Permissions:
    - File operations (read/write/delete)
    - Git operations (commit/push/branch)
    - Test runner (pytest, mypy, black)
    - Database operations (queries, backups)
    """
    
    def __init__(
        self,
        project_root: Path,
        config_path: Optional[Path] = None,
        autonomy_level: AutonomyLevel = AutonomyLevel.SEMI_AUTO
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–æ–±–æ—Ç–∞
        
        Args:
            project_root: –ö–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
            config_path: –ü—É—Ç—å –∫ robot_config.json
            autonomy_level: –£—Ä–æ–≤–µ–Ω—å –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç–∏
        """
        self.project_root = Path(project_root).resolve()
        self.autonomy_level = autonomy_level
        
        # Load configuration
        self.config = self._load_config(config_path)
        
        # State
        self.cycle_number = 0
        self.cycles_history: List[CycleResult] = []
        self.current_problems: List[Problem] = []
        self.applied_fixes: List[Fix] = []
        self.quality_metrics = QualityMetrics()
        
        # üöÄ ADVANCED ARCHITECTURE INTEGRATION
        
        # 1. Load multiple API keys
        self.deepseek_keys = self._load_api_keys()
        self.perplexity_api_key = os.getenv("PERPLEXITY_API_KEY")
        
        # 2. Initialize Intelligent Cache with ML
        cache_dir = Path(os.getenv("CACHE_DIR", ".cache/deepseek"))
        cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.cache = IntelligentCache(
            max_size=int(os.getenv("CACHE_MAX_SIZE", "1000")),
            ttl_seconds=int(os.getenv("CACHE_TTL_SECONDS", "3600")),
            cache_dir=cache_dir
        )
        
        # 3. Initialize Parallel Executor
        self.executor = ParallelDeepSeekExecutor(
            api_keys=self.deepseek_keys,
            cache=self.cache,
            max_workers=int(os.getenv("MAX_PARALLEL_WORKERS", "4"))
        )
        
        # 4. Initialize Workflow Orchestrator
        self.orchestrator = AdvancedWorkflowOrchestrator(
            deepseek_keys=self.deepseek_keys,
            perplexity_key=self.perplexity_api_key,
            cache_dir=cache_dir
        )
        
        # 5. Load previous context
        self._load_previous_context()
        
        # Audit log
        self.audit_log_path = self.project_root / "robot_audit.log"
        
        print("=" * 80)
        print("ü§ñ DeepSeek AI Robot initialized (ADVANCED ARCHITECTURE)")
        print("=" * 80)
        print(f"üìÅ Project: {self.project_root}")
        print(f"üîß Autonomy: {self.autonomy_level.value}")
        print(f"üéØ Target Quality: {self.config.get('target_quality', 95)}%")
        print(f"üîÑ Max Iterations: {self.config.get('max_iterations', 5)}")
        print(f"‚ö° API Keys: {len(self.deepseek_keys)}")
        print(f"‚ö° Max Workers: {self.executor.max_workers}")
        print(f"üíæ Cache Size: {self.cache.max_size}")
        print(f"üß† ML Features: {'Enabled' if self.cache.ml_manager.vectorizer else 'Disabled'}")
        print("=" * 80)
        print()
    
    def _load_config(self, config_path: Optional[Path]) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        default_config = {
            "target_quality": 95,
            "max_iterations": 5,
            "ai_providers": {
                "deepseek": {
                    "model": "deepseek-coder",
                    "temperature": 0.1
                },
                "perplexity": {
                    "model": "sonar-pro"
                }
            },
            "quality_metrics": {
                "code_quality_weight": 0.4,
                "test_quality_weight": 0.3,
                "architecture_weight": 0.2,
                "documentation_weight": 0.1
            },
            "tools": {
                "pytest": {"enabled": True, "args": ["-v", "--tb=short"]},
                "mypy": {"enabled": True},
                "black": {"enabled": True, "line_length": 100},
                "isort": {"enabled": True}
            }
        }
        
        if config_path and config_path.exists():
            with open(config_path) as f:
                return json.load(f)
        
        return default_config
    
    def _load_api_keys(self) -> List[str]:
        """Load all DeepSeek API keys from .env"""
        keys = []
        for i in range(1, 9):  # Support up to 8 keys
            key = os.getenv(f"DEEPSEEK_API_KEY_{i}")
            if key:
                keys.append(key)
        
        if not keys:
            # Fallback to single key
            single_key = os.getenv("DEEPSEEK_API_KEY")
            if single_key:
                keys = [single_key]
            else:
                raise ValueError("No DeepSeek API keys found in .env!")
        
        logger.info(f"‚úÖ Loaded {len(keys)} DeepSeek API keys")
        return keys
    
    def _load_previous_context(self):
        """Load previous context if exists"""
        try:
            latest = self.cache.ml_manager.load_latest_context()
            
            if latest:
                logger.info(f"‚úÖ Loaded context from {latest.timestamp}")
                logger.info(f"   ‚Ä¢ Files analyzed: {latest.project_state.get('files_analyzed', 0)}")
                logger.info(f"   ‚Ä¢ Quality: {latest.quality_metrics.get('cache_hit_rate', 0):.0%} cache hit rate")
            else:
                logger.info("‚ÑπÔ∏è  No previous context found (first run)")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Failed to load previous context: {e}")
    
    # ========================================================================
    # MAIN WORKFLOW
    # ========================================================================
    
    async def run_improvement_cycle(self) -> CycleResult:
        """
        –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ —É–ª—É—á—à–µ–Ω–∏—è: Analyze ‚Üí Fix ‚Üí Test ‚Üí Validate
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç —Ü–∏–∫–ª–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        self.cycle_number += 1
        start_time = datetime.now()
        
        print(f"\n{'=' * 80}")
        print(f"üîÑ Cycle {self.cycle_number}: Starting improvement iteration")
        print(f"{'=' * 80}\n")
        
        # 1. Measure initial quality
        quality_before = await self._calculate_quality()
        print(f"üìä Current quality: {quality_before:.1f}%\n")
        
        # 2. Analyze project
        print("üîç Phase 1: Analysis")
        problems = await self.analyze_project()
        print(f"   Found {len(problems)} problems\n")
        
        if not problems:
            print("‚úÖ No problems found! Quality is optimal.")
            return self._create_cycle_result(
                quality_before, quality_before, 0, 0, 0, start_time
            )
        
        # 3. Generate fixes
        print("üîß Phase 2: Generating fixes")
        fixes = await self.generate_fixes(problems)
        print(f"   Generated {len(fixes)} fixes\n")
        
        # 4. Apply fixes
        print("‚öôÔ∏è  Phase 3: Applying fixes")
        fixes_applied, fixes_failed = await self.apply_fixes(fixes)
        print(f"   ‚úÖ Applied: {fixes_applied}, ‚ùå Failed: {fixes_failed}\n")
        
        # 5. Validate changes
        print("‚úì Phase 4: Validation")
        validation_result = await self.validate_changes()
        print(f"   Tests: {'PASSED ‚úÖ' if validation_result['tests_passed'] else 'FAILED ‚ùå'}")
        print(f"   Linters: {validation_result['lint_errors']} errors\n")
        
        # 6. Measure final quality
        quality_after = await self._calculate_quality()
        print(f"üìà Quality after cycle: {quality_after:.1f}%")
        print(f"   Improvement: {quality_after - quality_before:+.1f}%\n")
        
        # 7. Create result
        duration = (datetime.now() - start_time).total_seconds()
        result = self._create_cycle_result(
            quality_before, quality_after, len(problems), 
            fixes_applied, fixes_failed, start_time, duration
        )
        
        self.cycles_history.append(result)
        
        return result
    
    async def run_until_perfect(
        self,
        target_quality: float = 100.0,
        max_iterations: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ —Ü–∏–∫–ª–æ–≤ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
        
        Args:
            target_quality: –¶–µ–ª–µ–≤–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (0-100)
            max_iterations: –ú–∞–∫—Å–∏–º—É–º –∏—Ç–µ—Ä–∞—Ü–∏–π (None = –±–µ–∑ –ª–∏–º–∏—Ç–∞)
        
        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
        """
        if max_iterations is None:
            max_iterations = self.config.get("max_iterations", 10)
        
        print(f"\n{'=' * 80}")
        print(f"üöÄ Starting improvement loop")
        print(f"üéØ Target Quality: {target_quality}%")
        print(f"üîÑ Max Iterations: {max_iterations}")
        print(f"{'=' * 80}\n")
        
        no_progress_count = 0
        previous_quality = 0.0
        
        for iteration in range(1, max_iterations + 1):
            print(f"\n{'=' * 80}")
            print(f"Iteration {iteration}/{max_iterations}")
            print(f"{'=' * 80}\n")
            
            result = await self.run_improvement_cycle()
            
            # Check for target achievement
            if result.quality_after >= target_quality:
                print(f"\nüéâ Target quality achieved: {result.quality_after:.1f}%")
                return self._create_final_report(success=True)
            
            # Check for progress
            if result.quality_after <= previous_quality + 0.1:
                no_progress_count += 1
                print(f"‚ö†Ô∏è  No significant progress (count: {no_progress_count}/3)")
            else:
                no_progress_count = 0
            
            previous_quality = result.quality_after
            
            # Escalate if stuck
            if no_progress_count >= 3:
                print("\n‚ö†Ô∏è  No progress for 3 cycles - escalating to human!")
                return await self._escalate_to_human()
            
            # Delay between cycles
            if iteration < max_iterations:
                await asyncio.sleep(1)
        
        print(f"\n‚è±Ô∏è  Max iterations reached: {result.quality_after:.1f}% (target: {target_quality}%)")
        return self._create_final_report(success=False)
    
    # ========================================================================
    # ANALYZER
    # ========================================================================
    
    async def analyze_project(self) -> List[Problem]:
        """
        –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞: –ø–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º –≤ –∫–æ–¥–µ (PARALLEL EXECUTION)
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
        """
        problems = []
        
        # 1. Get IDE errors
        print("   üìã Collecting IDE errors...")
        ide_errors = await self._get_ide_errors()
        problems.extend(ide_errors)
        
        # 2. Run linters
        print("   üîç Running linters (mypy, pylint)...")
        lint_problems = await self._run_linters()
        problems.extend(lint_problems)
        
        # 3. Check tests
        print("   üß™ Checking test status...")
        test_problems = await self._check_tests()
        problems.extend(test_problems)
        
        # 4. DeepSeek analysis (PARALLEL with 4-8 API keys!)
        print(f"   ü§ñ DeepSeek parallel analysis ({len(self.deepseek_keys)} workers)...")
        deepseek_problems = await self._deepseek_analyze_parallel()
        problems.extend(deepseek_problems)
        
        # Remove duplicates with semantic search
        problems = await self._deduplicate_problems_smart(problems)
        
        # Sort by severity
        problems.sort(key=lambda p: (p.severity.value, p.file))
        
        self.current_problems = problems
        return problems
    
    async def _deepseek_analyze_parallel(self) -> List[Problem]:
        """
        DeepSeek –∞–Ω–∞–ª–∏–∑ —Å parallel execution —á–µ—Ä–µ–∑ ParallelDeepSeekExecutor
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö DeepSeek
        """
        # Get files to analyze
        python_files = list(self.project_root.glob("**/*.py"))[:20]  # Limit to 20 for now
        
        if not python_files:
            return []
        
        # Prepare batch requests
        requests = []
        for file in python_files:
            try:
                content = file.read_text(encoding="utf-8")
                requests.append({
                    "query": f"Analyze this Python file for potential issues:\n\n{content[:2000]}",  # Limit content
                    "file": str(file),
                    "model": "deepseek-coder",
                    "temperature": 0.1,
                    "max_tokens": 1000
                })
            except Exception as e:
                logger.warning(f"Failed to read {file}: {e}")
        
        print(f"      ‚ö° Analyzing {len(requests)} files in parallel...")
        
        # Execute in parallel (4-8x faster!)
        results = await self.executor.execute_batch(
            requests=requests,
            use_cache=True
        )
        
        # Log cache statistics
        cached_count = sum(1 for r in results if r.get("cached"))
        print(f"      ‚úÖ Completed: {len(results)} analyses")
        print(f"         ‚Ä¢ Cached: {cached_count} ({cached_count/len(results)*100:.0f}%)")
        print(f"         ‚Ä¢ New: {len(results) - cached_count}")
        
        # Parse results into problems
        problems = []
        for result in results:
            if result.get("success"):
                response = result.get("response", "")
                # Extract issues from response
                # (simplified parsing, –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                if "issue" in response.lower() or "problem" in response.lower():
                    file_path = Path(result.get("file", "unknown"))
                    problems.append(Problem(
                        id=f"deepseek_{len(problems)}",
                        file=file_path,
                        line=1,  # TODO: parse line number from response
                        severity=ProblemSeverity.MEDIUM,
                        category="logic",
                        description=response[:200]  # First 200 chars
                    ))
        
        return problems
    
    async def _deduplicate_problems_smart(self, problems: List[Problem]) -> List[Problem]:
        """
        Smart deduplication using semantic search
        
        Args:
            problems: List of problems
            
        Returns:
            Deduplicated list
        """
        if not problems:
            return []
        
        unique_problems = []
        seen_descriptions = set()
        
        for problem in problems:
            # Create text representation
            problem_text = f"{problem.file} {problem.description}"
            
            # Check if similar problem already seen
            similar = self.cache.find_similar(problem_text, threshold=0.85)
            
            if similar:
                # Found similar problem, skip
                _, cached_result, similarity = similar[0]
                logger.debug(f"Skipping duplicate problem (similarity: {similarity:.0%})")
                continue
            
            # Add to unique problems
            unique_problems.append(problem)
            seen_descriptions.add(problem.description)
            
            # Add to cache for future similarity checks
            self.cache.set(
                key=f"problem_{problem.id}",
                value={"problem": problem.__dict__},
                text_for_ml=problem_text
            )
        
        # Train ML on all problem descriptions
        all_texts = [f"{p.file} {p.description}" for p in unique_problems]
        self.cache.ml_manager.fit_on_history(all_texts)
        
        print(f"      üîç Deduplicated: {len(problems)} ‚Üí {len(unique_problems)}")
        
        return unique_problems
    
    async def _get_ide_errors(self) -> List[Problem]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—à–∏–±–∫–∏ –∏–∑ IDE (—ç–º—É–ª—è—Ü–∏—è get_errors)"""
        # TODO: Integration with VS Code API
        # For now, return empty list
        return []
    
    async def _run_linters(self) -> List[Problem]:
        """–ó–∞–ø—É—Å–∫ –ª–∏–Ω—Ç–µ—Ä–æ–≤"""
        problems = []
        
        # Mypy
        if self.config["tools"]["mypy"]["enabled"]:
            try:
                result = subprocess.run(
                    ["mypy", str(self.project_root)],
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                # Parse mypy output
                # Format: file.py:line: error: message
                for line in result.stdout.split('\n'):
                    if ": error:" in line:
                        parts = line.split(':')
                        if len(parts) >= 4:
                            problems.append(Problem(
                                id=f"mypy_{len(problems)}",
                                file=Path(parts[0]),
                                line=int(parts[1]),
                                severity=ProblemSeverity.HIGH,
                                category="type",
                                description=":".join(parts[3:]).strip()
                            ))
            except Exception as e:
                print(f"      ‚ö†Ô∏è  Mypy failed: {e}")
        
        return problems
    
    async def _check_tests(self) -> List[Problem]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Å—Ç–æ–≤"""
        # Placeholder
        return []
    
    async def _deepseek_analyze(self) -> List[Problem]:
        """
        Deprecated: Use _deepseek_analyze_parallel instead
        """
        logger.warning("_deepseek_analyze is deprecated, use _deepseek_analyze_parallel")
        return await self._deepseek_analyze_parallel()
    
    def _deduplicate_problems(self, problems: List[Problem]) -> List[Problem]:
        """
        Deprecated: Use _deduplicate_problems_smart instead
        """
        logger.warning("_deduplicate_problems is deprecated, use _deduplicate_problems_smart")
        # Fallback to simple deduplication
        seen = set()
        unique = []
        for p in problems:
            key = (p.file, p.line, p.description)
            if key not in seen:
                seen.add(key)
                unique.append(p)
        return unique
    
    # ========================================================================
    # EXECUTOR
    # ========================================================================
    
    async def generate_fixes(self, problems: List[Problem]) -> List[Fix]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–±–ª–µ–º
        
        Args:
            problems: –°–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º
        
        Returns:
            –°–ø–∏—Å–æ–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        """
        fixes = []
        
        for problem in problems:
            # Ask DeepSeek for fix
            fix = await self._generate_fix_with_deepseek(problem)
            if fix:
                fixes.append(fix)
        
        return fixes
    
    async def _generate_fix_with_deepseek(self, problem: Problem) -> Optional[Fix]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ DeepSeek"""
        # Placeholder
        return None
    
    async def apply_fixes(self, fixes: List[Fix]) -> Tuple[int, int]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        
        Returns:
            (applied_count, failed_count)
        """
        applied = 0
        failed = 0
        
        for fix in fixes:
            try:
                # Create backup
                fix.backup_path = await self._create_backup(fix.file)
                
                # Apply fix
                fix.file.write_text(fix.new_content, encoding='utf-8')
                fix.status = FixStatus.APPLIED
                applied += 1
                
                self.applied_fixes.append(fix)
                print(f"      ‚úÖ {fix.file.name}")
                
            except Exception as e:
                fix.status = FixStatus.FAILED
                failed += 1
                print(f"      ‚ùå {fix.file.name}: {e}")
        
        return applied, failed
    
    async def _create_backup(self, file: Path) -> Path:
        """–°–æ–∑–¥–∞–Ω–∏–µ backup —Ñ–∞–π–ª–∞"""
        backup_dir = self.project_root / ".robot_backups"
        backup_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = backup_dir / f"{file.name}.{timestamp}.bak"
        
        import shutil
        shutil.copy2(file, backup_path)
        
        return backup_path
    
    # ========================================================================
    # VALIDATOR
    # ========================================================================
    
    async def validate_changes(self) -> Dict[str, Any]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π —á–µ—Ä–µ–∑ —Ç–µ—Å—Ç—ã –∏ –ª–∏–Ω—Ç–µ—Ä—ã
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        """
        result = {
            "tests_passed": False,
            "tests_total": 0,
            "tests_failed": 0,
            "lint_errors": 0,
            "coverage": 0.0
        }
        
        # 1. Run tests
        print("      üß™ Running pytest...")
        test_result = await self._run_pytest()
        result.update(test_result)
        
        # 2. Run linters
        print("      üîç Running mypy...")
        lint_result = await self._run_mypy()
        result["lint_errors"] = lint_result.get("errors", 0)
        
        return result
    
    async def _run_pytest(self) -> Dict:
        """–ó–∞–ø—É—Å–∫ pytest"""
        try:
            args = ["pytest"] + self.config["tools"]["pytest"]["args"]
            result = subprocess.run(
                args,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300
            )
            
            # Parse pytest output
            # TODO: Better parsing
            passed = "passed" in result.stdout.lower()
            
            return {
                "tests_passed": result.returncode == 0,
                "tests_total": result.stdout.count("PASSED") + result.stdout.count("FAILED"),
                "tests_failed": result.stdout.count("FAILED")
            }
        except Exception as e:
            print(f"         ‚ö†Ô∏è  pytest failed: {e}")
            return {
                "tests_passed": False,
                "tests_total": 0,
                "tests_failed": 0
            }
    
    async def _run_mypy(self) -> Dict:
        """–ó–∞–ø—É—Å–∫ mypy"""
        try:
            result = subprocess.run(
                ["mypy", str(self.project_root)],
                capture_output=True,
                text=True,
                timeout=60
            )
            errors = result.stdout.count("error:")
            return {"errors": errors}
        except Exception as e:
            print(f"         ‚ö†Ô∏è  mypy failed: {e}")
            return {"errors": 0}
    
    # ========================================================================
    # QUALITY ENGINE
    # ========================================================================
    
    async def _calculate_quality(self) -> float:
        """
        –†–∞—Å—á—ë—Ç –æ–±—â–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–µ–∫—Ç–∞
        
        Returns:
            –ö–∞—á–µ—Å—Ç–≤–æ 0-100
        """
        # Code quality (40%)
        lint_result = await self._run_mypy()
        code_quality = max(0, 100 - lint_result["errors"] * 5)
        
        # Test quality (30%)
        test_result = await self._run_pytest()
        if test_result["tests_total"] > 0:
            test_quality = (
                (test_result["tests_total"] - test_result["tests_failed"]) 
                / test_result["tests_total"]
            ) * 100
        else:
            test_quality = 0
        
        # Architecture quality (20%) - placeholder
        architecture_quality = 80.0
        
        # Documentation quality (10%) - placeholder
        documentation_quality = 75.0
        
        metrics = QualityMetrics(
            code_quality=code_quality,
            test_quality=test_quality,
            architecture_quality=architecture_quality,
            documentation_quality=documentation_quality
        )
        
        # Save metrics for external access
        self.quality_metrics = metrics
        self.last_quality_metrics = metrics
        
        return metrics.total
    
    # ========================================================================
    # HELPERS
    # ========================================================================
    
    def _create_cycle_result(
        self,
        quality_before: float,
        quality_after: float,
        problems_found: int,
        fixes_applied: int,
        fixes_failed: int,
        start_time: datetime,
        duration: float = 0.0
    ) -> CycleResult:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Ü–∏–∫–ª–∞"""
        return CycleResult(
            cycle_number=self.cycle_number,
            problems_found=problems_found,
            fixes_applied=fixes_applied,
            fixes_failed=fixes_failed,
            quality_before=quality_before,
            quality_after=quality_after,
            duration_seconds=duration
        )
    
    def _create_final_report(self, success: bool) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞"""
        return {
            "success": success,
            "total_cycles": len(self.cycles_history),
            "final_quality": self.cycles_history[-1].quality_after if self.cycles_history else 0,
            "initial_quality": self.cycles_history[0].quality_before if self.cycles_history else 0,
            "total_fixes": sum(c.fixes_applied for c in self.cycles_history),
            "total_duration": sum(c.duration_seconds for c in self.cycles_history),
            "cycles": [
                {
                    "cycle": c.cycle_number,
                    "quality_before": c.quality_before,
                    "quality_after": c.quality_after,
                    "improvement": c.quality_after - c.quality_before,
                    "fixes_applied": c.fixes_applied
                }
                for c in self.cycles_history
            ]
        }
    
    async def _escalate_to_human(self) -> Dict[str, Any]:
        """–≠—Å–∫–∞–ª–∞—Ü–∏—è –∫ —á–µ–ª–æ–≤–µ–∫—É"""
        print("\n" + "=" * 80)
        print("üö® ESCALATION TO HUMAN")
        print("=" * 80)
        print("Robot unable to make further progress automatically.")
        print("Manual intervention required.")
        print("\nLast problems:")
        for p in self.current_problems[:5]:
            print(f"  - {p.file}:{p.line} - {p.description}")
        print("=" * 80)
        
        return self._create_final_report(success=False)
    
    # ========================================================================
    # ADVANCED ARCHITECTURE METHODS
    # ========================================================================
    
    async def execute_advanced_workflow(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Execute full 4-stage workflow: DeepSeek ‚Üí Perplexity ‚Üí DeepSeek ‚Üí Copilot
        
        Args:
            tasks: List of analysis tasks
            
        Returns:
            Results with all stages
        """
        logger.info(f"üöÄ Starting advanced workflow")
        logger.info(f"   ‚Ä¢ Tasks: {len(tasks)}")
        logger.info(f"   ‚Ä¢ Pipeline: DeepSeek ‚Üí Perplexity ‚Üí DeepSeek ‚Üí Copilot")
        
        # Execute through orchestrator
        results = await self.orchestrator.execute_workflow(
            tasks=tasks,
            save_context=True
        )
        
        # Log results
        logger.info(f"‚úÖ Workflow completed!")
        logger.info(f"   ‚Ä¢ Duration: {results.get('total_duration', 0):.2f}s")
        logger.info(f"   ‚Ä¢ Cache hit rate: {self.cache.get_stats().get('hit_rate', 0):.1%}")
        
        return results
    
    def get_advanced_metrics(self) -> Dict[str, Any]:
        """Get advanced architecture metrics"""
        cache_stats = self.cache.get_stats()
        pool_stats = self.executor.key_pool.get_stats()
        
        return {
            "cache": {
                "size": cache_stats.get("size", 0),
                "max_size": cache_stats.get("max_size", 0),
                "hit_rate": cache_stats.get("hit_rate", 0.0),
                "evictions": cache_stats.get("evictions", 0)
            },
            "api_keys": {
                "total_keys": pool_stats.get("total_keys", 0),
                "total_requests": pool_stats.get("total_requests", 0),
                "total_errors": pool_stats.get("total_errors", 0),
                "requests_per_key": (
                    pool_stats.get("total_requests", 0) / pool_stats.get("total_keys", 1)
                    if pool_stats.get("total_keys", 0) > 0 else 0
                )
            },
            "ml": {
                "enabled": cache_stats.get("ml_enabled", False),
                "documents_trained": (
                    len(self.cache.ml_manager.documents)
                    if hasattr(self.cache.ml_manager, 'documents') else 0
                )
            },
            "performance": {
                "parallel_workers": self.executor.max_workers,
                "expected_speedup": f"{self.executor.max_workers}x"
            }
        }


# ============================================================================
# EXAMPLE USAGE
# ============================================================================

async def main():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã DeepSeek Robot"""
    
    robot = DeepSeekRobot(
        project_root=Path.cwd(),
        autonomy_level=AutonomyLevel.SEMI_AUTO
    )
    
    # Run improvement cycle until 95% quality
    result = await robot.run_until_perfect(
        target_quality=95.0,
        max_iterations=5
    )
    
    print("\n" + "=" * 80)
    print("üìä FINAL REPORT")
    print("=" * 80)
    print(json.dumps(result, indent=2))
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
