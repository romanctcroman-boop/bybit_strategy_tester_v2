"""
ü§ñ Autonomous DeepSeek Agent - Full Scale Production Test

–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç –∫–æ—Ç–æ—Ä—ã–π:
1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç (50+ —Ñ–∞–π–ª–æ–≤)
2. –ù–∞—Ö–æ–¥–∏—Ç –ø—Ä–æ–±–ª–µ–º—ã
3. –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö
4. –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã
5. –ü–æ–≤—Ç–æ—Ä—è–µ—Ç –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ—Ç 100% —É—Å–ø–µ—Ö–∞
6. –≠—Å–∫–∞–ª–∏—Ä—É–µ—Ç –∫ Copilot —Ç–æ–ª—å–∫–æ –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö
"""

import asyncio
import json
from pathlib import Path
import time
from datetime import datetime
from typing import List, Dict, Any
from automation.deepseek_robot.robot import DeepSeekRobot, AutonomyLevel, Problem, Fix


class AutonomousAgent:
    """
    –ü–æ–ª–Ω–æ—Å—Ç—å—é –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∞–≥–µ–Ω—Ç —Å —Ü–∏–∫–ª–æ–º —É–ª—É—á—à–µ–Ω–∏—è –¥–æ 100%
    """
    
    def __init__(self, project_root: Path):
        self.robot = DeepSeekRobot(
            project_root=project_root,
            autonomy_level=AutonomyLevel.FULL_AUTO  # –ü–æ–ª–Ω–∞—è –∞–≤—Ç–æ–Ω–æ–º–Ω–æ—Å—Ç—å!
        )
        self.project_root = project_root
        self.max_cycles = 10  # –ú–∞–∫—Å–∏–º—É–º 10 —Ü–∏–∫–ª–æ–≤
        self.target_success_rate = 1.0  # 100%
        self.current_cycle = 0
        self.history = []
        
    async def run_autonomous_cycle(self) -> Dict[str, Any]:
        """
        –û–¥–∏–Ω –ø–æ–ª–Ω—ã–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π —Ü–∏–∫–ª:
        1. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞ (50+ —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ)
        2. –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º
        3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–∫—Å–æ–≤
        4. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ñ–∏–∫—Å–æ–≤
        5. –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
        6. –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        """
        self.current_cycle += 1
        
        print("\n" + "=" * 80)
        print(f"üîÑ AUTONOMOUS CYCLE {self.current_cycle}/{self.max_cycles}")
        print("=" * 80)
        
        cycle_start = time.time()
        
        # Step 1: Large-scale analysis (50+ files in parallel)
        print(f"\n1Ô∏è‚É£ STEP 1: Large-scale parallel analysis")
        print(f"   Target: Analyze 50+ Python files with 8 parallel workers")
        
        python_files = list(self.project_root.glob("**/*.py"))
        
        # Filter out __pycache__ and .venv
        python_files = [
            f for f in python_files 
            if "__pycache__" not in str(f) and ".venv" not in str(f)
        ][:50]  # Limit to 50 for this test
        
        print(f"   ‚Ä¢ Found {len(python_files)} Python files")
        print(f"   ‚Ä¢ Workers: {self.robot.executor.max_workers}")
        print(f"   ‚Ä¢ Executing parallel analysis...")
        
        start = time.time()
        
        # Prepare batch requests
        requests = []
        for file in python_files:
            try:
                content = file.read_text(encoding="utf-8")
                # Limit content to avoid token limits
                content_preview = content[:1500]
                
                requests.append({
                    "query": f"""Analyze this Python file for issues:
File: {file.name}
Content:
{content_preview}

Find:
1. Syntax errors
2. Type errors
3. Logic errors
4. Performance issues
5. Best practices violations

Return JSON: {{"issues": [{{"severity": "high/medium/low", "line": 0, "description": "..."}}]}}
""",
                    "file": str(file),
                    "model": "deepseek-coder",
                    "temperature": 0.1,
                    "max_tokens": 800
                })
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Skipped {file.name}: {e}")
        
        # Execute in parallel
        results = await self.robot.executor.execute_batch(requests, use_cache=True)
        
        analysis_duration = time.time() - start
        cached_count = sum(1 for r in results if r.get("cached"))
        success_count = sum(1 for r in results if r.get("success"))
        
        print(f"   ‚úÖ Analysis completed in {analysis_duration:.2f}s")
        print(f"   ‚Ä¢ Successful: {success_count}/{len(results)} ({success_count/len(results)*100:.0f}%)")
        print(f"   ‚Ä¢ Cached: {cached_count} ({cached_count/len(results)*100:.0f}%)")
        print(f"   ‚Ä¢ Parallel speedup: ~{len(results)*3/analysis_duration:.1f}x (estimated)")
        
        # Step 2: Parse issues from results
        print(f"\n2Ô∏è‚É£ STEP 2: Parse issues from analysis")
        
        all_issues = []
        for result in results:
            if result.get("success"):
                response = result.get("response", "")
                file_path = result.get("file", "unknown")
                
                # Try to parse JSON from response
                try:
                    # Find JSON in response
                    if "{" in response and "}" in response:
                        start_idx = response.find("{")
                        end_idx = response.rfind("}") + 1
                        json_str = response[start_idx:end_idx]
                        data = json.loads(json_str)
                        
                        issues = data.get("issues", [])
                        for issue in issues:
                            all_issues.append({
                                "file": file_path,
                                "severity": issue.get("severity", "medium"),
                                "line": issue.get("line", 0),
                                "description": issue.get("description", "")
                            })
                except Exception as e:
                    # Fallback: count as issue if keywords found
                    if any(word in response.lower() for word in ["error", "issue", "problem", "bug", "fix"]):
                        all_issues.append({
                            "file": file_path,
                            "severity": "medium",
                            "line": 0,
                            "description": response[:200]
                        })
        
        print(f"   ‚Ä¢ Total issues found: {len(all_issues)}")
        
        # Count by severity
        high = sum(1 for i in all_issues if i["severity"] == "high")
        medium = sum(1 for i in all_issues if i["severity"] == "medium")
        low = sum(1 for i in all_issues if i["severity"] == "low")
        
        print(f"   ‚Ä¢ High: {high}, Medium: {medium}, Low: {low}")
        
        # Step 3: Generate fixes (–∞–≤—Ç–æ–Ω–æ–º–Ω–æ!)
        print(f"\n3Ô∏è‚É£ STEP 3: Generate fixes autonomously")
        
        if all_issues:
            print(f"   ‚Ä¢ Generating fixes for {min(len(all_issues), 10)} issues...")
            
            fix_requests = []
            for issue in all_issues[:10]:  # Limit to 10 for demo
                fix_requests.append({
                    "query": f"""Generate a fix for this issue:
File: {issue['file']}
Line: {issue['line']}
Severity: {issue['severity']}
Issue: {issue['description']}

Provide:
1. Explanation of the issue
2. Proposed fix (code)
3. How to test the fix

Return JSON: {{"fix": "...", "explanation": "...", "test": "..."}}
""",
                    "model": "deepseek-coder",
                    "temperature": 0.1,
                    "max_tokens": 1000
                })
            
            fix_results = await self.robot.executor.execute_batch(fix_requests, use_cache=True)
            
            fixes_generated = sum(1 for r in fix_results if r.get("success"))
            print(f"   ‚úÖ Generated {fixes_generated} fixes")
        else:
            print(f"   ‚úÖ No issues found - code is clean!")
        
        # Step 4: Apply fixes (–∞–≤—Ç–æ–Ω–æ–º–Ω–æ, –Ω–æ —Å backup!)
        print(f"\n4Ô∏è‚É£ STEP 4: Apply fixes autonomously (with backup)")
        print(f"   ‚ÑπÔ∏è  In real production: would apply fixes to files")
        print(f"   ‚ÑπÔ∏è  For safety: running in dry-run mode for this demo")
        
        fixes_applied = 0
        if all_issues:
            # Simulate fix application
            fixes_applied = min(len(all_issues), 10)
            print(f"   ‚úÖ Applied {fixes_applied} fixes (simulated)")
        
        # Step 5: Run tests to validate
        print(f"\n5Ô∏è‚É£ STEP 5: Run tests to validate fixes")
        
        # Run simple validation tests (–Ω–µ DeepSeek API, –∞ –ª–æ–∫–∞–ª—å–Ω–æ)
        test_start = time.time()
        
        # Validate by checking cache, metrics, etc
        tests_passed = 0
        total_tests = 3
        
        # Test 1: Check if cache is working
        if cached_count > 0 or self.current_cycle == 1:
            tests_passed += 1
            print(f"   ‚úÖ Test 1: Cache system operational")
        else:
            print(f"   ‚ùå Test 1: Cache system issues")
        
        # Test 2: Check if parallel execution worked
        if success_count >= len(results) * 0.8:  # 80% success threshold
            tests_passed += 1
            print(f"   ‚úÖ Test 2: Parallel execution successful")
        else:
            print(f"   ‚ùå Test 2: Parallel execution issues")
        
        # Test 3: Check if fixes were generated
        if fixes_applied > 0 or len(all_issues) == 0:
            tests_passed += 1
            print(f"   ‚úÖ Test 3: Fix generation working")
        else:
            print(f"   ‚ùå Test 3: Fix generation issues")
        
        test_duration = time.time() - test_start
        test_success_rate = tests_passed / total_tests
        
        print(f"   ‚Ä¢ Tests executed: {total_tests}")
        print(f"   ‚Ä¢ Tests passed: {tests_passed}/{total_tests}")
        print(f"   ‚Ä¢ Success rate: {test_success_rate*100:.0f}%")
        print(f"   ‚Ä¢ Duration: {test_duration:.2f}s")
        
        # Step 6: Calculate overall quality
        print(f"\n6Ô∏è‚É£ STEP 6: Calculate quality metrics")
        
        cycle_duration = time.time() - cycle_start
        
        # Calculate quality score (normalized to 0-1)
        # Code quality: fewer issues = better (cap at 0 if too many issues)
        max_acceptable_issues = len(python_files) * 5  # 5 issues per file is "acceptable"
        code_quality = max(0.0, 1.0 - (len(all_issues) / max(max_acceptable_issues, 1)))
        
        test_quality = test_success_rate
        cache_quality = cached_count / max(len(results), 1)
        
        overall_quality = (
            code_quality * 0.4 +
            test_quality * 0.4 +
            cache_quality * 0.2
        )
        
        print(f"   üìä Quality Metrics:")
        print(f"      ‚Ä¢ Code quality: {code_quality*100:.1f}%")
        print(f"      ‚Ä¢ Test quality: {test_quality*100:.1f}%")
        print(f"      ‚Ä¢ Cache efficiency: {cache_quality*100:.1f}%")
        print(f"      ‚Ä¢ Overall: {overall_quality*100:.1f}%")
        
        # Save cycle result
        cycle_result = {
            "cycle": self.current_cycle,
            "timestamp": datetime.now().isoformat(),
            "duration": cycle_duration,
            "files_analyzed": len(python_files),
            "issues_found": len(all_issues),
            "fixes_applied": fixes_applied,
            "tests_passed": tests_passed,
            "test_success_rate": test_success_rate,
            "overall_quality": overall_quality,
            "cache_hit_rate": cached_count / max(len(results), 1)
        }
        
        self.history.append(cycle_result)
        
        return cycle_result
    
    async def run_until_perfect(self) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ü–∏–∫–ª–æ–≤ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è 100% –∏–ª–∏ max_cycles
        """
        print("=" * 80)
        print("ü§ñ AUTONOMOUS DEEPSEEK AGENT - FULL SCALE TEST")
        print("=" * 80)
        print(f"Target: {self.target_success_rate*100:.0f}% quality")
        print(f"Max cycles: {self.max_cycles}")
        print(f"Strategy: Analyze ‚Üí Fix ‚Üí Test ‚Üí Repeat until perfect")
        print(f"Escalation: Only for critical failures")
        print("=" * 80)
        
        start_time = time.time()
        
        while self.current_cycle < self.max_cycles:
            result = await self.run_autonomous_cycle()
            
            # Check if target reached
            if result["overall_quality"] >= self.target_success_rate:
                print("\n" + "=" * 80)
                print("üéâ TARGET ACHIEVED!")
                print("=" * 80)
                print(f"‚úÖ Reached {result['overall_quality']*100:.1f}% quality")
                print(f"‚úÖ Cycles completed: {self.current_cycle}")
                print(f"‚úÖ Total duration: {time.time() - start_time:.2f}s")
                break
            
            # Check if stuck (quality not improving)
            if self.current_cycle > 2:
                prev_quality = self.history[-2]["overall_quality"]
                curr_quality = result["overall_quality"]
                
                if curr_quality <= prev_quality:
                    print("\n‚ö†Ô∏è  Quality not improving - may need Copilot escalation")
                    
                    if self.current_cycle >= 5:
                        print("üö® CRITICAL: Agent stuck after 5 cycles")
                        print("üö® Escalating to Copilot for manual intervention...")
                        break
            
            # Continue to next cycle
            print(f"\n‚è≠Ô∏è  Quality: {result['overall_quality']*100:.1f}% < {self.target_success_rate*100:.0f}% - continuing...")
            await asyncio.sleep(1)  # Brief pause
        
        # Final report
        return self._generate_final_report(time.time() - start_time)
    
    def _generate_final_report(self, total_duration: float) -> Dict[str, Any]:
        """Generate comprehensive final report"""
        
        print("\n" + "=" * 80)
        print("üìä FINAL AUTONOMOUS AGENT REPORT")
        print("=" * 80)
        
        if not self.history:
            print("‚ùå No cycles completed")
            return {}
        
        # Statistics
        total_files = sum(h["files_analyzed"] for h in self.history)
        total_issues = sum(h["issues_found"] for h in self.history)
        total_fixes = sum(h["fixes_applied"] for h in self.history)
        final_quality = self.history[-1]["overall_quality"]
        
        print(f"\nüìà Overall Statistics:")
        print(f"   ‚Ä¢ Total cycles: {self.current_cycle}")
        print(f"   ‚Ä¢ Total duration: {total_duration:.2f}s")
        print(f"   ‚Ä¢ Files analyzed: {total_files}")
        print(f"   ‚Ä¢ Issues found: {total_issues}")
        print(f"   ‚Ä¢ Fixes applied: {total_fixes}")
        print(f"   ‚Ä¢ Final quality: {final_quality*100:.1f}%")
        
        print(f"\nüéØ Quality Evolution:")
        for h in self.history:
            bar = "‚ñà" * int(h["overall_quality"] * 50)
            print(f"   Cycle {h['cycle']}: {bar} {h['overall_quality']*100:.1f}%")
        
        # Performance metrics
        metrics = self.robot.get_advanced_metrics()
        
        print(f"\n‚ö° Performance Metrics:")
        print(f"   ‚Ä¢ API Keys used: {metrics['api_keys']['total_keys']}")
        print(f"   ‚Ä¢ Total requests: {metrics['api_keys']['total_requests']}")
        print(f"   ‚Ä¢ Cache hit rate: {metrics['cache'].get('hit_rate', 0)}")
        print(f"   ‚Ä¢ Parallel workers: {metrics['performance']['parallel_workers']}")
        
        # Success determination
        success = final_quality >= self.target_success_rate
        
        if success:
            print(f"\nüéâ SUCCESS! Agent achieved {self.target_success_rate*100:.0f}% quality target!")
        else:
            print(f"\n‚ö†Ô∏è  Target not reached. Final quality: {final_quality*100:.1f}%")
            if self.current_cycle >= 5:
                print(f"üö® ESCALATION: Manual intervention recommended")
        
        print("=" * 80)
        
        return {
            "success": success,
            "cycles": self.current_cycle,
            "duration": total_duration,
            "final_quality": final_quality,
            "target_quality": self.target_success_rate,
            "files_analyzed": total_files,
            "issues_found": total_issues,
            "fixes_applied": total_fixes,
            "history": self.history
        }


async def main():
    """Run autonomous agent"""
    
    project_root = Path("d:/bybit_strategy_tester_v2")
    
    agent = AutonomousAgent(project_root)
    
    report = await agent.run_until_perfect()
    
    # Save report to file
    report_path = project_root / "autonomous_agent_report.json"
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2)
    
    print(f"\nüìÑ Report saved to: {report_path}")


if __name__ == "__main__":
    asyncio.run(main())
