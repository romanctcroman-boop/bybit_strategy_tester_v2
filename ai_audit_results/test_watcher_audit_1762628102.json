{
  "timestamp": 1762628102,
  "changed_files": [
    "add_provider_ready_decorator.py",
    "mcp-server\\server.py"
  ],
  "test_results": {
    "pytest_exit_code": -1,
    "coverage_total": 0,
    "coverage_by_file": {},
    "timestamp": 1762628088.6684844,
    "success": false,
    "error": "'CoverageData' object has no attribute 'covered_lines'"
  },
  "analysis_results": {
    "analysis": "## Test Quality Assessment\n**CRITICAL FAILURE** - Test suite failed to execute (Exit Code -1). This indicates either catastrophic test infrastructure issues or severe code defects preventing test execution. No meaningful quality assessment possible until basic test execution is resolved.\n\n## Coverage Analysis\n**0% coverage** - Tests didn't run successfully. Coverage data is unavailable, making gap analysis impossible. This is a severe regression.\n\n## Potential Issues with Recent Changes\nThe changes in `add_provider_ready_decorator.py` and `mcp-server\\server.py` likely introduced:\n- **Syntax errors** preventing import/execution\n- **Circular imports** or module loading issues\n- **Missing dependencies** or broken imports\n- **Runtime errors** during test setup/import\n\n## Immediate Recommendations\n1. **Fix Test Execution First**\n   - Check Python syntax in both changed files\n   - Verify imports and dependencies\n   - Run tests with `-v` flag to see where they fail\n\n2. **Debug Sequence**\n   ```bash\n   python -m py_compile add_provider_ready_decorator.py\n   python -m py_compile mcp-server/server.py\n   python -c \"import add_provider_ready_decorator\"  # Test imports\n   ```\n\n3. **Restore Baseline**\n   - Revert changes if possible to confirm tests pass\n   - Add changes incrementally with test validation at each step\n\n## Risk Assessment\n**HIGH RISK** - Code is completely untested and potentially broken. Deployment would be extremely risky. This represents a critical failure in the development workflow that must be addressed before any further development.\n\n**Priority:** Fix test execution immediately before any other quality metrics can be assessed.",
    "model": "deepseek-chat",
    "usage": {
      "prompt_tokens": 136,
      "completion_tokens": 356,
      "total_tokens": 492,
      "prompt_tokens_details": {
        "cached_tokens": 64
      },
      "prompt_cache_hit_tokens": 64,
      "prompt_cache_miss_tokens": 72
    },
    "success": true
  },
  "metadata": {
    "watch_path": "D:\\bybit_strategy_tester_v2",
    "debounce_seconds": 20
  }
}