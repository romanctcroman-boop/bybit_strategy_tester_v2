{
  "timestamp": 1762542132,
  "changed_files": [
    "tests\\monitoring\\test_metrics_export.py",
    "automation\\metrics\\collectors\\system_collector.py"
  ],
  "test_results": {
    "pytest_exit_code": -1,
    "coverage_total": 0,
    "coverage_by_file": {},
    "timestamp": 1762542117.9544919,
    "success": false,
    "error": "redirected stdin is pseudofile, has no fileno()"
  },
  "analysis_results": {
    "analysis": "Based on the test results, here are the key insights:\n\n## 1. Test Quality Assessment\n**Critical Failure** - Exit code -1 indicates a fatal error during test execution, not just test failures. The test suite didn't complete execution.\n\n## 2. Coverage Analysis\n**Complete Failure** - 0% coverage suggests:\n- Tests couldn't execute due to fatal errors\n- No code paths were exercised\n- Likely import/initialization failures\n\n## 3. Potential Issues with Recent Changes\n**Primary Suspects:**\n- **Import cycles** between test files and modified modules\n- **Syntax errors** in `system_collector.py` preventing module loading\n- **Missing dependencies** or broken imports in the modified files\n- **Configuration issues** in test setup/teardown\n\n## 4. Immediate Recommendations\n1. **Fix Import/Syntax Issues First**\n   - Check `system_collector.py` for syntax errors\n   - Verify imports in both changed files\n   - Run `python -m py_compile` on modified files\n\n2. **Isolate the Problem**\n   - Run tests for each changed file individually\n   - Check test file imports and fixtures\n   - Verify no circular dependencies\n\n3. **Debug Step-by-Step**\n   - Add `print()` statements at module level to trace execution\n   - Check test discovery configuration\n   - Verify pytest configuration files\n\n## 5. Risk Assessment\n**HIGH RISK** - Complete test suite failure indicates:\n- Production code may be broken\n- No validation of recent changes\n- Potential deployment blockers\n- Requires immediate attention before any further development\n\n**Priority:** Fix test execution before addressing coverage or adding new tests.",
    "model": "deepseek-chat",
    "usage": {
      "prompt_tokens": 144,
      "completion_tokens": 352,
      "total_tokens": 496,
      "prompt_tokens_details": {
        "cached_tokens": 64
      },
      "prompt_cache_hit_tokens": 64,
      "prompt_cache_miss_tokens": 80
    },
    "success": true
  },
  "metadata": {
    "watch_path": "D:\\bybit_strategy_tester_v2",
    "debounce_seconds": 20
  }
}