# ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —á–µ—Ä–µ–∑ Copilot ‚Üî Perplexity AI

**–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ ML –∏ AI**

## üéØ –û–ø–∏—Å–∞–Ω–∏–µ

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è ML-–±–∏–±–ª–∏–æ—Ç–µ–∫ (CatBoost, XGBoost, LightGBM) —Å Perplexity AI –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –Ω–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞—Ö.

### –°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã

```
Copilot ‚Üí Scripts ‚Üí Perplexity AI (MCP Server) ‚Üí ML-Optimization ‚Üí Copilot
    ‚Üì                                                      ‚Üë
   –ó–∞–ø—Ä–æ—Å                                            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```powershell
# ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
pip install -r requirements-ml.txt
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Perplexity API

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:

```env
PERPLEXITY_API_KEY=pplx-your-api-key-here
```

### 3. –ó–∞–ø—É—Å–∫ E2E —Ç–µ—Å—Ç–∞

```powershell
python test_ml_optimization_e2e.py
```

## üì¶ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

### ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏

| –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –í–µ—Ä—Å–∏—è | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|------------|--------|------------|
| **CatBoost** | ‚â•1.2.5 | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, DCA —Å—Ç—Ä–∞—Ç–µ–≥–∏–π |
| **XGBoost** | ‚â•2.0.3 | Grid/Bayes –ø–æ–∏—Å–∫, —Å–µ—Ç–æ—á–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ |
| **LightGBM** | ‚â•4.3.0 | –°–∫–æ—Ä–æ—Å—Ç–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö |
| **scikit-learn** | ‚â•1.4.2 | Grid/Random Search, –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è |
| **Optuna** | ‚â•3.6.1 | Bayesian Optimization |

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
backend/ml/
‚îú‚îÄ‚îÄ __init__.py              # ML-–º–æ–¥—É–ª—å
‚îú‚îÄ‚îÄ optimizer.py             # ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã (CatBoost/XGBoost/LightGBM)
‚îî‚îÄ‚îÄ prompts.py               # –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è Perplexity

ml_optimizer_perplexity.py   # –°–∫—Ä–∏–ø—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å Perplexity AI
test_ml_optimization_e2e.py  # E2E —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
requirements-ml.txt          # ML-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
```

## üí° –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

```python
import asyncio
from backend.core.backtest_engine import BacktestEngine
import pandas as pd

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
data = pd.read_csv('btc_usdt_1h.csv')

# –°–æ–∑–¥–∞—Ç—å –¥–≤–∏–∂–æ–∫
engine = BacktestEngine(initial_capital=10_000)

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
async def optimize():
    result = await engine.auto_optimize(
        data=data,
        strategy_type='sr_rsi',          # 'sr_rsi', 'ema_crossover', 'scalping'
        optimization_goal='sharpe_ratio', # 'sharpe_ratio', 'win_rate', 'total_return'
        quick_mode=False                  # False = —Ç–æ—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (100 –∏—Ç–µ—Ä–∞—Ü–∏–π)
    )
    
    print(f"Best Sharpe: {result['best_score']:.2f}")
    print(f"Best params: {result['best_params']}")
    
    return result

result = asyncio.run(optimize())
```

### –í–∞—Ä–∏–∞–Ω—Ç 2: –†—É—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

```python
# –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
param_space = {
    'sr_lookback': [20, 50, 100, 150, 200],
    'sr_threshold': [0.001, 0.002, 0.005, 0.01],
    'rsi_period': [7, 14, 21, 28],
    'rsi_overbought': [65, 70, 75, 80],
    'rsi_oversold': [20, 25, 30, 35],
    'take_profit_pct': [0.01, 0.02, 0.03, 0.05],
    'stop_loss_pct': [0.005, 0.01, 0.015, 0.02],
}

# –ó–∞–ø—É—Å—Ç–∏—Ç—å ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
async def manual_optimize():
    result = await engine.ml_optimize(
        data=data,
        param_space=param_space,
        optimization_goal='sharpe_ratio',
        ml_library='catboost',  # 'catboost', 'xgboost', 'lightgbm', 'hybrid'
        method='bayes',         # 'grid', 'random', 'bayes'
        n_trials=100,
        n_jobs=-1               # -1 = –≤—Å–µ —è–¥—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
    )
    
    # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    result['optimization_result'].save_to_file('optimization_result.json')
    
    return result

result = asyncio.run(manual_optimize())
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ —á–µ—Ä–µ–∑ Perplexity AI

```python
import asyncio
from ml_optimizer_perplexity import PerplexityMLOptimizer

async def generate_optimization_code():
    async with PerplexityMLOptimizer() as perplexity:
        
        # –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        code = await perplexity.generate_optimization_code(
            strategy_description="SR/RSI —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Å –ø—Ä–æ–±–æ–µ–º —É—Ä–æ–≤–Ω–µ–π",
            param_space={'rsi_period': [14, 21], 'sr_lookback': [50, 100]},
            optimization_goal='Sharpe Ratio',
            ml_library='catboost'
        )
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–æ–¥
        with open('generated_optimizer.py', 'w') as f:
            f.write(code)
        
        print(f"‚úÖ –ö–æ–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω ({len(code)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results_json = '{"sharpe": 1.8, "win_rate": 62.5}'
        
        analysis = await perplexity.analyze_optimization_results(
            results_json=results_json,
            strategy_description="SR/RSI —Å—Ç—Ä–∞—Ç–µ–≥–∏—è"
        )
        
        print(analysis)

asyncio.run(generate_optimization_code())
```

## üîß ML-–æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã

### CatBoostOptimizer (—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –Ø–Ω–¥–µ–∫—Å–∞)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –í—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- ‚úÖ –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –ü—Ä–æ—Å—Ç–æ–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤, DCA —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

```python
from backend.ml.optimizer import CatBoostOptimizer

optimizer = CatBoostOptimizer(
    objective_function=my_backtest_function,
    param_space=param_space,
    n_jobs=-1
)

result = await optimizer.optimize(n_trials=100, method='bayes')
```

### XGBoostOptimizer (—Å–∞–º–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ 2025)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å —Å–µ—Ç–æ—á–Ω—ã–º–∏ –∏ DCA —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏
- ‚úÖ –•–æ—Ä–æ—à–∞—è –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ GridSearch –∏ early-stopping

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –ü–æ–∏—Å–∫ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞, —Å–µ—Ç–æ–∫

### LightGBMOptimizer (–¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ –°–∞–º–∞—è –≤—ã—Å–æ–∫–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –†–∞–±–æ—Ç–∞ —Å –±–æ–ª—å—à–∏–º–∏ –º–∞—Å—Å–∏–≤–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –ù–∏–∑–∫–æ–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –°–∫–æ—Ä–æ—Å—Ç–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å –±–æ–ª—å—à–∏–º –æ–±—ä–µ–º–æ–º –¥–∞–Ω–Ω—ã—Ö

### HybridOptimizer (–∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö –º–µ—Ç–æ–¥–æ–≤)

**–°—Ç—Ä–∞—Ç–µ–≥–∏—è:**
1. 20% –±—é–¥–∂–µ—Ç–∞ ‚Üí Random Search (–≥—Ä—É–±—ã–π –ø–æ–∏—Å–∫)
2. 50% –±—é–¥–∂–µ—Ç–∞ ‚Üí Bayesian Optimization (—É–º–Ω—ã–π –ø–æ–∏—Å–∫)
3. 30% –±—é–¥–∂–µ—Ç–∞ ‚Üí Local Grid Search (–ª–æ–∫–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)

**–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:** –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–ª–æ–∂–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

## üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### OptimizationResult

```python
@dataclass
class OptimizationResult:
    best_params: Dict[str, Any]          # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    best_score: float                     # –õ—É—á—à–∞—è –º–µ—Ç—Ä–∏–∫–∞
    all_results: pd.DataFrame             # –í—Å–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏
    optimization_time: float              # –í—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Å–µ–∫)
    method: str                           # –ú–µ—Ç–æ–¥ ('grid', 'bayes', 'random')
    iterations: int                       # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
    
    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    feature_importance: Dict[str, float]  # –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    convergence_history: List[float]      # –ò—Å—Ç–æ—Ä–∏—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
    top_n_configs: List[Dict]             # –¢–æ–ø-N –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    
    # –ú–µ—Ç—Ä–∏–∫–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    sharpe_ratio: float
    max_drawdown: float
    win_rate: float
    profit_factor: float
    total_return: float
```

### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ JSON + CSV
result.save_to_file('optimization_result.json')

# –°–æ–∑–¥–∞—é—Ç—Å—è —Ñ–∞–π–ª—ã:
# - optimization_result.json (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
# - optimization_result_full_results.csv (–≤—Å–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏)
```

## üß† Perplexity AI –ø—Ä–æ–º–ø—Ç—ã

### –ì–æ—Ç–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã

```python
from backend.ml.prompts import (
    get_optimization_prompt,        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    get_feature_engineering_prompt, # Feature engineering
    get_analysis_prompt,            # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    get_new_strategies_prompt,      # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
prompt = get_optimization_prompt(
    strategy_description="SR/RSI —Å—Ç—Ä–∞—Ç–µ–≥–∏—è",
    param_space={'rsi': [14, 21]},
    optimization_goal="Sharpe Ratio",
    ml_library="catboost"
)
```

### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–æ–º–ø—Ç—ã

- `WALK_FORWARD_TEMPLATE` - Walk-Forward –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è
- `ENSEMBLE_STRATEGIES_TEMPLATE` - –ê–Ω—Å–∞–º–±–ª—å —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
- `RISK_MANAGEMENT_TEMPLATE` - ML-—Å–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∏—Å–∫–∞–º–∏
- `MARKET_REGIME_DETECTION_TEMPLATE` - ML-–¥–µ—Ç–µ–∫—Ç–æ—Ä —Ä—ã–Ω–æ—á–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
- `HYPERPARAMETER_SEARCH_TEMPLATE` - Multi-objective –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

## üéì –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è SR/RSI —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

```python
# 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
data = pd.read_csv('btc_1h.csv', parse_dates=['timestamp'])

# 2. –°–æ–∑–¥–∞—Ç—å –¥–≤–∏–∂–æ–∫
engine = BacktestEngine(initial_capital=10_000)

# 3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å
result = await engine.auto_optimize(
    data=data,
    strategy_type='sr_rsi',
    optimization_goal='sharpe_ratio'
)

# 4. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
best_config = {'type': 'sr_rsi', **result['best_params']}
final_results = engine.run(data, best_config)
```

### –ü—Ä–∏–º–µ—Ä 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ ML-–±–∏–±–ª–∏–æ—Ç–µ–∫

```python
libraries = ['catboost', 'xgboost', 'lightgbm']
results = {}

for lib in libraries:
    result = await engine.ml_optimize(
        data=data,
        param_space=param_space,
        ml_library=lib,
        method='bayes',
        n_trials=50
    )
    results[lib] = result

# –ù–∞–π—Ç–∏ –ª—É—á—à—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É
best_lib = max(results.items(), key=lambda x: x[1]['best_score'])
print(f"Best library: {best_lib[0]} (Sharpe: {best_lib[1]['best_score']:.2f})")
```

### –ü—Ä–∏–º–µ—Ä 3: Walk-Forward –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

```python
# –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø–µ—Ä–∏–æ–¥—ã
periods = [
    data.iloc[:300],   # In-Sample
    data.iloc[300:400], # Out-Of-Sample
    data.iloc[400:],    # Forward Test
]

results = []

for i, period_data in enumerate(periods):
    result = await engine.auto_optimize(
        data=period_data,
        strategy_type='sr_rsi',
        quick_mode=True
    )
    results.append(result)
    print(f"Period {i+1} Sharpe: {result['best_score']:.2f}")

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å
sharpes = [r['best_score'] for r in results]
print(f"Sharpe —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å: {np.std(sharpes):.2f}")
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

### –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|---------|----------|------------|
| `sharpe_ratio` | Risk-adjusted return | –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ |
| `sortino_ratio` | Downside risk —Ç–æ–ª—å–∫–æ | –î–ª—è –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π |
| `win_rate` | % –≤—ã–∏–≥—Ä—ã—à–Ω—ã—Ö —Å–¥–µ–ª–æ–∫ | –î–ª—è —Å–∫–∞–ª—å–ø–∏–Ω–≥–∞ |
| `profit_factor` | Gross Profit / Gross Loss | –î–ª—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π |
| `total_return` | –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å | –î–ª—è long-term —Å—Ç—Ä–∞—Ç–µ–≥–∏–π |
| `max_drawdown` | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞ | –ú–∏–Ω–∏–º–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–∞ |

### –®—Ç—Ä–∞—Ñ—ã –∑–∞ –º–∞–ª–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫

```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è —à—Ç—Ä–∞—Ñ—ã:
if total_trades < 10:
    score *= 0.1  # –°–∏–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ
elif total_trades < 30:
    score *= 0.5  # –°—Ä–µ–¥–Ω–∏–π —à—Ç—Ä–∞—Ñ
```

## üîç –û—Ç–ª–∞–¥–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑

### –ü—Ä–æ—Å–º–æ—Ç—Ä –∏—Å—Ç–æ—Ä–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏

```python
# –ü–æ–ª—É—á–∏—Ç—å DataFrame —Å–æ –≤—Å–µ–º–∏ –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
history = optimizer.get_optimization_history()

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
plt.plot(history['score'])
plt.title('Convergence History')
plt.xlabel('Iteration')
plt.ylabel('Sharpe Ratio')
plt.show()
```

### –¢–æ–ø-N –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π

```python
# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–ø-10 –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
top_configs = result.top_n_configs

for i, config in enumerate(top_configs, 1):
    print(f"{i}. Score: {config['score']:.2f}")
    print(f"   Params: {config}")
```

### Feature Importance

```python
# –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
if result.feature_importance:
    for param, importance in result.feature_importance.items():
        print(f"{param}: {importance:.3f}")
```

## ‚ö†Ô∏è –í–∞–∂–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è

### –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

1. **Walk-Forward –≤–∞–ª–∏–¥–∞—Ü–∏—è** –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞ –¥–ª—è production
2. **Out-Of-Sample —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ** –Ω–∞ 20-30% –¥–∞–Ω–Ω—ã—Ö
3. **–ú–∏–Ω–∏–º—É–º 30+ —Å–¥–µ–ª–æ–∫** –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏
4. **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤** —á–µ—Ä–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞

### –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

| –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö | ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ | –ú–µ—Ç–æ–¥ | –ò—Ç–µ—Ä–∞—Ü–∏–π |
|---------------|---------------|-------|----------|
| < 500 –±–∞—Ä–æ–≤ | LightGBM | Random | 30 |
| 500-2000 –±–∞—Ä–æ–≤ | XGBoost | Bayes | 50-100 |
| > 2000 –±–∞—Ä–æ–≤ | CatBoost | Bayes | 100-200 |
| –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è | Hybrid | Mixed | 150-300 |

### –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

```python
# –ü–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
result = await engine.ml_optimize(
    ...,
    n_jobs=-1  # –í—Å–µ —è–¥—Ä–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
)

# –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
result = await engine.auto_optimize(
    ...,
    quick_mode=True  # 30 –∏—Ç–µ—Ä–∞—Ü–∏–π –≤–º–µ—Å—Ç–æ 100
)
```

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```powershell
pip install -r requirements-ml.txt
```

### 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Perplexity API

–ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –Ω–∞ [perplexity.ai](https://perplexity.ai) –∏ –¥–æ–±–∞–≤—å—Ç–µ –≤ `.env`

### 3. –ó–∞–ø—É—Å–∫ –¥–µ–º–æ

```powershell
# E2E —Ç–µ—Å—Ç
python test_ml_optimization_e2e.py

# –î–µ–º–æ Perplexity –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
python ml_optimizer_perplexity.py
```

### 4. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ production

```python
# –í–∞—à production –∫–æ–¥
from backend.core.backtest_engine import BacktestEngine

engine = BacktestEngine()
result = await engine.auto_optimize(data, strategy_type='sr_rsi')

# –ü—Ä–∏–º–µ–Ω–∏—Ç—å –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
best_strategy = {'type': 'sr_rsi', **result['best_params']}
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [CatBoost Documentation](https://catboost.ai/docs/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [Perplexity AI API](https://docs.perplexity.ai/)

## üéØ –ü—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã 2025 –≥–æ–¥–∞

–í—Å–µ ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ —Ç–µ—Ö–Ω–∏–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–π–¥–µ—Ä–æ–≤ –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –≤ 2025 –≥–æ–¥—É.

---

**–°–æ–∑–¥–∞–Ω–æ:** Copilot —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å Perplexity AI  
**–°—Ö–µ–º–∞ —Ä–∞–±–æ—Ç—ã:** Copilot ‚Üî Perplexity AI (MCP Server) ‚Üî Copilot
