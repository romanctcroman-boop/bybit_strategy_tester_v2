"""
–ü–æ–ª–Ω—ã–π –∞—É–¥–∏—Ç –ø—Ä–æ–µ–∫—Ç–∞ Bybit Strategy Tester v2 —á–µ—Ä–µ–∑ DeepSeek –∏ Perplexity AI
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è 4 —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∑–∞–¥–∞–Ω–∏—è–º:
1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_1.md
2. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_2.md  
3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-1.md
4. –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-2.md
"""

import asyncio
import httpx
import json
from datetime import datetime
from pathlib import Path
import time

# API Configuration
DEEPSEEK_API_KEY = "sk-1630fbba63c64f88952c16ad33337242"
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"

PERPLEXITY_API_KEY = "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"
PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"

# Project paths
PROJECT_ROOT = Path(r"D:\bybit_strategy_tester_v2")
TZ_DIR = Path(r"D:\PERP\Demo")

# Output
RESULTS_FILE = PROJECT_ROOT / "FULL_TZ_AUDIT_RESULTS.json"
REPORT_FILE = PROJECT_ROOT / "FULL_TZ_AUDIT_REPORT.md"


class ProjectAnalyzer:
    def __init__(self):
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "tz_documents": [],
            "deepseek_analysis": {},
            "perplexity_analysis": {},
            "compliance_matrix": {},
            "critical_gaps": [],
            "recommendations": [],
            "total_tokens": 0
        }
    
    async def load_tz_documents(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö 4 –¢–ó –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        tz_files = [
            "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_1.md",
            "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_2.md",
            "–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-1.md",
            "–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-2.md"
        ]
        
        tz_content = {}
        for filename in tz_files:
            filepath = TZ_DIR / filename
            if filepath.exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    content = f.read()
                    tz_content[filename] = content
                    self.results["tz_documents"].append({
                        "name": filename,
                        "size": len(content),
                        "loaded": True
                    })
                    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {filename} ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            else:
                print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω: {filename}")
                self.results["tz_documents"].append({
                    "name": filename,
                    "loaded": False,
                    "error": "File not found"
                })
        
        return tz_content
    
    async def scan_project_structure(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞"""
        structure = {
            "backend": [],
            "frontend": [],
            "mcp_server": [],
            "scripts": [],
            "tests": [],
            "docs": []
        }
        
        # Backend
        backend_dir = PROJECT_ROOT / "backend"
        if backend_dir.exists():
            structure["backend"] = [f.name for f in backend_dir.rglob("*.py")][:50]
        
        # Frontend
        frontend_dir = PROJECT_ROOT / "frontend"
        if frontend_dir.exists():
            structure["frontend"] = [f.name for f in frontend_dir.rglob("*.tsx")][:30]
        
        # MCP Server
        mcp_dir = PROJECT_ROOT / "mcp-server"
        if mcp_dir.exists():
            structure["mcp_server"] = [f.name for f in mcp_dir.rglob("*.py")][:20]
        
        # Scripts
        scripts_dir = PROJECT_ROOT / "scripts"
        if scripts_dir.exists():
            structure["scripts"] = [f.name for f in scripts_dir.glob("*.py")][:20]
        
        return structure
    
    async def deepseek_api_call(self, prompt: str, context: str = "") -> dict:
        """–†–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ DeepSeek API"""
        full_prompt = f"{context}\n\n{prompt}" if context else prompt
        
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞–Ω–∏–π. –ü—Ä–æ–≤–æ–¥–∏ –≥–ª—É–±–æ–∫–∏–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑."
                },
                {
                    "role": "user",
                    "content": full_prompt
                }
            ],
            "temperature": 0.7,
            "max_tokens": 4000
        }
        
        headers = {
            "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
            "Content-Type": "application/json"
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(DEEPSEEK_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()
            
            self.results["total_tokens"] += result.get("usage", {}).get("total_tokens", 0)
            return result
    
    async def perplexity_api_call(self, query: str, context: str = "") -> dict:
        """–†–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ Perplexity AI Sonar Pro"""
        full_query = f"{context}\n\n{query}" if context else query
        
        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤, –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–º —Å–∏—Å—Ç–µ–º–∞–º –∏ —Ç–æ—Ä–≥–æ–≤—ã–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º."
                },
                {
                    "role": "user",
                    "content": full_query
                }
            ],
            "temperature": 0.3,
            "max_tokens": 4000
        }
        
        headers = {
            "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
            "Content-Type": "application/json"
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(PERPLEXITY_API_URL, json=payload, headers=headers)
            response.raise_for_status()
            result = response.json()
            
            self.results["total_tokens"] += result.get("usage", {}).get("total_tokens", 0)
            return result
    
    async def analyze_tz1_compliance(self, tz_content: str, project_structure: dict):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó-1: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ü—Ä–æ—Ç–æ–∫–æ–ª—ã, –û—á–µ—Ä–µ–¥–∏, –í–æ—Ä–∫–µ—Ä—ã"""
        print("\n" + "="*80)
        print("üìã –ê–ù–ê–õ–ò–ó –¢–ó-1: MCP Protocol, Redis Streams, –í–æ—Ä–∫–µ—Ä—ã")
        print("="*80)
        
        # DeepSeek: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        deepseek_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –ø—Ä–æ–µ–∫—Ç Bybit Strategy Tester v2 –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó-1.

–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï (–¢–ó-1):
{tz_content[:8000]}

–°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:
{json.dumps(project_structure, indent=2)}

–ö–†–ò–¢–ï–†–ò–ò –ü–†–û–í–ï–†–ö–ò:
1. JSON-RPC 2.0 –ø—Ä–æ—Ç–æ–∫–æ–ª (FastAPI)
2. Redis Streams –¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π (mcp_tasks)
3. Consumer Groups –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
4. Celery/ARQ –¥–ª—è CPU/ML –∑–∞–¥–∞—á
5. Async worker pool
6. SLA-driven autoscaling
7. Signal Routing Layer
8. Saga Pattern —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è–º–∏
9. Checkpoint Recovery

–í–´–ü–û–õ–ù–ò:
1. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–ª–∏—á–∏–µ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
2. –û—Ü–µ–Ω–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é (0-10)
3. –£–∫–∞–∂–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–µ–ª—ã
4. –î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ö–æ–º–ø–æ–Ω–µ–Ω—Ç: [–Ω–∞–∑–≤–∞–Ω–∏–µ]
- –°—Ç–∞—Ç—É—Å: [IMPLEMENTED/PARTIAL/NOT_IMPLEMENTED]
- –û—Ü–µ–Ω–∫–∞: [0-10]
- –ü—Ä–æ–±–ª–µ–º—ã: [—Å–ø–∏—Å–æ–∫]
- –ö–æ–¥ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: [–µ—Å–ª–∏ –Ω—É–∂–Ω–æ]
"""
        
        try:
            print("ü§ñ DeepSeek –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¢–ó-1...")
            deepseek_result = await self.deepseek_api_call(deepseek_prompt)
            deepseek_analysis = deepseek_result["choices"][0]["message"]["content"]
            
            self.results["deepseek_analysis"]["tz1"] = {
                "prompt_tokens": deepseek_result["usage"]["prompt_tokens"],
                "completion_tokens": deepseek_result["usage"]["completion_tokens"],
                "analysis": deepseek_analysis
            }
            
            print(f"‚úÖ DeepSeek –∑–∞–≤–µ—Ä—à–∏–ª –∞–Ω–∞–ª–∏–∑ –¢–ó-1")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {deepseek_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ DeepSeek: {e}")
            self.results["deepseek_analysis"]["tz1"] = {"error": str(e)}
        
        await asyncio.sleep(2)
        
        # Perplexity: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–º–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º–∏
        perplexity_query = f"""
–ü—Ä–æ–≤–µ—Ä—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ–µ–∫—Ç–∞ Bybit Strategy Tester v2 —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ 2025 –≥–æ–¥–∞.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –¢–ó-1:
- JSON-RPC 2.0 –ø—Ä–æ—Ç–æ–∫–æ–ª
- Redis Streams —Å Consumer Groups
- Saga Pattern –¥–ª—è long-running workflows
- SLA-driven autoscaling
- Checkpoint Recovery

–°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:
Backend: {len(project_structure['backend'])} —Ñ–∞–π–ª–æ–≤
MCP Server: {len(project_structure['mcp_server'])} —Ñ–∞–π–ª–æ–≤

–ó–ê–î–ê–ß–ê:
1. –°—Ä–∞–≤–Ω–∏ —Å best practices –∏–Ω–¥—É—Å—Ç—Ä–∏–∏
2. –û—Ü–µ–Ω–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—É—é –∑—Ä–µ–ª–æ—Å—Ç—å (1-10)
3. –£–∫–∞–∂–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏
4. –ü—Ä–µ–¥–ª–æ–∂–∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –∏ —É–ª—É—á—à–µ–Ω–∏—è

–ò—Å–ø–æ–ª—å–∑—É–π –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ MCP Protocol, Redis Streams patterns, Saga orchestration.
"""
        
        try:
            print("üîç Perplexity AI –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã...")
            perplexity_result = await self.perplexity_api_call(perplexity_query)
            perplexity_analysis = perplexity_result["choices"][0]["message"]["content"]
            
            self.results["perplexity_analysis"]["tz1"] = {
                "prompt_tokens": perplexity_result["usage"]["prompt_tokens"],
                "completion_tokens": perplexity_result["usage"]["completion_tokens"],
                "analysis": perplexity_analysis
            }
            
            print(f"‚úÖ Perplexity –∑–∞–≤–µ—Ä—à–∏–ª –∞–Ω–∞–ª–∏–∑ –¢–ó-1")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {perplexity_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Perplexity: {e}")
            self.results["perplexity_analysis"]["tz1"] = {"error": str(e)}
    
    async def analyze_tz2_compliance(self, tz_content: str, project_structure: dict):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó-2: Sandbox, Security, SLA/–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        print("\n" + "="*80)
        print("üîí –ê–ù–ê–õ–ò–ó –¢–ó-2: Sandbox Security, SLA, –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        print("="*80)
        
        # DeepSeek: Security audit
        deepseek_prompt = f"""
–ü—Ä–æ–≤–µ–¥–∏ security audit –ø—Ä–æ–µ–∫—Ç–∞ Bybit Strategy Tester v2 –ø–æ –¢–ó-2.

–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï (–¢–ó-2):
{tz_content[:8000]}

–°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:
{json.dumps(project_structure, indent=2)}

–ö–†–ò–¢–ï–†–ò–ò –ü–†–û–í–ï–†–ö–ò:
1. Docker/gVisor sandbox –¥–ª—è AI-–∫–æ–¥–∞
2. –°–µ—Ç–µ–≤–∞—è –∏–∑–æ–ª—è—Ü–∏—è, read-only FS
3. Syscall auditing
4. Prometheus + Grafana –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
5. OpenTelemetry distributed tracing
6. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ (Saga compensation)
7. SIEM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
8. Multi-tenancy isolation
9. Threat modeling

–í–´–ü–û–õ–ù–ò:
1. –û—Ü–µ–Ω–∏ —É—Ä–æ–≤–µ–Ω—å –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (0-10)
2. –ù–∞–π–¥–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–∏
3. –ü—Ä–æ–≤–µ—Ä—å SLA monitoring
4. –î–∞–π –∫–æ–¥ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º

–§–æ—Ä–º–∞—Ç: –∫–æ–º–ø–æ–Ω–µ–Ω—Ç ‚Üí —Å—Ç–∞—Ç—É—Å ‚Üí –æ—Ü–µ–Ω–∫–∞ ‚Üí –ø—Ä–æ–±–ª–µ–º—ã ‚Üí –∫–æ–¥
"""
        
        try:
            print("ü§ñ DeepSeek –ø—Ä–æ–≤–æ–¥–∏—Ç security audit...")
            deepseek_result = await self.deepseek_api_call(deepseek_prompt)
            deepseek_analysis = deepseek_result["choices"][0]["message"]["content"]
            
            self.results["deepseek_analysis"]["tz2"] = {
                "prompt_tokens": deepseek_result["usage"]["prompt_tokens"],
                "completion_tokens": deepseek_result["usage"]["completion_tokens"],
                "analysis": deepseek_analysis
            }
            
            print(f"‚úÖ DeepSeek –∑–∞–≤–µ—Ä—à–∏–ª security audit")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {deepseek_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ DeepSeek: {e}")
            self.results["deepseek_analysis"]["tz2"] = {"error": str(e)}
        
        await asyncio.sleep(2)
        
        # Perplexity: Best practices 2025
        perplexity_query = f"""
–û—Ü–µ–Ω–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ Bybit Strategy Tester v2 –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º 2025 –≥–æ–¥–∞.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –¢–ó-2:
- Sandbox execution (Docker-in-Docker, gVisor, Firecracker)
- Prometheus/Grafana/OpenTelemetry
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ
- Multi-tenancy
- Threat modeling

–ü–†–û–í–ï–†–¨:
1. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ OWASP Top 10 –¥–ª—è AI —Å–∏—Å—Ç–µ–º
2. Zero Trust Architecture –ø—Ä–∏–Ω—Ü–∏–ø—ã
3. Observability best practices (OpenTelemetry, Grafana)
4. Incident response automation

–î–∞–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π.
"""
        
        try:
            print("üîç Perplexity AI –ø—Ä–æ–≤–µ—Ä—è–µ—Ç security —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã...")
            perplexity_result = await self.perplexity_api_call(perplexity_query)
            perplexity_analysis = perplexity_result["choices"][0]["message"]["content"]
            
            self.results["perplexity_analysis"]["tz2"] = {
                "prompt_tokens": perplexity_result["usage"]["prompt_tokens"],
                "completion_tokens": perplexity_result["usage"]["completion_tokens"],
                "analysis": perplexity_analysis
            }
            
            print(f"‚úÖ Perplexity –∑–∞–≤–µ—Ä—à–∏–ª security –∞–Ω–∞–ª–∏–∑")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {perplexity_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Perplexity: {e}")
            self.results["perplexity_analysis"]["tz2"] = {"error": str(e)}
    
    async def analyze_tz3_compliance(self, tz_content_3_1: str, tz_content_3_2: str, project_structure: dict):
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¢–ó-3: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è"""
        print("\n" + "="*80)
        print("ü§ñ –ê–ù–ê–õ–ò–ó –¢–ó-3: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π")
        print("="*80)
        
        # DeepSeek: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        deepseek_prompt = f"""
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Bybit Strategy Tester v2 –ø–æ –¢–ó-3.

–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï (–¢–ó-3.1):
{tz_content_3_1[:6000]}

–¢–ï–•–ù–ò–ß–ï–°–ö–û–ï –ó–ê–î–ê–ù–ò–ï (–¢–ó-3.2):
{tz_content_3_2[:6000]}

–°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê:
{json.dumps(project_structure, indent=2)}

–¢–†–ï–ë–£–ï–ú–´–ï –ê–ì–ï–ù–¢–´:
1. MCP Server (—Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä)
2. Reasoning-–∞–≥–µ–Ω—Ç—ã (Perplexity AI)
3. Code generation (DeepSeek)
4. ML-–∞–≥–µ–Ω—Ç—ã/AutoML
5. User Behavior/Trader Psychology Agent
6. Sandbox execution
7. User-control interface

–ö–†–ò–¢–ï–†–ò–ò:
1. –ù–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö 7 –∞–≥–µ–Ω—Ç–æ–≤
2. Pipeline: –∏–¥–µ—è ‚Üí reasoning ‚Üí codegen ‚Üí ML ‚Üí backtest ‚Üí review
3. Chain-of-thought logging
4. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (user feedback)
5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∫–æ–¥–∞
6. Behavioral simulation (–ø—Ä–æ—Ñ–∏–ª–∏ —Ç—Ä–µ–π–¥–µ—Ä–æ–≤)
7. Knowledge base –¥–ª—è reasoning

–í–´–ü–û–õ–ù–ò:
1. –ü—Ä–æ–≤–µ—Ä—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é –∫–∞–∂–¥–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
2. –û—Ü–µ–Ω–∏ –ø–æ–ª–Ω–æ—Ç—É pipeline (0-10)
3. –ù–∞–π–¥–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
4. –î–∞–π –∫–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∞–≥–µ–Ω—Ç–æ–≤

–§–æ—Ä–º–∞—Ç: –∞–≥–µ–Ω—Ç ‚Üí —Å—Ç–∞—Ç—É—Å ‚Üí –æ—Ü–µ–Ω–∫–∞ ‚Üí –ø—Ä–æ–±–µ–ª—ã ‚Üí –∫–æ–¥
"""
        
        try:
            print("ü§ñ DeepSeek –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é —Å–∏—Å—Ç–µ–º—É...")
            deepseek_result = await self.deepseek_api_call(deepseek_prompt)
            deepseek_analysis = deepseek_result["choices"][0]["message"]["content"]
            
            self.results["deepseek_analysis"]["tz3"] = {
                "prompt_tokens": deepseek_result["usage"]["prompt_tokens"],
                "completion_tokens": deepseek_result["usage"]["completion_tokens"],
                "analysis": deepseek_analysis
            }
            
            print(f"‚úÖ DeepSeek –∑–∞–≤–µ—Ä—à–∏–ª –∞–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {deepseek_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ DeepSeek: {e}")
            self.results["deepseek_analysis"]["tz3"] = {"error": str(e)}
        
        await asyncio.sleep(2)
        
        # Perplexity: –ò–Ω–¥—É—Å—Ç—Ä–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º
        perplexity_query = f"""
–û—Ü–µ–Ω–∏ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É Bybit Strategy Tester v2 –ø–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø –¢–ó-3:
- Reasoning –∞–≥–µ–Ω—Ç—ã (chain-of-thought, explainable AI)
- Code generation —Å –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π
- AutoML –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- Trader Psychology Agent (–ø—Ä–æ—Ñ–∏–ª–∏: rabbit, wolf, speculator)
- User feedback loops –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
- Knowledge base –¥–ª—è accumulation –æ–ø—ã—Ç–∞

–°–¢–†–£–ö–¢–£–†–ê:
Backend: {len(project_structure['backend'])} —Ñ–∞–π–ª–æ–≤
MCP Server: {len(project_structure['mcp_server'])} —Ñ–∞–π–ª–æ–≤
Frontend: {len(project_structure['frontend'])} —Ñ–∞–π–ª–æ–≤

–ó–ê–î–ê–ß–ê:
1. –°—Ä–∞–≤–Ω–∏ —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ multi-agent frameworks (LangChain, AutoGen, CrewAI)
2. –û—Ü–µ–Ω–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—É—é –∑—Ä–µ–ª–æ—Å—Ç—å (1-10)
3. –ü—Ä–æ–≤–µ—Ä—å explainability –∏ user control
4. –ü—Ä–µ–¥–ª–æ–∂–∏ —É–ª—É—á—à–µ–Ω–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞

–ò—Å–ø–æ–ª—å–∑—É–π –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ multi-agent systems, reasoning chains, behavioral simulation.
"""
        
        try:
            print("üîç Perplexity AI –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã...")
            perplexity_result = await self.perplexity_api_call(perplexity_query)
            perplexity_analysis = perplexity_result["choices"][0]["message"]["content"]
            
            self.results["perplexity_analysis"]["tz3"] = {
                "prompt_tokens": perplexity_result["usage"]["prompt_tokens"],
                "completion_tokens": perplexity_result["usage"]["completion_tokens"],
                "analysis": perplexity_analysis
            }
            
            print(f"‚úÖ Perplexity –∑–∞–≤–µ—Ä—à–∏–ª –∞–Ω–∞–ª–∏–∑ –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {perplexity_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ Perplexity: {e}")
            self.results["perplexity_analysis"]["tz3"] = {"error": str(e)}
    
    async def generate_compliance_matrix(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è"""
        print("\n" + "="*80)
        print("üìä –ì–ï–ù–ï–†–ê–¶–ò–Ø –ú–ê–¢–†–ò–¶–´ –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø")
        print("="*80)
        
        # DeepSeek: –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        summary_prompt = f"""
–ù–∞ –æ—Å–Ω–æ–≤–µ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ–¥—ë–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ —Å–æ–∑–¥–∞–π compliance matrix –ø—Ä–æ–µ–∫—Ç–∞.

–ê–ù–ê–õ–ò–ó–´:
–¢–ó-1 (DeepSeek): {str(self.results['deepseek_analysis'].get('tz1', {}))[:2000]}
–¢–ó-2 (DeepSeek): {str(self.results['deepseek_analysis'].get('tz2', {}))[:2000]}
–¢–ó-3 (DeepSeek): {str(self.results['deepseek_analysis'].get('tz3', {}))[:2000]}

–°–û–ó–î–ê–ô –¢–ê–ë–õ–ò–¶–£:
| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –¢–ó-1 | –¢–ó-2 | –¢–ó-3 | –°—Ç–∞—Ç—É—Å | –û—Ü–µ–Ω–∫–∞ | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|-----------|------|------|------|--------|--------|-----------|
| JSON-RPC  | Req  | -    | Req  | ?      | ?/10   | ?         |
| ...

–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ü–†–û–ë–ï–õ–´ (TOP-5):
1. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç X - –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é
2. ...

–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò (TOP-10 —Å –∫–æ–¥–æ–º):
1. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Redis Streams
```python
[–∫–æ–¥]
```
2. ...

–ò–¢–û–ì–û–í–ê–Ø –û–¶–ï–ù–ö–ê: X/10
–í–†–ï–ú–Ø –î–û PRODUCTION: Y –Ω–µ–¥–µ–ª—å
"""
        
        try:
            print("ü§ñ DeepSeek –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é –º–∞—Ç—Ä–∏—Ü—É...")
            deepseek_result = await self.deepseek_api_call(summary_prompt)
            compliance_matrix = deepseek_result["choices"][0]["message"]["content"]
            
            self.results["compliance_matrix"] = {
                "prompt_tokens": deepseek_result["usage"]["prompt_tokens"],
                "completion_tokens": deepseek_result["usage"]["completion_tokens"],
                "matrix": compliance_matrix
            }
            
            print(f"‚úÖ –ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≥–æ—Ç–æ–≤–∞")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤: {deepseek_result['usage']['total_tokens']}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ DeepSeek: {e}")
            self.results["compliance_matrix"] = {"error": str(e)}
    
    async def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        print("\n" + "="*80)
        print("üíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
        print("="*80)
        
        # JSON results
        with open(RESULTS_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ JSON: {RESULTS_FILE}")
        
        # Markdown report
        report = self.generate_markdown_report()
        with open(REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"‚úÖ Markdown: {REPORT_FILE}")
        
        print(f"\nüìä –í—Å–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {self.results['total_tokens']}")
    
    def generate_markdown_report(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –æ—Ç—á—ë—Ç–∞"""
        report = f"""# üéØ –ü–û–õ–ù–´–ô –ê–£–î–ò–¢ –ü–†–û–ï–ö–¢–ê BYBIT STRATEGY TESTER V2

**–î–∞—Ç–∞**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤**: {self.results['total_tokens']}

---

## üìö –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ó–ê–î–ê–ù–ò–Ø

"""
        for tz in self.results["tz_documents"]:
            status = "‚úÖ" if tz.get("loaded") else "‚ùå"
            report += f"- {status} **{tz['name']}**"
            if tz.get("loaded"):
                report += f" ({tz['size']} —Å–∏–º–≤–æ–ª–æ–≤)\n"
            else:
                report += f" - {tz.get('error', 'Unknown error')}\n"
        
        report += "\n---\n\n## ü§ñ –ê–ù–ê–õ–ò–ó DEEPSEEK\n\n"
        
        for tz_key in ["tz1", "tz2", "tz3"]:
            if tz_key in self.results["deepseek_analysis"]:
                analysis = self.results["deepseek_analysis"][tz_key]
                report += f"### {tz_key.upper()}\n\n"
                if "error" in analysis:
                    report += f"‚ùå **–û—à–∏–±–∫–∞**: {analysis['error']}\n\n"
                else:
                    report += f"**–¢–æ–∫–µ–Ω—ã**: {analysis.get('prompt_tokens', 0)} ‚Üí {analysis.get('completion_tokens', 0)}\n\n"
                    report += f"```\n{analysis.get('analysis', 'N/A')[:2000]}\n```\n\n"
        
        report += "\n---\n\n## üîç –ê–ù–ê–õ–ò–ó PERPLEXITY AI\n\n"
        
        for tz_key in ["tz1", "tz2", "tz3"]:
            if tz_key in self.results["perplexity_analysis"]:
                analysis = self.results["perplexity_analysis"][tz_key]
                report += f"### {tz_key.upper()}\n\n"
                if "error" in analysis:
                    report += f"‚ùå **–û—à–∏–±–∫–∞**: {analysis['error']}\n\n"
                else:
                    report += f"**–¢–æ–∫–µ–Ω—ã**: {analysis.get('prompt_tokens', 0)} ‚Üí {analysis.get('completion_tokens', 0)}\n\n"
                    report += f"```\n{analysis.get('analysis', 'N/A')[:2000]}\n```\n\n"
        
        report += "\n---\n\n## üìä –ú–ê–¢–†–ò–¶–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø\n\n"
        
        if "matrix" in self.results["compliance_matrix"]:
            report += f"{self.results['compliance_matrix']['matrix']}\n\n"
        else:
            report += "‚ùå –ú–∞—Ç—Ä–∏—Ü–∞ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞\n\n"
        
        report += "\n---\n\n## üéâ –ò–¢–û–ì–û\n\n"
        report += f"- **–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ**: {len([t for t in self.results['tz_documents'] if t.get('loaded')])}/4\n"
        report += f"- **DeepSeek –∞–Ω–∞–ª–∏–∑–æ–≤**: {len(self.results['deepseek_analysis'])}\n"
        report += f"- **Perplexity –∞–Ω–∞–ª–∏–∑–æ–≤**: {len(self.results['perplexity_analysis'])}\n"
        report += f"- **–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤**: {self.results['total_tokens']}\n"
        
        return report
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π pipeline"""
        print("\n" + "="*80)
        print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ê–£–î–ò–¢–ê –ü–†–û–ï–ö–¢–ê")
        print("="*80)
        print(f"–ü—Ä–æ–µ–∫—Ç: {PROJECT_ROOT}")
        print(f"–¢–ó –¥–æ–∫—É–º–µ–Ω—Ç—ã: {TZ_DIR}")
        print()
        
        start_time = time.time()
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¢–ó
        tz_content = await self.load_tz_documents()
        
        # 2. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
        print("\nüìÇ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞...")
        project_structure = await self.scan_project_structure()
        print(f"‚úÖ Backend: {len(project_structure['backend'])} —Ñ–∞–π–ª–æ–≤")
        print(f"‚úÖ Frontend: {len(project_structure['frontend'])} —Ñ–∞–π–ª–æ–≤")
        print(f"‚úÖ MCP Server: {len(project_structure['mcp_server'])} —Ñ–∞–π–ª–æ–≤")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –¢–ó-1
        if "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_1.md" in tz_content:
            await self.analyze_tz1_compliance(
                tz_content["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_1.md"],
                project_structure
            )
        
        # 4. –ê–Ω–∞–ª–∏–∑ –¢–ó-2
        if "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_2.md" in tz_content:
            await self.analyze_tz2_compliance(
                tz_content["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–∞_2.md"],
                project_structure
            )
        
        # 5. –ê–Ω–∞–ª–∏–∑ –¢–ó-3
        if ("–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-1.md" in tz_content and 
            "–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-2.md" in tz_content):
            await self.analyze_tz3_compliance(
                tz_content["–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-1.md"],
                tz_content["–†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ_3-2.md"],
                project_structure
            )
        
        # 6. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Ç—Ä–∏—Ü—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
        await self.generate_compliance_matrix()
        
        # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        await self.save_results()
        
        elapsed = time.time() - start_time
        
        print("\n" + "="*80)
        print("üéâ –ê–£–î–ò–¢ –ó–ê–í–ï–†–®–Å–ù!")
        print("="*80)
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {self.results['total_tokens']}")
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {RESULTS_FILE}")
        print(f"üìÑ –û—Ç—á—ë—Ç: {REPORT_FILE}")
        print("="*80)


async def main():
    analyzer = ProjectAnalyzer()
    await analyzer.run()


if __name__ == "__main__":
    asyncio.run(main())
