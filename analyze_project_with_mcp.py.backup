"""
ü§ñ –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê –ß–ï–†–ï–ó COPILOT ‚Üî PERPLEXITY MCP

–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –Ω–∞–¥–æ —É–ª—É—á—à–∏—Ç—å –≤ —Ä–∞–±–æ—Ç–µ —Ç–µ—Å—Ç–µ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ MCP —Å–µ—Ä–≤–µ—Ä–∞?
–ú–µ—Ç–æ–¥: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ AI dialogue
"""

import os
from dotenv import load_dotenv

load_dotenv()  # Load environment variables from .env file


import asyncio
import httpx
import os
import json
from datetime import datetime

PERPLEXITY_API_KEY = os.getenv("PERPLEXITY_API_KEY")

if not PERPLEXITY_API_KEY:
    raise ValueError(
        "‚ö†Ô∏è SECURITY: PERPLEXITY_API_KEY not configured.
"
        "Please add PERPLEXITY_API_KEY to .env file"
    )
PERPLEXITY_API_URL = "https://api.perplexity.ai/chat/completions"


class ProjectAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞ —á–µ—Ä–µ–∑ MCP –¥–∏–∞–ª–æ–≥."""
    
    def __init__(self):
        self.analysis_results = {
            "timestamp": datetime.now().isoformat(),
            "phases": {}
        }
    
    async def call_perplexity(self, query: str, context: str = "") -> str:
        """–í—ã–∑–æ–≤ Perplexity API."""
        full_query = f"{context}\n\n{query}" if context else query
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            try:
                response = await client.post(
                    PERPLEXITY_API_URL,
                    headers={
                        "Authorization": f"Bearer {PERPLEXITY_API_KEY}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "sonar-pro",
                        "messages": [{
                            "role": "user",
                            "content": full_query
                        }],
                        "temperature": 0.2,
                        "max_tokens": 3000
                    }
                )
                response.raise_for_status()
                data = response.json()
                return data["choices"][0]["message"]["content"]
            except Exception as e:
                return f"ERROR: {e}"
    
    async def phase1_architecture_analysis(self):
        """–§–ê–ó–ê 1: –ê–Ω–∞–ª–∏–∑ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ø—Ä–æ–µ–∫—Ç–∞."""
        print("\n" + "="*80)
        print("üìã –§–ê–ó–ê 1: –ê–ù–ê–õ–ò–ó –ê–†–•–ò–¢–ï–ö–¢–£–†–´ –¢–ï–°–¢–ï–†–ê –°–¢–†–ê–¢–ï–ì–ò–ô")
        print("="*80)
        
        context = """
PROJECT STRUCTURE:

bybit_strategy_tester_v2/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backtest_engine.py       # –û—Å–Ω–æ–≤–Ω–æ–π –¥–≤–∏–∂–æ–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mtf_engine.py             # Multi-Timeframe –¥–≤–∏–∂–æ–∫
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ legacy_backtest.py        # Legacy –∫–æ–¥
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ legacy_optimizer.py       # Legacy –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ legacy_walkforward.py     # Legacy walk-forward
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bybit.py              # Bybit API adapter (—Å get_klines_historical)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bybit_async.py        # Async –≤–µ—Ä—Å–∏—è
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backfill_service.py       # –°–µ—Ä–≤–∏—Å –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ legacy_data_loader.py     # Legacy –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ legacy_base_strategy.py   # Legacy —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bybit_kline_audit.py      # –ú–æ–¥–µ–ª—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–≤–µ—á–µ–π –≤ –ë–î
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ       ‚îî‚îÄ‚îÄ __init__.py                # –ë–î –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ (SQLAlchemy)
‚îÇ
‚îú‚îÄ‚îÄ mcp-server/
‚îÇ   ‚îî‚îÄ‚îÄ server.py                      # MCP Server –¥–ª—è Copilot –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îî‚îÄ‚îÄ src/                           # Electron + React UI
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ integration/
    ‚îÇ   ‚îî‚îÄ‚îÄ test_mcp_cyclic_dialogue.py
    ‚îî‚îÄ‚îÄ backend/

RECENT ACHIEVEMENTS:
‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –ü–û–õ–ù–´–• 90 –¥–Ω–µ–π –¥–∞–Ω–Ω—ã—Ö (38,880 —Å–≤–µ—á–µ–π) —á–µ—Ä–µ–∑ get_klines_historical()
‚úÖ MTF –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (5m, 15m, 30m)
‚úÖ Grid Search –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (7 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
‚úÖ Perplexity AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (3 —Ñ–∞–∑—ã workflow)
‚úÖ Copilot ‚Üî Perplexity MCP –¥–∏–∞–ª–æ–≥ —Ä–∞–±–æ—Ç–∞–µ—Ç

KNOWN ISSUES:
‚ö†Ô∏è Legacy –∫–æ–¥ –Ω–µ —É–¥–∞–ª—ë–Ω (legacy_backtest.py, legacy_optimizer.py, etc.)
‚ö†Ô∏è MTFBacktestEngine —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–æ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ç–µ—Å—Ç–∞—Ö
‚ö†Ô∏è BackfillService —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –º–æ–¥–µ–ª—å BybitKlineAudit –Ω–µ –∏–º–µ–µ—Ç –ø–æ–ª—è 'interval'
‚ö†Ô∏è Walk-Forward –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞
‚ö†Ô∏è MCP —Å–µ—Ä–≤–µ—Ä –±–∞–∑–æ–≤—ã–π (–±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π)
"""
        
        query = """Analyze this Python backtesting system architecture and identify TOP 5 critical improvements needed:

FOCUS AREAS:
1. Code Architecture (legacy vs modern, coupling, modularity)
2. Data Management (storage, caching, retrieval efficiency)
3. Performance & Scalability (bottlenecks, optimization opportunities)
4. MCP Server Integration (current limitations, missing features)
5. Testing & Validation (coverage, robustness, production readiness)

For EACH improvement provide:
- Issue description
- Impact assessment (High/Medium/Low)
- Specific implementation steps
- Estimated effort (hours/days)
- Priority ranking (1-5)

Be specific and actionable."""

        print(f"\nü§ñ Copilot ‚Üí Perplexity:")
        print(f"   Query: Architecture analysis...")
        
        response = await self.call_perplexity(query, context)
        
        print(f"\nüí° Perplexity Response:")
        print(response)
        
        self.analysis_results["phases"]["phase1_architecture"] = {
            "query": query,
            "response": response
        }
        
        return response
    
    async def phase2_mcp_server_analysis(self):
        """–§–ê–ó–ê 2: –ê–Ω–∞–ª–∏–∑ MCP —Å–µ—Ä–≤–µ—Ä–∞."""
        print("\n" + "="*80)
        print("üìã –§–ê–ó–ê 2: –ê–ù–ê–õ–ò–ó MCP –°–ï–†–í–ï–†–ê (COPILOT ‚Üî PERPLEXITY)")
        print("="*80)
        
        context = """
CURRENT MCP SERVER (mcp-server/server.py):

IMPLEMENTED FEATURES:
‚úÖ analyze_backtest_results - –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—ç–∫—Ç–µ—Å—Ç–∞
‚úÖ optimize_strategy_params - –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
‚úÖ generate_trading_strategy - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
‚úÖ compare_strategies - –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
‚úÖ evaluate_risk_metrics - –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫-–º–µ—Ç—Ä–∏–∫
‚úÖ Perplexity API integration —á–µ—Ä–µ–∑ httpx

LIMITATIONS:
‚ùå No persistent storage for analysis history
‚ùå No caching of API responses
‚ùå No rate limiting handling
‚ùå No error recovery/retry logic (–∫—Ä–æ–º–µ –±–∞–∑–æ–≤–æ–π)
‚ùå No streaming responses for long computations
‚ùå No multi-model support (—Ç–æ–ª—å–∫–æ sonar-pro)
‚ùå No context window management
‚ùå No conversation history tracking
‚ùå No metrics/monitoring
‚ùå No authentication/authorization

USAGE EXAMPLE (from tests):
- test_real_ai_workflow.py: 8 —Ñ–∞–∑, –≤—Å–µ —É—Å–ø–µ—à–Ω–æ
- test_full_90days_mtf_ai_workflow.py: 3 —Ñ–∞–∑—ã AI –∞–Ω–∞–ª–∏–∑–∞, —Ä–∞–±–æ—Ç–∞–µ—Ç

MCP PROTOCOL:
- Based on Model Context Protocol specification
- Uses stdio transport
- Tool-based interaction model
"""
        
        query = """Analyze this MCP Server implementation for trading strategy analysis and provide:

1. **CRITICAL MISSING FEATURES** (Top 5)
   - What essential MCP server capabilities are missing?
   - What would unlock new use cases?

2. **PERFORMANCE OPTIMIZATIONS** (Top 3)
   - Caching strategies
   - API efficiency
   - Response time improvements

3. **RELIABILITY IMPROVEMENTS** (Top 3)
   - Error handling patterns
   - Retry mechanisms
   - Graceful degradation

4. **ADVANCED FEATURES ROADMAP**
   - Conversation memory/context
   - Multi-model orchestration
   - Streaming responses
   - Metrics/observability

5. **INTEGRATION ENHANCEMENTS**
   - Better Copilot integration patterns
   - Database persistence
   - Real-time monitoring

Prioritize by impact and implementation complexity."""

        print(f"\nü§ñ Copilot ‚Üí Perplexity:")
        print(f"   Query: MCP Server analysis...")
        
        response = await self.call_perplexity(query, context)
        
        print(f"\nüí° Perplexity Response:")
        print(response)
        
        self.analysis_results["phases"]["phase2_mcp_server"] = {
            "query": query,
            "response": response
        }
        
        return response
    
    async def phase3_data_pipeline_analysis(self):
        """–§–ê–ó–ê 3: –ê–Ω–∞–ª–∏–∑ data pipeline."""
        print("\n" + "="*80)
        print("üìã –§–ê–ó–ê 3: –ê–ù–ê–õ–ò–ó DATA PIPELINE")
        print("="*80)
        
        context = """
DATA PIPELINE COMPONENTS:

1. DATA SOURCES:
   - Bybit API (Public REST API)
   - Limit: 1000 candles per request
   - Rate limit: ~5 req/sec (standard tier)

2. DATA LOADING:
   ‚úÖ BybitAdapter.get_klines_historical() - Pagination support
   ‚úÖ BackfillService - Batch loading with cursor tracking
   ‚ö†Ô∏è BybitKlineAudit model - Missing 'interval' field (only symbol + open_time unique)

3. DATA STORAGE:
   - SQLite (dev) / PostgreSQL (production option)
   - In-memory caching via Redis (optional)
   - No data versioning
   - No data validation pipeline

4. DATA ACCESS PATTERNS:
   - Load full period ‚Üí Convert to DataFrame ‚Üí Backtest
   - No incremental updates
   - No data quality checks
   - No missing data handling

5. PERFORMANCE METRICS (from recent test):
   - 5m: 25,920 candles in 16.35s (1,586 candles/sec)
   - 15m: 8,640 candles in 5.07s (1,703 candles/sec)
   - 30m: 4,320 candles in 2.64s (1,638 candles/sec)

ISSUES IDENTIFIED:
‚ùå No data integrity validation
‚ùå No duplicate detection (except DB unique constraint)
‚ùå No gap filling strategies
‚ùå No data quality metrics
‚ùå No alternative data sources
‚ùå BybitKlineAudit model doesn't support multiple intervals properly
"""
        
        query = """Analyze this market data pipeline for a trading backtesting system:

1. **DATA QUALITY ISSUES** (Top 5)
   - Missing validations
   - Data integrity risks
   - Gap handling strategies

2. **STORAGE OPTIMIZATION**
   - Database schema improvements (especially interval field issue)
   - Indexing strategies
   - Compression opportunities
   - Partitioning schemes

3. **LOADING EFFICIENCY**
   - Caching strategies (Redis, file-based)
   - Parallel loading
   - Incremental updates
   - Smart prefetching

4. **DATA RELIABILITY**
   - Multiple source redundancy
   - Fallback mechanisms
   - Data verification
   - Anomaly detection

5. **PRODUCTION READINESS**
   - Monitoring needs
   - Alerting triggers
   - Backup strategies
   - Disaster recovery

Prioritize improvements that impact backtest accuracy and system reliability."""

        print(f"\nü§ñ Copilot ‚Üí Perplexity:")
        print(f"   Query: Data pipeline analysis...")
        
        response = await self.call_perplexity(query, context)
        
        print(f"\nüí° Perplexity Response:")
        print(response)
        
        self.analysis_results["phases"]["phase3_data_pipeline"] = {
            "query": query,
            "response": response
        }
        
        return response
    
    async def phase4_testing_validation_analysis(self):
        """–§–ê–ó–ê 4: –ê–Ω–∞–ª–∏–∑ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
        print("\n" + "="*80)
        print("üìã –§–ê–ó–ê 4: –ê–ù–ê–õ–ò–ó –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ò –í–ê–õ–ò–î–ê–¶–ò–ò")
        print("="*80)
        
        context = """
TESTING INFRASTRUCTURE:

CURRENT STATE:
‚úÖ Integration tests exist (tests/integration/)
‚úÖ Real AI workflow test completed (8/8 phases)
‚úÖ Full 90-day MTF test completed (3 AI phases + Grid Search)
‚ö†Ô∏è Unit tests coverage unknown
‚ö†Ô∏è No automated test suite
‚ö†Ô∏è No CI/CD pipeline

VALIDATION METHODS:
‚úÖ Grid Search optimization (7 parameter combinations)
‚úÖ Performance metrics tracking (Sharpe, PF, WR, etc.)
‚ùå No Walk-Forward validation
‚ùå No Monte Carlo simulation
‚ùå No out-of-sample testing framework
‚ùå No overfitting detection
‚ùå No statistical significance testing

BACKTESTING ENGINE:
- BacktestEngine (modern)
- MTFBacktestEngine (exists but unused)
- Legacy engines (legacy_backtest.py, legacy_optimizer.py)

KNOWN GAPS:
‚ùå No transaction cost modeling (slippage, commission partly implemented)
‚ùå No realistic order execution simulation
‚ùå No market impact modeling
‚ùå No liquidity constraints
‚ùå No position sizing validation
‚ùå No risk limit enforcement during backtest

STRATEGY VALIDATION:
- Single backtest period (89 days)
- No robustness testing across market regimes
- No stress testing
- No benchmark comparison (vs Buy&Hold, etc.)
"""
        
        query = """Analyze this backtesting system's testing and validation framework:

1. **CRITICAL TESTING GAPS** (Top 5)
   - What testing methodologies are missing?
   - What risks are not being validated?
   - What could cause false confidence in results?

2. **VALIDATION FRAMEWORK IMPROVEMENTS**
   - Walk-Forward validation implementation
   - Out-of-sample testing
   - Cross-validation techniques
   - Monte Carlo robustness testing
   - Statistical significance testing

3. **REALISM ENHANCEMENTS**
   - Transaction cost modeling
   - Order execution simulation
   - Market impact
   - Slippage models
   - Liquidity constraints

4. **OVERFITTING PREVENTION**
   - Detection methods
   - Prevention strategies
   - Regularization techniques
   - Parameter stability analysis

5. **PRODUCTION VALIDATION**
   - Paper trading pipeline
   - Live validation metrics
   - Performance degradation detection
   - Alert systems

Provide specific, implementable recommendations with priority rankings."""

        print(f"\nü§ñ Copilot ‚Üí Perplexity:")
        print(f"   Query: Testing & validation analysis...")
        
        response = await self.call_perplexity(query, context)
        
        print(f"\nüí° Perplexity Response:")
        print(response)
        
        self.analysis_results["phases"]["phase4_testing_validation"] = {
            "query": query,
            "response": response
        }
        
        return response
    
    async def phase5_production_readiness_analysis(self):
        """–§–ê–ó–ê 5: –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É."""
        print("\n" + "="*80)
        print("üìã –§–ê–ó–ê 5: –ê–ù–ê–õ–ò–ó PRODUCTION READINESS")
        print("="*80)
        
        context = """
PRODUCTION READINESS ASSESSMENT:

INFRASTRUCTURE:
‚úÖ FastAPI backend structure exists
‚úÖ Electron + React frontend exists
‚úÖ Database layer (SQLAlchemy)
‚úÖ Redis caching (optional, configured)
‚ö†Ô∏è No Docker containerization
‚ö†Ô∏è No deployment automation
‚ö†Ô∏è No CI/CD
‚ö†Ô∏è No environment management (dev/staging/prod)

MONITORING & OBSERVABILITY:
‚ùå No logging aggregation
‚ùå No metrics collection
‚ùå No distributed tracing
‚ùå No alerting system
‚ùå No health checks
‚ùå No performance monitoring

SECURITY:
‚ö†Ô∏è API keys hardcoded in test files
‚ùå No secrets management
‚ùå No authentication system
‚ùå No authorization/RBAC
‚ùå No audit logging
‚ùå No data encryption (at rest/in transit beyond HTTPS)

SCALABILITY:
‚ö†Ô∏è Single-threaded backtest execution
‚ö†Ô∏è In-memory DataFrame processing
‚ùå No horizontal scaling support
‚ùå No job queue for long-running tasks
‚ùå No distributed computing
‚ùå No load balancing

RELIABILITY:
‚ö†Ô∏è No backup strategy
‚ö†Ô∏è No disaster recovery
‚ùå No failover mechanisms
‚ùå No circuit breakers
‚ùå No rate limiting (except Bybit API inherent limits)
‚ùå No graceful shutdown

ERROR HANDLING:
‚úÖ Basic try-catch in critical paths
‚ö†Ô∏è Inconsistent error handling patterns
‚ùå No centralized error tracking (Sentry, etc.)
‚ùå No error classification
‚ùå No automated recovery

DOCUMENTATION:
‚úÖ Recent comprehensive test reports
‚úÖ Code has some docstrings
‚ö†Ô∏è No API documentation (OpenAPI/Swagger)
‚ö†Ô∏è No deployment guide
‚ö†Ô∏è No runbook for operations
‚ùå No architecture diagrams
"""
        
        query = """Assess production readiness of this algorithmic trading backtesting system:

1. **CRITICAL BLOCKERS FOR PRODUCTION** (Top 5)
   - What MUST be fixed before any production deployment?
   - What are the highest risk areas?

2. **INFRASTRUCTURE REQUIREMENTS**
   - Containerization (Docker/Kubernetes)
   - CI/CD pipeline design
   - Environment management
   - Secret management
   - Deployment automation

3. **OBSERVABILITY STACK**
   - Logging architecture
   - Metrics collection
   - Tracing setup
   - Alerting rules
   - Dashboard requirements

4. **SECURITY HARDENING**
   - Authentication/authorization
   - API security
   - Data protection
   - Audit trail
   - Compliance considerations (if any)

5. **OPERATIONAL EXCELLENCE**
   - Backup/restore procedures
   - Disaster recovery plan
   - Incident response playbook
   - Performance SLOs/SLAs
   - Capacity planning

6. **SCALABILITY PATH**
   - Immediate bottlenecks
   - Scaling strategies (vertical vs horizontal)
   - Distributed processing architecture
   - Cost optimization

Provide actionable roadmap with effort estimates and dependencies."""

        print(f"\nü§ñ Copilot ‚Üí Perplexity:")
        print(f"   Query: Production readiness analysis...")
        
        response = await self.call_perplexity(query, context)
        
        print(f"\nüí° Perplexity Response:")
        print(response)
        
        self.analysis_results["phases"]["phase5_production_readiness"] = {
            "query": query,
            "response": response
        }
        
        return response
    
    def save_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞."""
        report_json = "PROJECT_IMPROVEMENT_ANALYSIS_REPORT.json"
        report_md = "PROJECT_IMPROVEMENT_ANALYSIS_SUMMARY.md"
        
        # JSON
        with open(report_json, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, default=str)
        
        print(f"\n‚úÖ JSON –æ—Ç—á—ë—Ç: {report_json}")
        
        # Markdown summary
        md_content = f"""# üîç –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê –ß–ï–†–ï–ó COPILOT ‚Üî PERPLEXITY MCP

**–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞**: {self.analysis_results['timestamp']}  
**–ú–µ—Ç–æ–¥**: –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–π AI-–∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Perplexity MCP  
**–§–∞–∑—ã**: 5 (Architecture, MCP Server, Data Pipeline, Testing, Production Readiness)

---

## üìã –§–ê–ó–´ –ê–ù–ê–õ–ò–ó–ê

"""
        
        for phase_name, phase_data in self.analysis_results["phases"].items():
            md_content += f"### {phase_name.upper()}\n\n"
            md_content += f"**Query:**\n```\n{phase_data['query'][:200]}...\n```\n\n"
            md_content += f"**Response:**\n{phase_data['response']}\n\n---\n\n"
        
        with open(report_md, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        print(f"‚úÖ Markdown –æ—Ç—á—ë—Ç: {report_md}")
    
    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥."""
        print("\n" + "üåü"*40)
        print("ü§ñ –ì–õ–£–ë–û–ö–ò–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê –ß–ï–†–ï–ó COPILOT ‚Üî PERPLEXITY MCP")
        print("üåü"*40)
        print(f"\n–í–æ–ø—Ä–æ—Å: –ß—Ç–æ –Ω–∞–¥–æ —É–ª—É—á—à–∏—Ç—å –≤ —Ä–∞–±–æ—Ç–µ —Ç–µ—Å—Ç–µ—Ä–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏ MCP —Å–µ—Ä–≤–µ—Ä–∞?")
        print(f"–ú–µ—Ç–æ–¥: 5 —Ñ–∞–∑ AI-–∞–Ω–∞–ª–∏–∑–∞\n")
        
        # –§–ê–ó–ê 1: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        await self.phase1_architecture_analysis()
        
        # –§–ê–ó–ê 2: MCP Server
        await self.phase2_mcp_server_analysis()
        
        # –§–ê–ó–ê 3: Data Pipeline
        await self.phase3_data_pipeline_analysis()
        
        # –§–ê–ó–ê 4: Testing & Validation
        await self.phase4_testing_validation_analysis()
        
        # –§–ê–ó–ê 5: Production Readiness
        await self.phase5_production_readiness_analysis()
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç
        self.save_report()
        
        print("\n" + "="*80)
        print("‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù!")
        print("="*80)


if __name__ == "__main__":
    analyzer = ProjectAnalyzer()
    asyncio.run(analyzer.run())
