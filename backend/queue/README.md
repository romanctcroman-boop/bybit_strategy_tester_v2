# Phase 1: Redis Streams Queue Manager

–ó–∞–º–µ–Ω–∞ Celery –Ω–∞ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π Redis Streams –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∞–º–∏ –±—ç–∫—Ç–µ—Å—Ç–∞ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏.

## üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞

```
backend/queue/
‚îú‚îÄ‚îÄ __init__.py              # –≠–∫—Å–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª—è
‚îú‚îÄ‚îÄ redis_queue_manager.py   # –û—Å–Ω–æ–≤–Ω–æ–π –º–µ–Ω–µ–¥–∂–µ—Ä –æ—á–µ—Ä–µ–¥–µ–π
‚îú‚îÄ‚îÄ task_handlers.py         # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞–¥–∞—á (backtest, optimization)
‚îú‚îÄ‚îÄ worker_cli.py            # CLI –¥–ª—è –∑–∞–ø—É—Å–∫–∞ workers
‚îî‚îÄ‚îÄ autoscaler.py            # Auto-scaling –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ Redis

```powershell
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ Redis –∑–∞–ø—É—â–µ–Ω
redis-cli ping
# –î–æ–ª–∂–Ω–æ –≤–µ—Ä–Ω—É—Ç—å: PONG
```

–ï—Å–ª–∏ Redis –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:

```powershell
# Windows: —Å–∫–∞—á–∞—Ç—å —Å https://github.com/microsoftarchive/redis/releases
# –ò–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Docker:
docker run -d -p 6379:6379 --name redis redis:latest
```

### 2. –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞

```powershell
# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å venv
& D:/bybit_strategy_tester_v2/.venv/Scripts/Activate.ps1

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç
python test_redis_queue.py
```

### 3. –ó–∞–ø—É—Å–∫ workers

```powershell
# –ó–∞–ø—É—Å—Ç–∏—Ç—å 4 worker –ø—Ä–æ—Ü–µ—Å—Å–∞
python -m backend.queue.worker_cli --workers 4

# –° custom Redis URL
python -m backend.queue.worker_cli --workers 4 --redis-url redis://localhost:6379/1

# –° environment variable
$env:REDIS_URL = "redis://localhost:6379/0"
python -m backend.queue.worker_cli --workers 4
```

### 4. –ó–∞–ø—É—Å–∫ AutoScaler (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```powershell
# –ó–∞–ø—É—Å—Ç–∏—Ç—å AutoScaler –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
python backend/queue/autoscaler.py --min-workers 2 --max-workers 8 --interval 30
```

## üìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

### Redis Streams Flow

```
Producer (FastAPI)
    ‚Üì
    XADD ‚Üí Redis Stream: bybit:tasks
    ‚Üì
Consumer Group: workers
    ‚Üì
    XREADGROUP (atomic claim)
    ‚Üì
Worker Processes (1..N)
    ‚Üì
Task Handler (backtest_handler, optimization_handler)
    ‚Üì
Result ‚Üí XACK ‚Üí Completed Stream
    or
Error ‚Üí Retry ‚Üí DLQ (Dead Letter Queue)
```

### –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

1. **RedisQueueManager** (`redis_queue_manager.py`)
   - Consumer Groups –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
   - Automatic retry —Å exponential backoff
   - Dead Letter Queue –¥–ª—è –ø—Ä–æ–≤–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
   - Graceful shutdown

2. **Task Handlers** (`task_handlers.py`)
   - `backtest_handler` - –∑–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–æ–≤
   - `optimization_handler` - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
   - `data_fetch_handler` - –∑–∞–≥—Ä—É–∑–∫–∞ market data

3. **Worker CLI** (`worker_cli.py`)
   - Multi-worker –ø–æ–¥–¥–µ—Ä–∂–∫–∞
   - Signal handling (SIGINT, SIGTERM)
   - Windows —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å

4. **AutoScaler** (`autoscaler.py`)
   - SLA-based –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
   - Scale UP/DOWN –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫
   - Cooldown –º–µ–∂–¥—É –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ (60 —Å–µ–∫)

## üîß API Reference

### –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–¥–∞—á–∏

```python
from backend.queue import RedisQueueManager, TaskPriority

qm = RedisQueueManager(redis_url="redis://localhost:6379/0")
await qm.connect()

# –û—Ç–ø—Ä–∞–≤–∏—Ç—å backtest –∑–∞–¥–∞—á—É
task_id = await qm.submit_task(
    task_type="backtest",
    payload={
        "backtest_id": 123,
        "strategy_config": {...},
        "symbol": "BTCUSDT",
        "interval": "1h",
        "start_date": "2024-01-01",
        "end_date": "2024-12-31",
        "initial_capital": 10000.0
    },
    priority=TaskPriority.HIGH.value,
    max_retries=3,
    timeout_seconds=3600
)
```

### –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞

```python
async def my_handler(payload):
    print(f"Processing: {payload}")
    # Do work...
    return {"status": "ok"}

qm.register_handler("my_task_type", my_handler)
```

### –ó–∞–ø—É—Å–∫ worker

```python
# –ó–∞–ø—É—Å—Ç–∏—Ç—å worker (blocking call)
await qm.start_worker()
```

## üìà –ú–µ—Ç—Ä–∏–∫–∏

```python
metrics = qm.get_metrics()
# {
#   "tasks_submitted": 100,
#   "tasks_completed": 95,
#   "tasks_failed": 3,
#   "tasks_timeout": 2,
#   "active_tasks": 5
# }
```

## üéõÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### Environment Variables

```bash
REDIS_URL=redis://localhost:6379/0
```

### Worker CLI Options

```
--redis-url    Redis connection URL
--workers      Number of worker processes (default: 4)
--stream       Redis stream name (default: bybit:tasks)
--group        Consumer group name (default: workers)
```

### AutoScaler Options

```
--min-workers  Minimum workers (default: 1)
--max-workers  Maximum workers (default: 10)
--interval     Check interval in seconds (default: 30)
```

## üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```powershell
# Unit tests
pytest tests/queue/

# Integration test
python test_redis_queue.py

# Load test (1000 –∑–∞–¥–∞—á)
python tests/queue/test_load.py
```

## üîÑ –ú–∏–≥—Ä–∞—Ü–∏—è —Å Celery

### –î–æ (Celery):

```python
from backend.tasks.backtest_tasks import run_backtest_task

task = run_backtest_task.delay(
    backtest_id=123,
    strategy_config={...}
)
```

### –ü–æ—Å–ª–µ (Redis Streams):

```python
from backend.queue import RedisQueueManager

qm = RedisQueueManager()
await qm.connect()

task_id = await qm.submit_task(
    task_type="backtest",
    payload={
        "backtest_id": 123,
        "strategy_config": {...}
    }
)
```

## ‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

- **Latency**: < 10ms –Ω–∞ XADD/XREADGROUP
- **Throughput**: 10,000+ tasks/sec (–æ–¥–∏–Ω–æ—á–Ω—ã–π Redis)
- **Memory**: ~100MB –Ω–∞ worker –ø—Ä–æ—Ü–µ—Å—Å
- **Retry overhead**: Exponential backoff (2^n —Å–µ–∫—É–Ω–¥)

## üõ°Ô∏è –ò–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å

- –ê—Ç–æ–º–∞—Ä–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ —á–µ—Ä–µ–∑ `claim_backtest_to_run`
- Consumer Groups –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—é—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
- Dead Letter Queue –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–¥–∞—á
- Graceful shutdown –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∑–∞–¥–∞—á

## üìù TODO

- [ ] Prometheus metrics exporter
- [ ] Worker process management (subprocess/Docker)
- [ ] Task result storage (–æ—Ç–¥–µ–ª—å–Ω—ã–π hash)
- [ ] Priority queues (–æ—Ç–¥–µ–ª—å–Ω—ã–µ streams –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º)
- [ ] Scheduled tasks (CRON-like)

## üîó –°—Å—ã–ª–∫–∏

- Redis Streams: https://redis.io/docs/data-types/streams/
- Consumer Groups: https://redis.io/docs/data-types/streams-tutorial/

---

**Status**: ‚úÖ Phase 1 Complete (16 hours)  
**Next**: Phase 2 - Architecture (54 hours)
