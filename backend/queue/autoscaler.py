"""
Auto-Scaling Controller with SLA-driven policies

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–µ—Ç—Ä–∏–∫ –æ—á–µ—Ä–µ–¥–∏
"""

import asyncio
import time
from dataclasses import dataclass

from loguru import logger

try:
    import redis.asyncio as aioredis
except ImportError:
    try:
        import aioredis
    except ImportError:
        raise ImportError("Install redis with: pip install redis>=5.0.0")


@dataclass
class SLATarget:
    """SLA –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è"""
    max_queue_latency_seconds: float = 300.0  # 5 –º–∏–Ω—É—Ç
    min_throughput_tasks_per_minute: float = 10.0
    max_worker_utilization: float = 0.8  # 80%
    target_worker_utilization: float = 0.6  # 60% (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞)


@dataclass
class ScalingMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π –æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏"""
    pending_tasks: int
    active_tasks: int
    avg_task_duration_seconds: float
    queue_latency_seconds: float
    worker_count: int
    cpu_usage: float = 0.0  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ


class AutoScaler:
    """
    –ê–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ workers –Ω–∞ –æ—Å–Ω–æ–≤–µ SLA
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è:
    - Scale UP: –µ—Å–ª–∏ queue latency > SLA –∏–ª–∏ utilization > 80%
    - Scale DOWN: –µ—Å–ª–∏ utilization < 20% –∏ queue latency –≤ –Ω–æ—Ä–º–µ
    - Cooldown: 60 —Å–µ–∫ –º–µ–∂–¥—É –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏ (–ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ flapping)
    
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
        scaler = AutoScaler(redis_url="redis://localhost:6379/0")
        await scaler.connect()
        await scaler.run(interval_seconds=30)
    """
    
    def __init__(
        self,
        redis_url: str,
        stream_name: str = "bybit:tasks",
        consumer_group: str = "workers",
        sla_target: SLATarget | None = None,
        min_workers: int = 1,
        max_workers: int = 10,
        scale_up_threshold: float = 0.8,
        scale_down_threshold: float = 0.2,
        cooldown_seconds: int = 60,
    ):
        self.redis_url = redis_url
        self.stream_name = stream_name
        self.consumer_group = consumer_group
        self.sla_target = sla_target or SLATarget()
        self.min_workers = min_workers
        self.max_workers = max_workers
        self.scale_up_threshold = scale_up_threshold
        self.scale_down_threshold = scale_down_threshold
        self.cooldown_seconds = cooldown_seconds
        
        self._redis: aioredis.Redis | None = None
        self._last_scale_time = 0.0
        self._running = False
        
        # –ò—Å—Ç–æ—Ä–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        self._metrics_history = []
        self._max_history_size = 10
    
    async def connect(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis"""
        self._redis = await aioredis.from_url(
            self.redis_url,
            encoding="utf-8",
            decode_responses=True
        )
        await self._redis.ping()
        logger.info(f"‚úÖ AutoScaler connected to Redis: {self.redis_url}")
    
    async def disconnect(self):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ"""
        if self._redis:
            await self._redis.close()
            logger.info("‚úÖ AutoScaler disconnected")
    
    async def get_metrics(self) -> ScalingMetrics:
        """–°–æ–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ Redis"""
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ stream
            stream_info = await self._redis.xinfo_stream(self.stream_name)
            pending_tasks = stream_info.get("length", 0)
            
            # –ü–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∏–∑ consumer groups
            try:
                groups_info = await self._redis.xinfo_groups(self.stream_name)
                active_tasks = sum(g.get("pending", 0) for g in groups_info)
            except Exception:
                active_tasks = 0
            
            # –ü–æ–ª—É—á–∏—Ç—å worker count
            # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ workers —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç —Å–µ–±—è –≤ Redis Set
            worker_count = await self._redis.scard("workers:active")
            if worker_count == 0:
                # –ï—Å–ª–∏ workers –Ω–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É—é—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback
                worker_count = 1
            
            # –†–∞—Å—Å—á–∏—Ç–∞—Ç—å queue latency (approx)
            queue_latency = 0.0
            if pending_tasks > 0:
                try:
                    # –í–∑—è—Ç—å –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –µ–≥–æ timestamp
                    messages = await self._redis.xrange(self.stream_name, count=1)
                    if messages:
                        msg_id = messages[0][0]
                        # msg_id format: "<timestamp_ms>-<seq>"
                        timestamp_ms = int(msg_id.split("-")[0])
                        queue_latency = (time.time() * 1000 - timestamp_ms) / 1000.0
                except Exception as e:
                    logger.debug(f"Could not calculate queue latency: {e}")
            
            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ (–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –∏–ª–∏ –∑–∞–≥–ª—É—à–∫–∞)
            avg_duration = 60.0  # 1 –º–∏–Ω—É—Ç–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if self._metrics_history:
                # –ú–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å –∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –∑–∞–¥–∞—á
                pass
            
            metrics = ScalingMetrics(
                pending_tasks=pending_tasks,
                active_tasks=active_tasks,
                avg_task_duration_seconds=avg_duration,
                queue_latency_seconds=queue_latency,
                worker_count=worker_count,
            )
            
            # –î–æ–±–∞–≤–∏—Ç—å –≤ –∏—Å—Ç–æ—Ä–∏—é
            self._metrics_history.append(metrics)
            if len(self._metrics_history) > self._max_history_size:
                self._metrics_history.pop(0)
            
            return metrics
        
        except Exception as e:
            logger.error(f"‚ùå Failed to get metrics: {e}", exc_info=True)
            # –í–µ—Ä–Ω—É—Ç—å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            return ScalingMetrics(
                pending_tasks=0,
                active_tasks=0,
                avg_task_duration_seconds=60.0,
                queue_latency_seconds=0.0,
                worker_count=1,
            )
    
    def should_scale_up(self, metrics: ScalingMetrics) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –≤–≤–µ—Ä—Ö"""
        # SLA violation: queue latency
        if metrics.queue_latency_seconds > self.sla_target.max_queue_latency_seconds:
            logger.warning(
                f"‚ö†Ô∏è SLA violation: queue latency {metrics.queue_latency_seconds:.1f}s "
                f"> {self.sla_target.max_queue_latency_seconds}s"
            )
            return True
        
        # High utilization
        if metrics.worker_count > 0:
            utilization = metrics.active_tasks / metrics.worker_count
            if utilization > self.scale_up_threshold:
                logger.warning(
                    f"‚ö†Ô∏è High utilization: {utilization:.1%} > {self.scale_up_threshold:.1%}"
                )
                return True
        
        # –ë–æ–ª—å—à–∞—è –æ—á–µ—Ä–µ–¥—å –æ–∂–∏–¥–∞—é—â–∏—Ö –∑–∞–¥–∞—á
        if metrics.pending_tasks > metrics.worker_count * 5:
            logger.warning(
                f"‚ö†Ô∏è Large queue: {metrics.pending_tasks} pending tasks "
                f"for {metrics.worker_count} workers"
            )
            return True
        
        return False
    
    def should_scale_down(self, metrics: ScalingMetrics) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –≤–Ω–∏–∑"""
        if metrics.worker_count <= self.min_workers:
            return False
        
        if metrics.worker_count > 0:
            utilization = metrics.active_tasks / metrics.worker_count
            
            # Low utilization –∏ queue –≤ –Ω–æ—Ä–º–µ
            if (utilization < self.scale_down_threshold and
                metrics.queue_latency_seconds < self.sla_target.max_queue_latency_seconds * 0.5 and
                metrics.pending_tasks < metrics.worker_count):
                logger.info(
                    f"‚úÖ Low utilization: {utilization:.1%} < {self.scale_down_threshold:.1%}"
                )
                return True
        
        return False
    
    async def scale_up(self, current_workers: int) -> int:
        """
        –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –≤–≤–µ—Ä—Ö (–¥–æ–±–∞–≤–∏—Ç—å worker)
        
        Returns:
            –ù–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers
        """
        new_count = min(current_workers + 1, self.max_workers)
        
        if new_count == current_workers:
            logger.info(f"‚ö†Ô∏è Already at max workers: {self.max_workers}")
            return new_count
        
        logger.info(f"üìà Scaling UP: {current_workers} ‚Üí {new_count} workers")
        
        # TODO: –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –∑–∞–ø—É—Å–∫–∞ –Ω–æ–≤–æ–≥–æ worker –ø—Ä–æ—Ü–µ—Å—Å–∞
        # –í–∞—Ä–∏–∞–Ω—Ç—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏:
        # 1. subprocess.Popen([sys.executable, "-m", "backend.queue.worker_cli"])
        # 2. Docker API: docker.from_env().containers.run(...)
        # 3. Kubernetes API: client.AppsV1Api().patch_namespaced_deployment(...)
        
        # –ó–∞–≥–ª—É—à–∫–∞: –≤—ã–≤–µ—Å—Ç–∏ –∫–æ–º–∞–Ω–¥—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞
        logger.info(
            "üí° To scale up manually, run: "
            "python -m backend.queue.worker_cli --workers 1"
        )
        
        return new_count
    
    async def scale_down(self, current_workers: int) -> int:
        """
        –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å –≤–Ω–∏–∑ (—É–¥–∞–ª–∏—Ç—å worker)
        
        Returns:
            –ù–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ workers
        """
        new_count = max(current_workers - 1, self.min_workers)
        
        if new_count == current_workers:
            logger.info(f"‚ö†Ô∏è Already at min workers: {self.min_workers}")
            return new_count
        
        logger.info(f"üìâ Scaling DOWN: {current_workers} ‚Üí {new_count} workers")
        
        # TODO: –õ–æ–≥–∏–∫–∞ graceful shutdown –æ–¥–Ω–æ–≥–æ worker
        # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Redis pub/sub –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∫–æ–º–∞–Ω–¥—ã shutdown
        
        logger.info(
            "üí° To scale down manually, stop one worker process"
        )
        
        return new_count
    
    async def run(self, interval_seconds: int = 30):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Args:
            interval_seconds: –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–µ—Ç—Ä–∏–∫ (default: 30 —Å–µ–∫)
        """
        self._running = True
        logger.info("ü§ñ AutoScaler started")
        
        try:
            while self._running:
                try:
                    # –°–æ–±—Ä–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
                    metrics = await self.get_metrics()
                    
                    logger.info(
                        f"üìä Metrics: pending={metrics.pending_tasks}, "
                        f"active={metrics.active_tasks}, "
                        f"workers={metrics.worker_count}, "
                        f"latency={metrics.queue_latency_seconds:.1f}s"
                    )
                    
                    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å cooldown
                    now = time.time()
                    cooldown_remaining = self.cooldown_seconds - (now - self._last_scale_time)
                    
                    if cooldown_remaining > 0:
                        logger.debug(
                            f"‚è≥ Cooldown active ({cooldown_remaining:.0f}s remaining)"
                        )
                        await asyncio.sleep(interval_seconds)
                        continue
                    
                    # –ü—Ä–∏–Ω—è—Ç—å —Ä–µ—à–µ–Ω–∏–µ –æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–∏
                    if self.should_scale_up(metrics):
                        new_count = await self.scale_up(metrics.worker_count)
                        self._last_scale_time = now
                    elif self.should_scale_down(metrics):
                        new_count = await self.scale_down(metrics.worker_count)
                        self._last_scale_time = now
                    else:
                        logger.debug("‚úÖ No scaling needed")
                    
                    await asyncio.sleep(interval_seconds)
                
                except Exception as e:
                    logger.error(f"‚ùå AutoScaler error: {e}", exc_info=True)
                    await asyncio.sleep(interval_seconds)
        
        finally:
            logger.info("üõë AutoScaler stopped")
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∞–≤—Ç–æ–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        self._running = False
        await self.disconnect()


# CLI –¥–ª—è –∑–∞–ø—É—Å–∫–∞ AutoScaler
if __name__ == "__main__":
    import os

    import click
    
    @click.command()
    @click.option('--redis-url', default=lambda: os.environ.get('REDIS_URL', 'redis://localhost:6379/0'))
    @click.option('--min-workers', default=1, type=int)
    @click.option('--max-workers', default=10, type=int)
    @click.option('--interval', default=30, type=int, help='Check interval in seconds')
    def main(redis_url: str, min_workers: int, max_workers: int, interval: int):
        """Start AutoScaler"""
        scaler = AutoScaler(
            redis_url=redis_url,
            min_workers=min_workers,
            max_workers=max_workers,
        )
        
        async def run():
            await scaler.connect()
            await scaler.run(interval_seconds=interval)
        
        try:
            asyncio.run(run())
        except KeyboardInterrupt:
            logger.info("Interrupted by user")
    
    main()
