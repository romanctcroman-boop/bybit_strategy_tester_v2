"""
–û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞–¥–∞—á –¥–ª—è Redis Queue Manager
"""

from datetime import UTC
from typing import Any

from loguru import logger

from backend.core.engine_adapter import get_engine
from backend.database import SessionLocal
from backend.services.data_service import DataService


async def backtest_handler(payload: dict[str, Any]) -> dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–¥–∞—á–∏ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    
    Payload –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
        backtest_id: int - ID –±—ç–∫—Ç–µ—Å—Ç–∞ –≤ –ë–î
        strategy_config: dict - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        symbol: str - –°–∏–º–≤–æ–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, "BTCUSDT")
        interval: str - –ò–Ω—Ç–µ—Ä–≤–∞–ª (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1h")
        start_date: str - –ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞
        end_date: str - –ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞
        initial_capital: float - –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª (default: 10000.0)
    """
    backtest_id = payload["backtest_id"]
    logger.info(f"üöÄ Starting backtest {backtest_id}")
    
    db = SessionLocal()
    ds = DataService(db)
    
    try:
        # 1. Claim backtest (–∞—Ç–æ–º–∞—Ä–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è)
        from datetime import datetime
        now = datetime.now(UTC)
        claimed = ds.claim_backtest_to_run(backtest_id, now, stale_seconds=300)
        
        if claimed["status"] == "completed":
            logger.info(f"Backtest {backtest_id} already completed")
            return {"backtest_id": backtest_id, "status": "completed"}
        
        if claimed["status"] == "running":
            logger.info(f"Backtest {backtest_id} already running by another worker")
            return {"backtest_id": backtest_id, "status": "running"}
        
        if claimed["status"] != "claimed":
            raise ValueError(f"Failed to claim backtest: {claimed['message']}")
        
        logger.info(f"‚úÖ Claimed backtest {backtest_id}")
        
        # 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å market data
        candles = ds.get_market_data(
            symbol=payload["symbol"],
            timeframe=payload["interval"],
            start_time=payload["start_date"],
            end_time=payload["end_date"]
        )
        
        if candles is None or candles.empty:
            raise ValueError(f"No market data for {payload['symbol']} {payload['interval']}")
        
        logger.info(f"üìä Loaded {len(candles)} candles")
        
        # 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å backtest engine
        engine = get_engine(
            None,
            initial_capital=payload.get("initial_capital", 10000.0),
            commission=0.0006,  # 0.06% –∫–æ–º–∏—Å—Å–∏—è Bybit
            slippage_pct=0.0001     # 0.01% slippage
        )
        
        results = engine.run(
            data=candles,
            strategy_config=payload["strategy_config"]
        )
        
        # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î
        # –ò–∑–≤–ª–µ—á—å —Ç–æ–ª—å–∫–æ scalar –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è update_backtest_results
        scalar_results = {
            k: v for k, v in results.items()
            if k in ('final_capital', 'total_return', 'total_trades', 'winning_trades',
                     'losing_trades', 'win_rate', 'sharpe_ratio', 'max_drawdown',
                     'sortino_ratio', 'profit_factor')
        }
        
        ds.update_backtest_results(
            backtest_id=backtest_id,
            **scalar_results
        )
        
        # 5. –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ completed
        ds.update_backtest(backtest_id, status="completed")
        
        logger.success(f"‚úÖ Backtest {backtest_id} completed: final_capital={results.get('final_capital', 0):.2f}")
        
        return {
            "backtest_id": backtest_id,
            "status": "completed",
            "results": results
        }
    
    except Exception as e:
        logger.error(f"‚ùå Backtest {backtest_id} failed: {e}", exc_info=True)
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å –Ω–∞ failed
        ds.update_backtest(
            backtest_id,
            status="failed",
            error_message=str(e)
        )
        
        raise
    
    finally:
        db.close()


async def optimization_handler(payload: dict[str, Any]) -> dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–¥–∞—á–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    
    Payload –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
        optimization_id: int - ID –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤ –ë–î
        optimization_type: str - –¢–∏–ø ('grid', 'bayesian', 'walk_forward')
        strategy_config: dict - –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        param_space: dict - –ü—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        symbol: str
        interval: str
        start_date: str
        end_date: str
        metric: str - –ú–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ ('sharpe_ratio', 'total_return', etc.)
    """
    optimization_id = payload["optimization_id"]
    opt_type = payload["optimization_type"]
    
    logger.info(f"üîç Starting {opt_type} optimization {optimization_id}")
    
    db = SessionLocal()
    ds = DataService(db)
    
    try:
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        # –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º—É –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—É
        
        if opt_type == "grid":
            # optimizer = GridSearchOptimizer(...)
            # results = optimizer.optimize(...)
            pass
        elif opt_type == "bayesian":
            # optimizer = BayesianOptimizer(...)
            # results = optimizer.optimize(...)
            pass
        elif opt_type == "walk_forward":
            # analyzer = WalkForwardAnalyzer(...)
            # results = analyzer.run(...)
            pass
        else:
            raise ValueError(f"Unknown optimization type: {opt_type}")
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å
        ds.update_optimization(optimization_id, status="completed")
        
        logger.success(f"‚úÖ Optimization {optimization_id} completed")
        
        return {
            "optimization_id": optimization_id,
            "status": "completed",
            # "results": results
        }
    
    except Exception as e:
        logger.error(f"‚ùå Optimization {optimization_id} failed: {e}", exc_info=True)
        
        ds.update_optimization(
            optimization_id,
            status="failed",
            error_message=str(e)
        )
        
        raise
    
    finally:
        db.close()


async def data_fetch_handler(payload: dict[str, Any]) -> dict[str, Any]:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏ market data
    
    Payload:
        symbol: str
        interval: str
        start_date: str
        end_date: str
        force_refresh: bool (default: False)
    """
    symbol = payload["symbol"]
    interval = payload["interval"]
    
    logger.info(f"üì• Fetching market data: {symbol} {interval}")
    
    db = SessionLocal()
    ds = DataService(db)
    
    try:
        # TODO: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å BybitAdapter –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        from backend.services.adapters.bybit import BybitAdapter
        
        adapter = BybitAdapter()
        candles = await adapter.get_historical_klines(
            symbol=symbol,
            interval=interval,
            start_time=payload["start_date"],
            end_time=payload["end_date"]
        )
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
        # ds.bulk_insert_market_data(candles)
        
        logger.success(f"‚úÖ Fetched {len(candles)} candles for {symbol}")
        
        return {
            "symbol": symbol,
            "interval": interval,
            "candles_count": len(candles),
            "status": "completed"
        }
    
    except Exception as e:
        logger.error(f"‚ùå Data fetch failed: {e}", exc_info=True)
        raise
    
    finally:
        db.close()
