# –ü–õ–ê–ù –î–ï–ô–°–¢–í–ò–ô - –§–ê–ó–ê 1: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø
## –ü—Ä–æ–µ–∫—Ç: Bybit Strategy Tester v2
## –°—Ä–æ–∫: 1-2 –Ω–µ–¥–µ–ª–∏
## –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô

---

## –¶–ï–õ–¨ –§–ê–ó–´ 1

–ü—Ä–∏–≤–µ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç –∫ **100% —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é –¢–ó MVP** —Å —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∞–Ω–æ–º–∞–ª–∏–π.

**–¶–µ–ª–µ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞:** MVP 92% ‚Üí **100%**

---

## –ó–ê–î–ê–ß–ê 1: –ö–û–ù–°–û–õ–ò–î–ê–¶–ò–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò (3 –¥–Ω—è)

### –ü—Ä–æ–±–ª–µ–º–∞
–ù–∞–π–¥–µ–Ω–æ **3 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏** Walk-Forward Optimization:
1. `backend/tasks/optimize_tasks.py` (Celery task)
2. `backend/core/walk_forward_optimizer.py`
3. `backend/optimization/walk_forward.py`

–ù–∞–π–¥–µ–Ω–æ **2 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏** Monte Carlo:
1. `backend/optimization/monte_carlo.py`
2. `backend/core/monte_carlo_simulator.py`

### –†–µ—à–µ–Ω–∏–µ

#### 1.1 –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—ã–π –º–æ–¥—É–ª—å Walk-Forward

**–§–∞–π–ª:** `backend/optimization/walk_forward_optimizer.py`

```python
"""
Walk-Forward Optimization - –ï–¥–∏–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó 3.5.2:
- in_sample_size, out_sample_size, step_size –≤ –±–∞—Ä–∞—Ö
- parameter_stability –º–µ—Ç—Ä–∏–∫–∞
- aggregated_metrics
"""

from typing import Any
import pandas as pd
from loguru import logger


class WalkForwardOptimizer:
    """
    –¢–ó 3.5.2 - –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Å–∫–æ–ª—å–∑—è—â—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
    –î–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º —É—Ä–æ–≤–Ω–µ
    """
    
    def __init__(
        self,
        in_sample_size: int,   # 252 bars
        out_sample_size: int,  # 63 bars
        step_size: int         # 63 bars (sliding window step)
    ):
        """
        Args:
            in_sample_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            out_sample_size: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            step_size: –®–∞–≥ —Å–¥–≤–∏–≥–∞ –æ–∫–Ω–∞ (–≤ –±–∞—Ä–∞—Ö)
        """
        self.in_sample_size = in_sample_size
        self.out_sample_size = out_sample_size
        self.step_size = step_size
        
        logger.info(
            f"WalkForwardOptimizer initialized: IS={in_sample_size}, "
            f"OOS={out_sample_size}, step={step_size}"
        )
    
    def run(
        self,
        data: pd.DataFrame,
        param_space: dict[str, list],
        strategy_config: dict,
        metric: str = "sharpe_ratio"
    ) -> dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ Walk-Forward –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Returns:
            {
                'walk_results': list[dict],      # –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∂–¥–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
                'aggregated_metrics': dict,      # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                'parameter_stability': dict      # –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            }
        """
        walk_results = []
        all_params = []
        
        # Calculate number of walks
        total_bars = len(data)
        num_walks = (total_bars - self.in_sample_size - self.out_sample_size) // self.step_size + 1
        
        logger.info(f"Starting {num_walks} walk-forward iterations")
        
        for walk_idx in range(num_walks):
            start_idx = walk_idx * self.step_size
            is_end = start_idx + self.in_sample_size
            oos_end = is_end + self.out_sample_size
            
            if oos_end > total_bars:
                break
            
            # In-Sample data
            is_data = data.iloc[start_idx:is_end]
            
            # Out-of-Sample data
            oos_data = data.iloc[is_end:oos_end]
            
            # Optimize on IS
            best_params = self._optimize_on_is(
                is_data, param_space, strategy_config, metric
            )
            
            # Test on OOS
            oos_metrics = self._test_on_oos(
                oos_data, best_params, strategy_config
            )
            
            walk_results.append({
                'walk_index': walk_idx,
                'is_start': start_idx,
                'is_end': is_end,
                'oos_start': is_end,
                'oos_end': oos_end,
                'best_params': best_params,
                'is_metric': best_params['score'],
                'oos_metrics': oos_metrics
            })
            
            all_params.append(best_params)
            
            logger.info(
                f"Walk {walk_idx+1}/{num_walks}: IS {metric}={best_params['score']:.3f}, "
                f"OOS {metric}={oos_metrics.get(metric, 0):.3f}"
            )
        
        # Aggregate metrics
        aggregated = self._calculate_aggregated_metrics(walk_results, metric)
        
        # Parameter stability
        stability = self._calculate_parameter_stability(all_params)
        
        return {
            'walk_results': walk_results,
            'aggregated_metrics': aggregated,
            'parameter_stability': stability
        }
    
    def _optimize_on_is(
        self,
        data: pd.DataFrame,
        param_space: dict,
        strategy_config: dict,
        metric: str
    ) -> dict:
        """Grid search –Ω–∞ In-Sample –¥–∞–Ω–Ω—ã—Ö"""
        from backend.core.engine_adapter import get_engine
        from itertools import product
        
        # Generate all combinations
        param_names = list(param_space.keys())
        param_values = [param_space[name] for name in param_names]
        combinations = list(product(*param_values))
        
        best_score = float('-inf')
        best_params = None
        
        for combo in combinations:
            params = dict(zip(param_names, combo))
            
            # Merge params into strategy_config
            test_config = {**strategy_config, **params}
            
            # Run backtest
            engine = get_engine()
            result = engine.run(data, test_config)
            
            score = result.get(metric, 0)
            
            if score > best_score:
                best_score = score
                best_params = {**params, 'score': score}
        
        return best_params
    
    def _test_on_oos(
        self,
        data: pd.DataFrame,
        params: dict,
        strategy_config: dict
    ) -> dict:
        """–¢–µ—Å—Ç –Ω–∞ Out-of-Sample –¥–∞–Ω–Ω—ã—Ö"""
        from backend.core.engine_adapter import get_engine
        
        # Remove 'score' from params
        test_params = {k: v for k, v in params.items() if k != 'score'}
        test_config = {**strategy_config, **test_params}
        
        engine = get_engine()
        result = engine.run(data, test_config)
        
        return {
            'sharpe_ratio': result.get('sharpe_ratio', 0),
            'total_return': result.get('total_return', 0),
            'max_drawdown': result.get('max_drawdown', 0),
            'win_rate': result.get('win_rate', 0),
            'profit_factor': result.get('profit_factor', 0)
        }
    
    def _calculate_aggregated_metrics(
        self,
        walk_results: list[dict],
        metric: str
    ) -> dict:
        """–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—Å–µ–º –ø–µ—Ä–∏–æ–¥–∞–º"""
        import numpy as np
        
        is_scores = [w['is_metric'] for w in walk_results]
        oos_scores = [w['oos_metrics'].get(metric, 0) for w in walk_results]
        
        return {
            'is_mean': np.mean(is_scores),
            'is_std': np.std(is_scores),
            'oos_mean': np.mean(oos_scores),
            'oos_std': np.std(oos_scores),
            'is_oos_ratio': np.mean(oos_scores) / np.mean(is_scores) if np.mean(is_scores) > 0 else 0,
            'num_walks': len(walk_results)
        }
    
    def _calculate_parameter_stability(self, all_params: list[dict]) -> dict:
        """
        –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–¢–ó 3.5.2)
        
        –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç std deviation –∫–∞–∂–¥–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –ø–æ –≤—Å–µ–º –ø–µ—Ä–∏–æ–¥–∞–º.
        –ù–∏–∑–∫–∏–π std = —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã = —Ö–æ—Ä–æ—à–æ.
        """
        import numpy as np
        
        if not all_params:
            return {}
        
        param_names = [k for k in all_params[0].keys() if k != 'score']
        stability = {}
        
        for param_name in param_names:
            values = [p[param_name] for p in all_params]
            stability[param_name] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values),
                'stability_score': 1.0 / (1.0 + np.std(values))  # Higher = more stable
            }
        
        return stability
```

**–î–µ–π—Å—Ç–≤–∏—è:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —Ñ–∞–π–ª `backend/optimization/walk_forward_optimizer.py`
2. ‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ª—É—á—à–∏–µ —á–∞—Å—Ç–∏ –∏–∑ 3 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `parameter_stability` (–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å–µ–π—á–∞—Å)
4. ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å bars –≤–º–µ—Å—Ç–æ months
5. ‚ùå –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã (–æ—Å—Ç–∞–≤–∏—Ç—å —Å –ø–æ–º–µ—Ç–∫–æ–π `_deprecated`)
6. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å `backend/tasks/optimize_tasks.py` –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ –∫–ª–∞—Å—Å–∞
7. ‚úÖ –ù–∞–ø–∏—Å–∞—Ç—å unit tests

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∏—ë–º–∫–∏:**
- [ ] 1 –∫–ª–∞—Å—Å WalkForwardOptimizer —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] –í—Å–µ 3 —Å—Ç–∞—Ä—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ deprecated
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç (100%)
- [ ] `parameter_stability` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö

---

#### 1.2 –°–æ–∑–¥–∞—Ç—å –µ–¥–∏–Ω—ã–π –º–æ–¥—É–ª—å Monte Carlo

**–§–∞–π–ª:** `backend/optimization/monte_carlo_simulator.py`

```python
"""
Monte Carlo Simulation - –ï–¥–∏–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è

–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó 3.5.3:
- num_simulations (1000)
- prob_profit, prob_ruin (–¢–ó —Ç—Ä–µ–±—É–µ—Ç, —Å–µ–π—á–∞—Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)
- percentile_5, percentile_95
"""

import numpy as np
from typing import Any
from loguru import logger


class MonteCarloSimulator:
    """
    –¢–ó 3.5.3 - –û—Ü–µ–Ω–∫–∞ —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ —Å–ª—É—á–∞–π–Ω—ã–µ –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∏
    –î–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–º —É—Ä–æ–≤–Ω–µ
    """
    
    def run(
        self,
        trades: list[dict],
        num_simulations: int = 1000,
        initial_capital: float = 10000.0
    ) -> dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ Monte Carlo —Å–∏–º—É–ª—è—Ü–∏–∏
        
        Args:
            trades: –°–ø–∏—Å–æ–∫ —Å–¥–µ–ª–æ–∫ –∏–∑ BacktestEngine
            num_simulations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1000)
            initial_capital: –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª
        
        Returns:
            {
                'simulations': list[dict],   # –†–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∂–¥–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏
                'statistics': {
                    'mean_return': float,
                    'std_return': float,
                    'percentile_5': float,   # –ü–µ—Å—Å–∏–º–∏—Å—Ç–∏—á–Ω—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
                    'percentile_95': float,  # –û–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π
                    'prob_profit': float,    # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–±—ã–ª–∏ ‚úÖ NEW
                    'prob_ruin': float       # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫—Ä–∞—Ö–∞ ‚úÖ NEW
                }
            }
        """
        if not trades:
            logger.warning("No trades provided for Monte Carlo simulation")
            return self._empty_result()
        
        logger.info(f"Starting Monte Carlo: {num_simulations} simulations, {len(trades)} trades")
        
        simulations = []
        final_capitals = []
        
        for sim_idx in range(num_simulations):
            # Randomly shuffle trades
            shuffled_trades = np.random.choice(trades, size=len(trades), replace=True)
            
            # Calculate equity curve
            capital = initial_capital
            equity_curve = [capital]
            
            for trade in shuffled_trades:
                pnl = trade.get('pnl', 0)
                capital += pnl
                equity_curve.append(capital)
            
            final_capital = capital
            total_return = (final_capital - initial_capital) / initial_capital
            max_drawdown = self._calculate_max_drawdown(equity_curve, initial_capital)
            
            simulations.append({
                'simulation_index': sim_idx,
                'final_capital': final_capital,
                'total_return': total_return,
                'max_drawdown': max_drawdown
            })
            
            final_capitals.append(final_capital)
        
        # Calculate statistics
        final_capitals = np.array(final_capitals)
        returns = (final_capitals - initial_capital) / initial_capital
        
        # ‚úÖ NEW: Probability calculations
        prob_profit = np.sum(final_capitals > initial_capital) / num_simulations
        prob_ruin = np.sum(final_capitals < initial_capital * 0.5) / num_simulations  # 50% loss = ruin
        
        statistics = {
            'mean_return': float(np.mean(returns)),
            'std_return': float(np.std(returns)),
            'percentile_5': float(np.percentile(returns, 5)),
            'percentile_95': float(np.percentile(returns, 95)),
            'prob_profit': float(prob_profit),      # ‚úÖ NEW
            'prob_ruin': float(prob_ruin),          # ‚úÖ NEW
            'median_return': float(np.median(returns)),
            'best_case': float(np.max(returns)),
            'worst_case': float(np.min(returns))
        }
        
        logger.info(
            f"MC completed: mean={statistics['mean_return']:.2%}, "
            f"prob_profit={prob_profit:.1%}, prob_ruin={prob_ruin:.1%}"
        )
        
        return {
            'simulations': simulations,
            'statistics': statistics
        }
    
    def _calculate_max_drawdown(self, equity_curve: list[float], initial: float) -> float:
        """Calculate maximum drawdown from equity curve"""
        peak = initial
        max_dd = 0.0
        
        for equity in equity_curve:
            if equity > peak:
                peak = equity
            dd = (peak - equity) / peak if peak > 0 else 0
            if dd > max_dd:
                max_dd = dd
        
        return max_dd
    
    def _empty_result(self) -> dict:
        """Empty result for no trades case"""
        return {
            'simulations': [],
            'statistics': {
                'mean_return': 0.0,
                'std_return': 0.0,
                'percentile_5': 0.0,
                'percentile_95': 0.0,
                'prob_profit': 0.0,
                'prob_ruin': 0.0
            }
        }
```

**–î–µ–π—Å—Ç–≤–∏—è:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `backend/optimization/monte_carlo_simulator.py`
2. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `prob_profit` –∏ `prob_ruin` (—Å–µ–π—á–∞—Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç)
3. ‚úÖ –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É –∏–∑ 2 —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π
4. ‚ùå –£–¥–∞–ª–∏—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
5. ‚úÖ –ù–∞–ø–∏—Å–∞—Ç—å unit tests

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∏—ë–º–∫–∏:**
- [ ] `prob_profit` –∏ `prob_ruin` —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è
- [ ] –í—Å–µ —Å—Ç–∞—Ä—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ deprecated
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

---

## –ó–ê–î–ê–ß–ê 2: –°–û–ó–î–ê–¢–¨ DATAMANAGER –ö–õ–ê–°–° (2 –¥–Ω—è)

### –ü—Ä–æ–±–ª–µ–º–∞
–¢–ó 3.1.2 —è–≤–Ω–æ —Ç—Ä–µ–±—É–µ—Ç:
```python
class DataManager:
    def load_historical(limit=1000) -> pd.DataFrame
    def update_cache() -> None
    def get_multi_timeframe(timeframes: list) -> dict
```

–¢–µ–∫—É—â–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª —Ä–∞–∑–±—Ä–æ—Å–∞–Ω –º–µ–∂–¥—É `BybitAdapter` –∏ `DataService`.

### –†–µ—à–µ–Ω–∏–µ

**–§–∞–π–ª:** `backend/services/data_manager.py`

```python
"""
DataManager - –§–∞—Å–∞–¥ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏

–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó 3.1:
- –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã–º–∏
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (Parquet + DB)
- Multi-timeframe support
"""

import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Any

import pandas as pd
from loguru import logger

from backend.services.adapters.bybit import BybitAdapter
from backend.services.data_service import DataService


class DataManager:
    """
    –¢–ó 3.1.2 - –£–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫–æ–π, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    - symbol: str - –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (BTCUSDT, ETHUSDT, etc.)
    - timeframe: str - –¢–∞–π–º—Ñ—Ä–µ–π–º ('1', '5', '15', '60', '240', 'D')
    - start_date: datetime - –ù–∞—á–∞–ª–æ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞
    - end_date: datetime - –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞
    - cache_dir: str - –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∫—ç—à–∞
    
    –ú–µ—Ç–æ–¥—ã:
    - load_historical(limit=1000) -> pd.DataFrame
    - update_cache() -> None
    - get_multi_timeframe(timeframes: list) -> dict[str, pd.DataFrame]
    """
    
    def __init__(
        self,
        symbol: str,
        timeframe: str,
        start_date: datetime | None = None,
        end_date: datetime | None = None,
        cache_dir: str = "data/ohlcv"
    ):
        self.symbol = symbol.upper()
        self.timeframe = timeframe
        self.start_date = start_date or (datetime.now() - timedelta(days=365))
        self.end_date = end_date or datetime.now()
        self.cache_dir = Path(cache_dir)
        
        # Initialize adapters
        self.bybit = BybitAdapter()
        
        # Ensure cache directory exists
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(
            f"DataManager initialized: {self.symbol} @ {self.timeframe}, "
            f"cache={self.cache_dir}"
        )
    
    def load_historical(self, limit: int = 1000) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        
        1. –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ Parquet –∫—ç—à–∞
        2. –ï—Å–ª–∏ –Ω–µ—Ç - –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –∏–∑ Bybit API
        3. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –∫—ç—à
        
        Args:
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ä–æ–≤ (–º–∞–∫—Å–∏–º—É–º)
        
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ [timestamp, open, high, low, close, volume]
        """
        logger.info(f"Loading historical data for {self.symbol} @ {self.timeframe}, limit={limit}")
        
        # Try to load from Parquet cache
        cache_path = self._get_cache_path()
        
        if cache_path.exists():
            logger.info(f"Loading from cache: {cache_path}")
            df = pd.read_parquet(cache_path)
            
            # Filter by date range
            df = df[
                (df['timestamp'] >= self.start_date) &
                (df['timestamp'] <= self.end_date)
            ]
            
            if len(df) >= limit:
                logger.info(f"Cache hit: {len(df)} bars loaded")
                return df.tail(limit)
            else:
                logger.warning(f"Cache has only {len(df)} bars, need {limit}. Fetching from API...")
        
        # Fetch from Bybit API
        logger.info(f"Fetching from Bybit API: {self.symbol} @ {self.timeframe}")
        klines = self.bybit.get_klines(
            symbol=self.symbol,
            interval=self.timeframe,
            limit=limit
        )
        
        if not klines:
            logger.error("No data returned from Bybit API")
            return pd.DataFrame()
        
        # Convert to DataFrame
        df = pd.DataFrame(klines)
        
        # Normalize columns
        df = df.rename(columns={
            'open_time': 'timestamp',
            'open': 'open',
            'high': 'high',
            'low': 'low',
            'close': 'close',
            'volume': 'volume'
        })
        
        # Ensure timestamp is datetime
        if 'timestamp' in df.columns:
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        
        # Save to cache
        self.update_cache(df)
        
        logger.info(f"Loaded {len(df)} bars from API")
        return df
    
    def update_cache(self, data: pd.DataFrame | None = None) -> None:
        """
        –û–±–Ω–æ–≤–∏—Ç—å Parquet –∫—ç—à
        
        Args:
            data: DataFrame –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ None, –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å API)
        """
        if data is None:
            data = self.load_historical()
        
        cache_path = self._get_cache_path()
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Save to Parquet
        data.to_parquet(cache_path, compression='snappy', index=False)
        
        logger.info(f"Cache updated: {cache_path}, {len(data)} bars")
    
    def get_multi_timeframe(self, timeframes: list[str]) -> dict[str, pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞–º
        
        Args:
            timeframes: –°–ø–∏—Å–æ–∫ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ ['1', '5', '15', '60']
        
        Returns:
            dict[timeframe, DataFrame]
        """
        logger.info(f"Loading multi-timeframe data: {timeframes}")
        
        result = {}
        
        for tf in timeframes:
            # Create DataManager for each timeframe
            dm = DataManager(
                symbol=self.symbol,
                timeframe=tf,
                start_date=self.start_date,
                end_date=self.end_date,
                cache_dir=str(self.cache_dir)
            )
            
            df = dm.load_historical()
            result[tf] = df
            
            logger.info(f"  {tf}: {len(df)} bars")
        
        return result
    
    def _get_cache_path(self) -> Path:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ Parquet –∫—ç—à—É
        
        Format: data/ohlcv/{symbol}/{timeframe}.parquet
        """
        return self.cache_dir / self.symbol / f"{self.timeframe}.parquet"
```

**–î–µ–π—Å—Ç–≤–∏—è:**
1. ‚úÖ –°–æ–∑–¥–∞—Ç—å `backend/services/data_manager.py`
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å 3 –º–µ—Ç–æ–¥–∞ –∏–∑ –¢–ó
3. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å Parquet –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (–¢–ó 7.3)
4. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å BybitAdapter
5. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –º–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (BacktestEngine, optimize_tasks)
6. ‚úÖ –ù–∞–ø–∏—Å–∞—Ç—å unit tests

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∏—ë–º–∫–∏:**
- [ ] –ö–ª–∞—Å—Å `DataManager` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
- [ ] 3 –º–µ—Ç–æ–¥–∞ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [ ] Parquet –∫—ç—à —Å–æ–∑–¥–∞—ë—Ç—Å—è –≤ `data/ohlcv/{symbol}/{timeframe}.parquet`
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç

---

## –ó–ê–î–ê–ß–ê 3: BUY & HOLD RETURN (1 –¥–µ–Ω—å)

### –ü—Ä–æ–±–ª–µ–º–∞
–¢–ó 4.2 —Ç—Ä–µ–±—É–µ—Ç –º–µ—Ç—Ä–∏–∫—É "Buy & hold return":
```python
'Buy & hold return': float  # (last_price - first_price) / first_price * 100
```

–ü–æ–ª–µ –µ—Å—Ç—å –≤ Pydantic –º–æ–¥–µ–ª–∏, –Ω–æ —Ä–∞—Å—á—ë—Ç –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω.

### –†–µ—à–µ–Ω–∏–µ

**–§–∞–π–ª:** `backend/services/report_generator.py`

**–ù–∞–π—Ç–∏ —Å—Ç—Ä–æ–∫—É:**
```python
def generate_performance_csv(self) -> str:
    # ... existing code ...
    
    # ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞—Å—á—ë—Ç Buy & hold
```

**–ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞:**
```python
def generate_performance_csv(self) -> str:
    # ... existing code ...
    
    # ‚úÖ Calculate Buy & hold return
    buy_hold_return_usdt, buy_hold_return_pct = self._calculate_buy_hold_return()
    
    # ... use in CSV generation
```

**–î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥:**
```python
def _calculate_buy_hold_return(self) -> tuple[float, float]:
    """
    –†–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø–∞—Å—Å–∏–≤–Ω—É—é –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (Buy & Hold)
    
    Formula (–¢–ó 4.2):
    buy_hold_return = (last_price - first_price) / first_price * 100
    
    Returns:
        (usdt, percent)
    """
    if not self.all_trades:
        return 0.0, 0.0
    
    # Get first and last prices from trades
    first_trade = self.all_trades[0]
    last_trade = self.all_trades[-1]
    
    first_price = first_trade.get('entry_price', 0)
    last_price = last_trade.get('exit_price', first_trade.get('entry_price', 0))
    
    if first_price == 0:
        return 0.0, 0.0
    
    # Calculate return
    price_change = last_price - first_price
    pct_change = (price_change / first_price) * 100
    
    # Calculate USDT value (assuming same position size)
    position_value = first_trade.get('position_size_value', self.initial_capital)
    usdt_return = (price_change / first_price) * position_value
    
    logger.debug(
        f"Buy & hold: {first_price:.2f} ‚Üí {last_price:.2f} = "
        f"{pct_change:.2f}% (${usdt_return:.2f})"
    )
    
    return usdt_return, pct_change
```

**–î–µ–π—Å—Ç–≤–∏—è:**
1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å –º–µ—Ç–æ–¥ `_calculate_buy_hold_return`
2. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `generate_performance_csv`
3. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å —Ç–µ—Å—Ç—ã –≤ `tests/test_report_generator.py`
4. ‚úÖ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó —Ñ–æ—Ä–º—É–ª–µ

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Buy & hold return —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è
- [ ] –ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ Performance.csv
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç (16/16)

---

## –ó–ê–î–ê–ß–ê 4: SIGNAL EXIT (2 –¥–Ω—è)

### –ü—Ä–æ–±–ª–µ–º–∞
–¢–ó 3.2.2 —Ç—Ä–µ–±—É–µ—Ç –≤—ã—Ö–æ–¥ –ø–æ —Å–∏–≥–Ω–∞–ª—É:
```python
'signal_exit': {
    'enabled': True,
    'signals': ['opposite_signal', 'reversal_pattern']
}
```

–°–µ–π—á–∞—Å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.

### –†–µ—à–µ–Ω–∏–µ

#### 4.1 –û–±–Ω–æ–≤–∏—Ç—å Pydantic –º–æ–¥–µ–ª—å

**–§–∞–π–ª:** `backend/models/data_types.py`

**–ù–∞–π—Ç–∏:**
```python
class ExitConditions(BaseModel):
    take_profit: TakeProfitConfig
    stop_loss: StopLossConfig
    trailing_stop: TrailingStopConfig
    time_exit: TimeExitConfig
```

**–î–æ–±–∞–≤–∏—Ç—å:**
```python
class SignalExitConfig(BaseModel):
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤—ã—Ö–æ–¥–∞ –ø–æ —Å–∏–≥–Ω–∞–ª—É"""
    enabled: bool
    signals: list[str] = Field(
        default_factory=lambda: ['opposite_signal'],
        description="–¢–∏–ø—ã —Å–∏–≥–Ω–∞–ª–æ–≤ –≤—ã—Ö–æ–¥–∞"
    )


class ExitConditions(BaseModel):
    take_profit: TakeProfitConfig
    stop_loss: StopLossConfig
    trailing_stop: TrailingStopConfig
    time_exit: TimeExitConfig
    signal_exit: SignalExitConfig  # ‚úÖ NEW
```

#### 4.2 –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤ BacktestEngine

**–§–∞–π–ª:** `backend/core/backtest_engine.py`

**–ù–∞–π—Ç–∏ –º–µ—Ç–æ–¥ `_check_exit_conditions`:**
```python
def _check_exit_conditions(self, position, bar, bar_index, config):
    # ... existing TP/SL/Trailing logic ...
    
    # ‚úÖ NEW: Signal exit
    if config.get('signal_exit', {}).get('enabled', False):
        exit_signals = config['signal_exit'].get('signals', [])
        
        if 'opposite_signal' in exit_signals:
            # Check for opposite signal
            if self._has_opposite_signal(position, bar_index):
                return True, 'opposite_signal'
        
        if 'reversal_pattern' in exit_signals:
            # Check for reversal pattern
            if self._has_reversal_pattern(bar_index):
                return True, 'reversal_pattern'
    
    return False, None


def _has_opposite_signal(self, position: Position, bar_index: int) -> bool:
    """Check if opposite signal occurred"""
    strategy_type = self.config.get('type', 'ema_crossover')
    
    if strategy_type == 'ema_crossover':
        ema_fast = self.state.indicators['ema_fast'].iloc[bar_index]
        ema_slow = self.state.indicators['ema_slow'].iloc[bar_index]
        
        if position.side == 'long':
            # Exit long when fast crosses below slow
            prev_fast = self.state.indicators['ema_fast'].iloc[bar_index - 1]
            prev_slow = self.state.indicators['ema_slow'].iloc[bar_index - 1]
            
            return prev_fast >= prev_slow and ema_fast < ema_slow
        
        elif position.side == 'short':
            # Exit short when fast crosses above slow
            prev_fast = self.state.indicators['ema_fast'].iloc[bar_index - 1]
            prev_slow = self.state.indicators['ema_slow'].iloc[bar_index - 1]
            
            return prev_fast <= prev_slow and ema_fast > ema_slow
    
    return False
```

**–î–µ–π—Å—Ç–≤–∏—è:**
1. ‚úÖ –î–æ–±–∞–≤–∏—Ç—å `SignalExitConfig` –≤ Pydantic –º–æ–¥–µ–ª–∏
2. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `_has_opposite_signal` –≤ BacktestEngine
3. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `_has_reversal_pattern` (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
4. ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤ `_check_exit_conditions`
5. ‚úÖ –û–±–Ω–æ–≤–∏—Ç—å —Ç–µ—Å—Ç—ã

**–ö—Ä–∏—Ç–µ—Ä–∏–π –ø—Ä–∏—ë–º–∫–∏:**
- [ ] Signal exit —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] Opposite signal –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–µ—Ç–µ–∫—Ç–∏—Ä—É–µ—Ç—Å—è
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç
- [ ] Exit reason = 'opposite_signal' –≤ trades

---

## –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–ê–ó–´ 1

### Unit Tests

–°–æ–∑–¥–∞—Ç—å/–æ–±–Ω–æ–≤–∏—Ç—å —Ç–µ—Å—Ç—ã:

1. ‚úÖ `tests/test_walk_forward_optimizer.py`
   ```python
   def test_parameter_stability():
       """Test that parameter_stability is calculated"""
       # ...
   ```

2. ‚úÖ `tests/test_monte_carlo_simulator.py`
   ```python
   def test_prob_profit_and_prob_ruin():
       """Test that probabilities are calculated"""
       # ...
   ```

3. ‚úÖ `tests/test_data_manager.py`
   ```python
   def test_load_historical_from_cache():
       """Test Parquet cache loading"""
       # ...
   
   def test_multi_timeframe():
       """Test multi-TF loading"""
       # ...
   ```

4. ‚úÖ `tests/test_report_generator.py` (–æ–±–Ω–æ–≤–∏—Ç—å)
   ```python
   def test_buy_hold_return_calculation():
       """Test Buy & hold return formula"""
       # ...
   ```

5. ‚úÖ `tests/test_backtest_engine.py` (–æ–±–Ω–æ–≤–∏—Ç—å)
   ```python
   def test_signal_exit_opposite():
       """Test exit on opposite signal"""
       # ...
   ```

### Integration Tests

6. ‚úÖ `tests/integration/test_wfo_end_to_end.py`
   ```python
   def test_walk_forward_full_cycle():
       """Test WFO from API to results"""
       # ...
   ```

---

## –ö–†–ò–¢–ï–†–ò–ò –ü–†–ò–Å–ú–ö–ò –§–ê–ó–´ 1

### Checklist

- [ ] **–ó–∞–¥–∞—á–∞ 1**: –ö–æ–Ω—Å–æ–ª–∏–¥–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
  - [ ] WalkForwardOptimizer –µ–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å
  - [ ] MonteCarloSimulator –µ–¥–∏–Ω—ã–π –∫–ª–∞—Å—Å
  - [ ] parameter_stability —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
  - [ ] prob_profit/prob_ruin —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã
  - [ ] –°—Ç–∞—Ä—ã–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ deprecated
  - [ ] –¢–µ—Å—Ç—ã: 20/20 passing

- [ ] **–ó–∞–¥–∞—á–∞ 2**: DataManager –∫–ª–∞—Å—Å
  - [ ] –ö–ª–∞—Å—Å —Å–æ–∑–¥–∞–Ω
  - [ ] 3 –º–µ—Ç–æ–¥–∞ —Ä–∞–±–æ—Ç–∞—é—Ç (load_historical, update_cache, get_multi_timeframe)
  - [ ] Parquet –∫—ç—à —Å–æ–∑–¥–∞—ë—Ç—Å—è
  - [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å BacktestEngine
  - [ ] –¢–µ—Å—Ç—ã: 15/15 passing

- [ ] **–ó–∞–¥–∞—á–∞ 3**: Buy & hold return
  - [ ] –ú–µ—Ç–æ–¥ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω
  - [ ] –ó–Ω–∞—á–µ–Ω–∏–µ –≤ Performance.csv
  - [ ] –§–æ—Ä–º—É–ª–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –¢–ó
  - [ ] –¢–µ—Å—Ç—ã: 16/16 passing (test_report_generator)

- [ ] **–ó–∞–¥–∞—á–∞ 4**: Signal exit
  - [ ] SignalExitConfig –º–æ–¥–µ–ª—å
  - [ ] –õ–æ–≥–∏–∫–∞ –≤ BacktestEngine
  - [ ] opposite_signal —Ä–∞–±–æ—Ç–∞–µ—Ç
  - [ ] Exit reason —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è
  - [ ] –¢–µ—Å—Ç—ã: 30/30 passing

### –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

| –ú–µ—Ç—Ä–∏–∫–∞ | –î–æ –§–∞–∑—ã 1 | –ü–æ—Å–ª–µ –§–∞–∑—ã 1 | –¶–µ–ª—å |
|---------|-----------|--------------|------|
| –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¢–ó MVP | 92% | 100% | ‚úÖ 100% |
| –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ | 75% | 85% | ‚úÖ 85% |
| –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –±–∞–≥–∏ | 4 | 0 | ‚úÖ 0 |
| –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–¥–∞ | 5 –º–µ—Å—Ç | 0 | ‚úÖ 0 |

---

## TIMELINE

### –ù–µ–¥–µ–ª—è 1

**–î–µ–Ω—å 1-2:** –ó–∞–¥–∞—á–∞ 1 (WFO + Monte Carlo)
- –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã
- –ú–∏–≥—Ä–∞—Ü–∏—è –ª–æ–≥–∏–∫–∏
- –ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã

**–î–µ–Ω—å 3:** –ó–∞–¥–∞—á–∞ 2 (DataManager)
- –°–æ–∑–¥–∞—Ç—å –∫–ª–∞—Å—Å
- Parquet –∫—ç—à
- –¢–µ—Å—Ç—ã

**–î–µ–Ω—å 4:** –ó–∞–¥–∞—á–∞ 3 + 4 (Buy & hold + Signal exit)
- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±–µ –∑–∞–¥–∞—á–∏
- –¢–µ—Å—Ç—ã

**–î–µ–Ω—å 5:** Code review + QA
- –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

### –ù–µ–¥–µ–ª—è 2 (buffer)

**–î–µ–Ω—å 6-7:** –ë–∞–≥-—Ñ–∏–∫—Å—ã
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

**–î–µ–Ω—å 8-10:** –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –§–∞–∑–µ 2
- Planning
- Documentation
- Sprint review

---

## NEXT STEPS –ü–û–°–õ–ï –§–ê–ó–´ 1

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:

1. ‚úÖ **Release v0.9-beta** (MVP ready)
2. üü° **–ù–∞—á–∞—Ç—å –§–∞–∑—É 2**: –£—Ä–æ–≤–Ω–∏ –¥–æ—Å—Ç—É–ø–∞ + Commission –º–æ–¥–µ–ª—å
3. üìä **Performance benchmarks**: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¢–ó 9.2 —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
4. üìù **Update –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è**: README, API docs

**–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ –§–∞–∑—ã 1:** 25 –æ–∫—Ç—è–±—Ä—è 2025  
**–¶–µ–ª–µ–≤–∞—è –¥–∞—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:** 8 –Ω–æ—è–±—Ä—è 2025  
**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π:** Development Team
