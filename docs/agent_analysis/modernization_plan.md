# ğŸ”§ Agent Infrastructure Modernization Plan

> **Created:** 2026-02-11  
> **Based on:** Engineering audit by 3 LLM agents (DeepSeek, Qwen, Perplexity)  
> **Scope:** `backend/agents/` â€” 27 files, 16,127 LOC  
> **Average Score:** 6.73/10 (DeepSeek 6.5, Qwen 7.5, Perplexity 6.2)

---

## ğŸ“Š Cross-Agent Consensus Matrix

| Category           | DeepSeek | Qwen | Perplexity | **Avg** | **Consensus** |
| ------------------ | -------- | ---- | ---------- | ------- | ------------- |
| Architecture       | 6        | 7    | 5          | **6.0** | âš ï¸ Needs work |
| LLM Connections    | 7        | 8    | 7          | **7.3** | âœ… Good       |
| Prompt Engineering | 7        | 6    | 8          | **7.0** | âœ… Good       |
| Security           | 6        | 7    | 7          | **6.7** | âš ï¸ Adequate   |
| Memory             | 4        | 5    | 4          | **4.3** | ğŸ”´ Critical   |
| Consensus System   | 8        | 8    | 8          | **8.0** | âœ… Strong     |
| Testing            | 3        | 4    | 2          | **3.0** | ğŸ”´ Critical   |
| Code Quality       | 7        | 7    | 4          | **6.0** | âš ï¸ Needs work |
| Scalability        | 5        | 6    | 6          | **5.7** | âš ï¸ Needs work |

### Key Observations

- **Testing (3.0)** and **Memory (4.3)** are critical bottlenecks â€” all 3 agents agree
- **Consensus system (8.0)** is the strongest module â€” unanimous praise
- **LLM Connections (7.3)** and **Prompt Engineering (7.0)** are solid but improvable
- Biggest disagreement: Code Quality (Perplexity scored 4 vs others' 7) â€” Perplexity focused on structural issues

---

## ğŸ”´ Critical Issues â€” All 3 Agents Agree

### Issue #1: `unified_agent_interface.py` God-Class (1875 LOC)

**Severity:** HIGH | **Agreement:** 3/3 agents | **Priority:** P0

| Agent      | Diagnosis                                                                |
| ---------- | ------------------------------------------------------------------------ |
| DeepSeek   | "Massive monolithic file with multiple responsibilities. Violates SRP."  |
| Qwen       | "Zero test coverage for fallback routing, key rotation, MCP switching."  |
| Perplexity | "1875 LOC god-class. Duplicates APIKey class already in key_manager.py." |

**Proposed Fix:**

```
unified_agent_interface.py (1875 LOC)
  â”œâ”€â”€ llm/client_deepseek.py    (~200 LOC) â€” DeepSeek-specific client
  â”œâ”€â”€ llm/client_qwen.py        (~200 LOC) â€” Qwen-specific client
  â”œâ”€â”€ llm/client_perplexity.py  (~200 LOC) â€” Perplexity-specific client
  â”œâ”€â”€ orchestrator.py           (~300 LOC) â€” Routing, fallback, orchestration
  â”œâ”€â”€ health_monitor.py         (~150 LOC) â€” Health checks, diagnostics
  â””â”€â”€ agent_interface.py        (~300 LOC) â€” Public API, thin facade
```

**Effort:** Large (3-5 days) | **Impact:** High

---

### Issue #2: Zero Test Coverage for 28K LOC

**Severity:** HIGH | **Agreement:** 3/3 agents | **Priority:** P0

| Agent      | Diagnosis                                                      |
| ---------- | -------------------------------------------------------------- |
| DeepSeek   | "No test files. Critical systems lack unit tests. Target 70%+" |
| Qwen       | "Zero coverage. No mocks, no fixtures, no CI pipeline."        |
| Perplexity | "No visible tests in 28K LOC. Target 80%+"                     |

**Proposed Structure:**

```
tests/
  agents/
    unit/
      test_api_key_pool.py        â€” Key rotation, pool exhaustion
      test_circuit_breaker.py     â€” State transitions, recovery
      test_prompt_guard.py        â€” Injection detection, false positives
      test_response_parser.py     â€” JSON/markdown parsing, edge cases
      test_rate_limiter.py        â€” Token bucket, rate enforcement
      test_key_manager.py         â€” Encryption, decryption, None handling
      test_prompt_optimizer.py    â€” Token reduction, metric filtering
    integration/
      test_llm_fallback.py        â€” Provider failure â†’ fallback routing
      test_consensus_flow.py      â€” Full deliberation â†’ consensus
      test_memory_persistence.py  â€” Save/load/TTL/eviction
    e2e/
      test_agent_workflow.py      â€” Complete agent task execution
```

**Effort:** Large (1-2 weeks) | **Impact:** High

---

### Issue #3: Memory System â€” No Persistence, No Concurrency

**Severity:** HIGH | **Agreement:** 3/3 agents | **Priority:** P1

| Agent      | Diagnosis                                                                                   |
| ---------- | ------------------------------------------------------------------------------------------- |
| DeepSeek   | "File-based JSON storage, no concurrency control, no TTL/cleanup."                          |
| Qwen       | "All memory tiers in-memory only. Data loss on restart. vector_store.py exists but unused." |
| Perplexity | "File-based memory won't scale. Replace with Redis/memcached."                              |

**Proposed Fix (2 phases):**

1. **Phase A (quick win):** SQLite-backed persistence for `HierarchicalMemory` with TTL and LRU eviction
2. **Phase B (optional):** Redis adapter for multi-node deployment

**Effort:** Medium (2-3 days for Phase A) | **Impact:** High

---

## âš ï¸ Significant Issues â€” 2/3 Agents Agree

### Issue #4: `APIKey` Class Duplicated 3x

**Agents:** DeepSeek (implied), Perplexity (explicit)

- `unified_agent_interface.py` â€” has its own APIKey
- `key_manager.py` â€” has APIKey with decryption
- `api_key_pool.py` â€” has APIKey with pool management

**Fix:** Single source of truth in `models.py`, delete duplicates.  
**Effort:** Small (2-4 hours) | **Impact:** Medium

### Issue #5: Mixed Russian/English in Code

**Agents:** DeepSeek, Perplexity

- `models.py`, various docstrings have Russian comments
- Reduces maintainability for international collaboration

**Fix:** Standardize to English. Run automated scan + manual review.  
**Effort:** Small (1-2 hours) | **Impact:** Low-Medium

### Issue #6: `connections.py` Oversized (969 LOC)

**Agents:** Perplexity (explicit), DeepSeek (implied via RateLimiter issues)

**Fix:** Split into `connections/base.py`, `connections/rate_limiter.py`, `connections/models.py`  
**Effort:** Medium (1-2 days) | **Impact:** Medium

---

## ğŸ“‹ Unique Insights by Agent

### DeepSeek Only

- **Dead letter queue with retry policies** â€” failed LLM calls should be queued for retry
- **Cost tracking per agent** â€” no budget alerts or spend monitoring
- **Configuration validation at startup** â€” no fail-fast on missing config

### Qwen Only

- **Circular import risk** â€” `unified_agent_interface.py` â†” `key_manager.py` â†” `api_key_pool.py` â†” `circuit_breaker_manager.py` all reference each other via lazy imports
- **Token budgeting in RateLimiter** â€” currently tracks only request count, not tokens. Needs `tiktoken` integration
- **PromptGuard semantic jailbreaks** â€” regex-only is vulnerable; needs LLM-based classifier fallback
- **Pydantic model versioning** â€” no schema migration for `models.py`
- **Hardcoded thresholds in templates.py** â€” values like "Max Drawdown < 15%" should be template variables

### Perplexity Only

- **src/ layout migration** â€” `backend/agents/` should follow Python packaging best practices
- **pre-commit hooks** â€” enforce `black`, `isort`, `mypy`, `ruff` before commit
- **Docker/K8s deployment manifests** â€” no container orchestration for agents

---

## ğŸ—ï¸ Modernization Roadmap

### Phase 1: Foundation (Week 1-2) â€” P0 Items

| #   | Task                                                        | Source              | Effort | Impact    |
| --- | ----------------------------------------------------------- | ------------------- | ------ | --------- |
| 1.1 | Split `unified_agent_interface.py` into 5-6 focused modules | All 3               | Large  | ğŸŸ¢ High   |
| 1.2 | Consolidate `APIKey` into single `models.py`                | Perplexity+DeepSeek | Small  | ğŸŸ¡ Medium |
| 1.3 | Create pytest structure with 20+ critical tests             | All 3               | Large  | ğŸŸ¢ High   |
| 1.4 | Split `connections.py` into submodules                      | Perplexity+DeepSeek | Medium | ğŸŸ¡ Medium |
| 1.5 | Standardize English-only comments                           | DeepSeek+Perplexity | Small  | ğŸŸ¡ Medium |

**Success Criteria:** No file > 500 LOC, 50+ test cases, 0 duplicate classes

### Phase 2: Reliability (Week 3-4) â€” P1 Items

| #   | Task                                                   | Source              | Effort | Impact    |
| --- | ------------------------------------------------------ | ------------------- | ------ | --------- |
| 2.1 | SQLite-backed `HierarchicalMemory` with TTL            | All 3               | Medium | ğŸŸ¢ High   |
| 2.2 | Token-aware `RateLimiter` (tiktoken integration)       | Qwen                | Small  | ğŸŸ¢ High   |
| 2.3 | Structured logging with correlation IDs                | DeepSeek+Perplexity | Small  | ğŸŸ¢ High   |
| 2.4 | Resolve circular imports (dependency injection)        | Qwen                | Medium | ğŸŸ¡ Medium |
| 2.5 | Template variables for hardcoded thresholds            | Qwen                | Small  | ğŸŸ¡ Medium |
| 2.6 | PromptGuard semantic fallback (lightweight classifier) | Qwen                | Medium | ğŸŸ¡ Medium |
| 2.7 | Configuration validation at startup                    | DeepSeek            | Small  | ğŸŸ¡ Medium |

**Success Criteria:** Memory persists across restarts, rate limiting tracks tokens, all logs have request IDs

### Phase 3: Scale & Quality (Month 2) â€” P2 Items

| #   | Task                                      | Source              | Effort | Impact    |
| --- | ----------------------------------------- | ------------------- | ------ | --------- |
| 3.1 | Cost tracking and budget alerts per agent | DeepSeek            | Medium | ğŸŸ¡ Medium |
| 3.2 | A/B testing framework for prompts         | DeepSeek+Qwen       | Medium | ğŸŸ¡ Medium |
| 3.3 | Pre-commit hooks (ruff, mypy enforcement) | Perplexity          | Small  | ğŸŸ¡ Medium |
| 3.4 | Secret rotation automation                | DeepSeek            | Medium | ğŸŸ¡ Medium |
| 3.5 | Load testing suite for API key rotation   | DeepSeek+Qwen       | Medium | ğŸŸ¡ Medium |
| 3.6 | Dead letter queue for failed LLM calls    | DeepSeek            | Medium | ğŸŸ¡ Medium |
| 3.7 | OpenTelemetry distributed tracing         | DeepSeek+Perplexity | Medium | ğŸŸ¡ Medium |

**Success Criteria:** Cost dashboards active, prompt versions tracked, tracing across agent calls

---

## ğŸ“ˆ Expected Score Improvement

| Category           | Current Avg | Target (Phase 1) | Target (Phase 2) | Target (Phase 3) |
| ------------------ | ----------- | ---------------- | ---------------- | ---------------- |
| Architecture       | 6.0         | **8.0**          | 8.5              | 9.0              |
| LLM Connections    | 7.3         | 7.5              | **8.5**          | 9.0              |
| Prompt Engineering | 7.0         | 7.0              | **8.0**          | 8.5              |
| Security           | 6.7         | 7.0              | **8.0**          | 8.5              |
| Memory             | 4.3         | 4.5              | **7.5**          | 8.0              |
| Consensus          | 8.0         | 8.0              | 8.0              | **8.5**          |
| Testing            | 3.0         | **6.5**          | 7.5              | 8.5              |
| Code Quality       | 6.0         | **8.0**          | 8.5              | 9.0              |
| Scalability        | 5.7         | 6.0              | **7.5**          | 8.5              |
| **Overall**        | **6.0**     | **7.0**          | **7.8**          | **8.6**          |

---

## ğŸ¯ Agreed Strengths (Do NOT Refactor)

All 3 agents unanimously praised these â€” preserve and extend:

1. **Consensus System (8.0)** â€” Multi-agent deliberation with structured signal exchange
2. **LLM Provider Abstraction** â€” Good connection pooling, circuit breakers, adaptive retries
3. **Prompt Engineering Stack** â€” Context builder, templating, parsing, optimization
4. **Security Layers** â€” Prompt guard, output validator, key encryption, rate limiting
5. **MCP Tool Registry** â€” Auto-schema generation, tool introspection

---

## ğŸ“Š Audit Metadata

| Metric                  | Value         |
| ----------------------- | ------------- |
| Total audit time        | 105.6 seconds |
| Total tokens consumed   | 70,791        |
| Total prompt tokens     | 67,095        |
| Total completion tokens | 3,696         |
| Avg latency per agent   | 31.9s         |
| Files audited           | 27            |
| LOC audited             | 16,127        |
| Audit date              | 2026-02-11    |

---

_Generated by cross-referencing engineering audits from DeepSeek (deepseek-chat), Qwen (qwen-plus), and Perplexity (sonar-pro). See `engineering_audit_results.json` for raw data._
