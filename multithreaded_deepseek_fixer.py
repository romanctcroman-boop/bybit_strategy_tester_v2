"""
ğŸ”¥ Multithreaded DeepSeek Code Review & Fix Generator
Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ThreadPoolExecutor + 8 DeepSeek API ĞºĞ»ÑÑ‡ĞµĞ¹ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€Ğ°Ğ»Ğ»ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°

Features:
- 7x critical issues analysis (parallel execution)
- Detailed fix plans generation
- Code review + refactoring recommendations
- Ready-to-apply code patches
"""

import json
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import httpx
from dotenv import load_dotenv
import time

load_dotenv()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PROJECT_ROOT = Path(__file__).parent
OUTPUT_DIR = PROJECT_ROOT / "deepseek_fix_plans"
OUTPUT_DIR.mkdir(exist_ok=True)

# Load 8 DeepSeek API keys
DEEPSEEK_KEYS = [
    os.getenv("DEEPSEEK_API_KEY"),
    os.getenv("DEEPSEEK_API_KEY_1"),
    os.getenv("DEEPSEEK_API_KEY_2"),
    os.getenv("DEEPSEEK_API_KEY_3"),
    os.getenv("DEEPSEEK_API_KEY_4"),
    os.getenv("DEEPSEEK_API_KEY_5"),
    os.getenv("DEEPSEEK_API_KEY_6"),
    os.getenv("DEEPSEEK_API_KEY_7"),
]
DEEPSEEK_KEYS = [k for k in DEEPSEEK_KEYS if k]

DEEPSEEK_URL = "https://api.deepseek.com/chat/completions"
MAX_WORKERS = min(7, len(DEEPSEEK_KEYS))  # 7 critical issues

print(f"ğŸ”‘ Loaded {len(DEEPSEEK_KEYS)} DeepSeek API keys")
print(f"ğŸš€ Max parallel workers: {MAX_WORKERS}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CRITICAL ISSUES (from Perplexity audit)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CRITICAL_ISSUES = [
    {
        "id": 1,
        "priority": "HIGH",
        "category": "Backend Tasks (Celery + async/await)",
        "problem": """
ĞĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ async/await Ñ Celery tasks.
Celery Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµÑ‚ async def Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾.

Ğ¤Ğ°Ğ¹Ğ»: backend/tasks/optimize_tasks.py (3KB)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°:
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ async def Ğ´Ğ»Ñ Celery tasks
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ñ eventlet/gevent
- Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ¸ Ğ¸ Ğ½ĞµĞ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ
""",
        "task": """
ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ Ğ³Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹ code review backend/tasks/optimize_tasks.py:

1. ĞĞ°Ğ¹Ğ´Ğ¸ Ğ²ÑĞµ async def Celery tasks
2. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹, Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ»Ğ¸ Ğ½ÑƒĞ¶ĞµĞ½ async/await
3. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ Ñ€ĞµÑ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³:
   - Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A: ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ² sync Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
   - Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ B: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Celery Ñ eventlet/gevent workers
4. Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ´-Ğ¿Ğ°Ñ‚Ñ‡ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
5. ĞÑ†ĞµĞ½Ğ¸ Ñ€Ğ¸ÑĞºĞ¸ Ğ¸ breaking changes

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- analysis: Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹
- current_code_issues: ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°Ğ¼Ğ¸
- refactoring_options: 2-3 Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ° Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ
- recommended_solution: Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ Ñ Ğ¾Ğ±Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼
- code_patch: Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ´ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¼ĞµĞ½Ñ‹
- migration_steps: Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
- risks: Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ñ€Ğ¸ÑĞºĞ¸
- testing_strategy: ĞºĞ°Ğº Ğ¿Ñ€Ğ¾Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
""",
        "files": ["backend/tasks/optimize_tasks.py"]
    },
    {
        "id": 2,
        "priority": "CRITICAL",
        "category": "Security (API Keys & Secrets)",
        "problem": """
ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑƒÑ‚ĞµÑ‡ĞºĞ° secrets Ğ² JSON Ñ„Ğ°Ğ¹Ğ»Ğ°Ñ… Ğ¸ Ğ½ĞµĞ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ API ĞºĞ»ÑÑ‡ĞµĞ¹.

Ğ¤Ğ°Ğ¹Ğ»Ñ‹:
- backend/agents/deepseek.py (41KB)
- backend/agents/deepseek_cli.py (13KB)
- Multiple *_RESULTS.json files (145KB+)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ hardcoded API ĞºĞ»ÑÑ‡Ğ¸
- ĞĞµÑ‚ secrets vault Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
- JSON Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ¼Ğ¾Ğ³ÑƒÑ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ°Ñ‚ÑŒ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
""",
        "task": """
ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ security audit API key management:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ backend/agents/deepseek.py Ğ¸ deepseek_cli.py
2. ĞĞ°Ğ¹Ğ´Ğ¸ Ğ²ÑĞµ Ğ¼ĞµÑÑ‚Ğ° Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ/Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ API ĞºĞ»ÑÑ‡ĞµĞ¹
3. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ JSON Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ½Ğ° ÑƒÑ‚ĞµÑ‡ĞºÑƒ secrets
4. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ secure architecture:
   - Environment variables best practices
   - Secrets rotation Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼
   - Encryption at rest
   - Audit logging
5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ implementation plan

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- security_audit: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ ÑƒÑĞ·Ğ²Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
- current_implementation: ĞºĞ°Ğº ÑĞµĞ¹Ñ‡Ğ°Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚
- threat_model: Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ°Ñ‚Ğ°ĞºĞ¸
- secure_architecture: Ğ½Ğ¾Ğ²Ğ°Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°
- code_changes: ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ´Ğ°
- secrets_management_strategy: ĞºĞ°Ğº ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸
- encryption_approach: ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
- compliance_checklist: Ñ‚Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸
""",
        "files": ["backend/agents/deepseek.py", "backend/agents/deepseek_cli.py"]
    },
    {
        "id": 3,
        "priority": "HIGH",
        "category": "API Design (RESTful principles)",
        "problem": """
ĞĞµĞºĞ¾Ğ½ÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ½Ğ¾Ğµ Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ API endpoints, Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğµ RESTful Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ².

Ğ¤Ğ°Ğ¹Ğ»Ñ‹: backend/api/* (45 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- Ğ“Ğ»Ğ°Ğ³Ğ¾Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ (/createBacktest, /getData)
- ĞĞµÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ HTTP Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ²ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ API
""",
        "task": """
ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ review API endpoints:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ²ÑĞµ 45 Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² backend/api/
2. Ğ¡Ğ¾ÑÑ‚Ğ°Ğ²ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ RESTful Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ²
3. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ Ğ½Ğ¾Ğ²ÑƒÑ naming convention
4. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ migration plan Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ API
5. ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ backward compatibility strategy

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- current_api_analysis: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… endpoints
- violations: ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ½Ğ°Ñ€ÑƒÑˆĞµĞ½Ğ¸Ğ¹ RESTful
- naming_convention: Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ° Ğ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- endpoint_mapping: old -> new URLs
- http_method_corrections: Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ²
- versioning_strategy: ĞºĞ°Ğº Ğ²ĞµÑ€ÑĞ¸Ğ¾Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ API
- backward_compatibility: ĞºĞ°Ğº Ğ½Ğµ ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
- migration_timeline: Ğ¿Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
- documentation_updates: Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸
""",
        "files": ["backend/api/"]
    },
    {
        "id": 4,
        "priority": "HIGH",
        "category": "Test Coverage",
        "problem": """
ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ test coverage, Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Coverage.py Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸.

Ğ¤Ğ°Ğ¹Ğ»Ñ‹: tests/* (163 Ñ‚ĞµÑÑ‚Ğ°)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- ĞĞµÑ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ñ coverage
- ĞĞµĞ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾, ĞºĞ°ĞºĞ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸ ĞºĞ¾Ğ´Ğ° Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ñ‹ Ñ‚ĞµÑÑ‚Ğ°Ğ¼Ğ¸
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ CI/CD integration Ğ´Ğ»Ñ coverage reports
""",
        "task": """
Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ comprehensive testing strategy:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ 163 Ñ‚ĞµÑÑ‚Ğ°
2. ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸ gaps Ğ² coverage (ĞºĞ°ĞºĞ¸Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸ Ğ½Ğµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ñ‹)
3. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ Coverage.py integration
4. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ CI/CD pipeline Ğ´Ğ»Ñ coverage tracking
5. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸ target coverage Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ (80%+ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- current_tests_analysis: Ñ‡Ñ‚Ğ¾ Ñ‚ĞµÑÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ ÑĞµĞ¹Ñ‡Ğ°Ñ
- coverage_gaps: Ğ½ĞµĞ¿Ğ¾ĞºÑ€Ñ‹Ñ‚Ñ‹Ğµ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ÑƒĞ»Ğ¸
- coverage_setup: ĞºĞ°Ğº Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Coverage.py
- ci_cd_integration: Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ pytest + coverage
- target_metrics: Ñ†ĞµĞ»ĞµĞ²Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»Ğ¸ (% Ğ¿Ğ¾ Ğ¼Ğ¾Ğ´ÑƒĞ»ÑĞ¼)
- test_generation_plan: Ğ³Ğ´Ğµ Ğ½ÑƒĞ¶Ğ½Ñ‹ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ñ‚ĞµÑÑ‚Ñ‹
- critical_paths_to_test: Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚Ğ½Ñ‹Ğµ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¸
- automation_strategy: Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²
""",
        "files": ["tests/", "pytest.ini", ".github/workflows/"]
    },
    {
        "id": 5,
        "priority": "MEDIUM",
        "category": "TypeScript Strictness (Frontend)",
        "problem": """
ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ°Ñ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ÑÑ‚ÑŒ TypeScript, Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ 'any' Ñ‚Ğ¸Ğ¿Ğ¾Ğ².

Ğ¤Ğ°Ğ¹Ğ»Ñ‹: frontend/src/components/* (50 ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- ĞĞµÑ‚ strict mode Ğ² tsconfig.json
- Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ any Ğ²Ğ¼ĞµÑÑ‚Ğ¾ explicit types
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ type safety Ğ´Ğ»Ñ props
""",
        "task": """
ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ TypeScript quality audit:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ tsconfig.json Ğ½Ğ° strict settings
2. ĞĞ°Ğ¹Ğ´Ğ¸ Ğ²ÑĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ 'any' Ñ‚Ğ¸Ğ¿Ğ° Ğ² ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ°Ñ…
3. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ type coverage Ğ´Ğ»Ñ props Ğ¸ state
4. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ migration plan Ğº strict TypeScript
5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ type definitions Ğ´Ğ»Ñ Ğ²ÑĞµÑ… ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¾Ğ²

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- tsconfig_analysis: Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
- any_usage_report: Ğ³Ğ´Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ 'any'
- type_coverage: Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚ typed vs untyped ĞºĞ¾Ğ´Ğ°
- strict_mode_migration: ĞºĞ°Ğº Ğ²ĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ strict
- interface_definitions: Ğ½Ğ¾Ğ²Ñ‹Ğµ type definitions
- refactoring_priorities: ĞºĞ°ĞºĞ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ñ„Ğ¸ĞºÑĞ¸Ñ‚ÑŒ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸
- breaking_changes: Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ ÑĞ»Ğ¾Ğ¼Ğ°Ñ‚ÑŒÑÑ
- gradual_migration_plan: Ğ¿Ğ¾ÑÑ‚Ğ°Ğ¿Ğ½Ğ¾Ğµ Ğ²Ğ½ĞµĞ´Ñ€ĞµĞ½Ğ¸Ğµ
""",
        "files": ["frontend/tsconfig.json", "frontend/src/components/"]
    },
    {
        "id": 6,
        "priority": "HIGH",
        "category": "Database Schema Design",
        "problem": """
Schema normalization Ğ½Ğµ Ğ¿Ğ¾Ğ´Ñ‚Ğ²ĞµÑ€Ğ¶Ğ´ĞµĞ½Ğ° (3NF?), Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½Ğ´ĞµĞºÑĞ¾Ğ².

Ğ¤Ğ°Ğ¹Ğ»Ñ‹: backend/models/* (8 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- ĞĞµÑÑĞ½Ğ¾, ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ»Ğ¸ schema 3NF
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ indexes
- ĞĞµÑ‚ migration strategy Ğ´Ğ»Ñ schema changes
""",
        "task": """
ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ database architecture review:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ²ÑĞµ 8 Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ½Ğ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ 3NF
2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑŒ foreign key relationships
3. ĞÑ†ĞµĞ½Ğ¸ index optimization opportunities
4. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ migration strategy
5. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ performance optimization plan

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- schema_analysis: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñ‹ Ğ‘Ğ”
- normalization_assessment: ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğµ 3NF
- denormalization_candidates: Ğ³Ğ´Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ´ĞµĞ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ
- index_optimization: Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ğ¼
- query_performance: Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¼ĞµĞ´Ğ»ĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
- migration_strategy: ĞºĞ°Ğº Ğ¸Ğ·Ğ¼ĞµĞ½ÑÑ‚ÑŒ schema
- alembic_setup: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
- performance_benchmarks: Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ´Ğ¾/Ğ¿Ğ¾ÑĞ»Ğµ
""",
        "files": ["backend/models/", "alembic/"]
    },
    {
        "id": 7,
        "priority": "MEDIUM",
        "category": "Error Handling & Logging",
        "problem": """
ĞĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ error handling, Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ structured logging.

Ğ¤Ğ°Ğ¹Ğ»Ñ‹: backend/services/* (33 Ñ„Ğ°Ğ¹Ğ»Ğ°)

ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹:
- Generic exception handling (catch Exception)
- ĞĞµÑ‚ structured logging (JSON logs)
- ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¸Ğµ correlation IDs Ğ´Ğ»Ñ Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ğ½Ğ³Ğ°
""",
        "task": """
Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ comprehensive error handling strategy:

1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¹ error handling Ğ² services
2. ĞĞ°Ğ¹Ğ´Ğ¸ Ğ²ÑĞµ generic exception handlers
3. Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ¹ custom exception hierarchy
4. ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ structured logging (JSON format)
5. Ğ’Ğ½ĞµĞ´Ñ€Ğ¸ distributed tracing (correlation IDs)

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°: JSON Ñ Ğ¿Ğ¾Ğ»ÑĞ¼Ğ¸:
- current_error_handling: ĞºĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ ÑĞµĞ¹Ñ‡Ğ°Ñ
- exception_analysis: Ñ‚Ğ¸Ğ¿Ñ‹ Ğ¸ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¹
- custom_exceptions_design: Ğ¸ĞµÑ€Ğ°Ñ€Ñ…Ğ¸Ñ ĞºĞ°ÑÑ‚Ğ¾Ğ¼Ğ½Ñ‹Ñ… exceptions
- structured_logging_setup: Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° JSON logging
- correlation_ids_implementation: ĞºĞ°Ğº Ñ‚Ñ€ĞµĞ¹ÑĞ¸Ñ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
- monitoring_integration: Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼
- alerting_rules: ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ°Ğ»ĞµÑ€Ñ‚Ñ‹
- best_practices_guide: Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ²
""",
        "files": ["backend/services/"]
    }
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DEEPSEEK API CLIENT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def call_deepseek_with_key(api_key: str, prompt: str, max_tokens: int = 4000) -> str:
    """Call DeepSeek API with specific key"""
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {
                "role": "system",
                "content": "You are an expert software architect and security consultant. "
                          "Provide detailed, actionable code reviews and fix plans in valid JSON format. "
                          "Focus on practical solutions with ready-to-use code patches."
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        "temperature": 0.3,  # Lower for more focused analysis
        "max_tokens": max_tokens
    }
    
    with httpx.Client(timeout=120.0) as client:
        response = client.post(DEEPSEEK_URL, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        return data["choices"][0]["message"]["content"]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FILE READING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def read_file_content(file_path: Path, max_lines: int = 500) -> str:
    """Read file content with size limit"""
    try:
        if not file_path.exists():
            return f"[File not found: {file_path}]"
        
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()[:max_lines]
            content = ''.join(lines)
            
            if len(lines) >= max_lines:
                content += f"\n... (truncated, total lines: {len(lines)})"
            
            return content
    except Exception as e:
        return f"[Error reading file: {e}]"


def get_files_context(files: List[str]) -> str:
    """Get context from multiple files"""
    context = []
    
    for file_pattern in files:
        file_path = PROJECT_ROOT / file_pattern
        
        if file_path.is_dir():
            # List directory contents
            py_files = list(file_path.glob("**/*.py"))[:20]  # First 20 files
            context.append(f"\nğŸ“ Directory: {file_pattern}")
            context.append(f"Total Python files: {len(list(file_path.glob('**/*.py')))}")
            context.append(f"\nKey files (first 20):")
            for f in py_files:
                context.append(f"- {f.relative_to(PROJECT_ROOT)} ({f.stat().st_size // 1024}KB)")
        else:
            # Read file content
            content = read_file_content(file_path, max_lines=300)
            context.append(f"\nğŸ“„ File: {file_pattern}")
            context.append(f"```python\n{content}\n```")
    
    return "\n".join(context)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALYSIS EXECUTOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def execute_issue_analysis(issue_index: int, issue: Dict, api_key: str) -> Dict:
    """Execute single issue analysis with DeepSeek"""
    start_time = time.time()
    
    try:
        print(f"ğŸ” [{issue_index+1}/{len(CRITICAL_ISSUES)}] Analyzing: {issue['category']}...")
        
        # Prepare context
        files_context = get_files_context(issue["files"])
        
        # Build full prompt
        full_prompt = f"""
# CRITICAL ISSUE #{issue['id']}: {issue['category']}

## Priority: {issue['priority']}

## Problem Description:
{issue['problem']}

## Files Context:
{files_context}

## Your Task:
{issue['task']}

IMPORTANT: Return ONLY valid JSON (no markdown, no code blocks). Start directly with {{
"""
        
        # Call DeepSeek
        result = call_deepseek_with_key(api_key, full_prompt, max_tokens=4000)
        
        # Clean result (remove markdown if present)
        result_clean = result.strip()
        if result_clean.startswith("```json"):
            result_clean = result_clean[7:]
        if result_clean.startswith("```"):
            result_clean = result_clean[3:]
        if result_clean.endswith("```"):
            result_clean = result_clean[:-3]
        result_clean = result_clean.strip()
        
        duration = time.time() - start_time
        print(f"âœ… [{issue_index+1}/{len(CRITICAL_ISSUES)}] Completed {issue['category']} in {duration:.1f}s")
        
        # Try to parse as JSON
        try:
            parsed_result = json.loads(result_clean)
        except json.JSONDecodeError:
            parsed_result = {"raw_response": result_clean, "note": "Failed to parse as JSON"}
        
        return {
            "issue_id": issue["id"],
            "category": issue["category"],
            "priority": issue["priority"],
            "status": "success",
            "analysis": parsed_result,
            "api_key_index": issue_index,
            "duration": duration,
            "prompt_tokens": len(full_prompt.split()),
            "response_tokens": len(result.split())
        }
        
    except Exception as e:
        print(f"âŒ [{issue_index+1}/{len(CRITICAL_ISSUES)}] Failed {issue['category']}: {e}")
        return {
            "issue_id": issue["id"],
            "category": issue["category"],
            "priority": issue["priority"],
            "status": "error",
            "error": str(e),
            "api_key_index": issue_index,
            "duration": time.time() - start_time
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN EXECUTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Main execution with ThreadPoolExecutor"""
    print("="*80)
    print("ğŸ”¥ Multithreaded DeepSeek Code Review & Fix Generator")
    print("="*80)
    print()
    
    if len(DEEPSEEK_KEYS) == 0:
        print("âŒ No DeepSeek API keys found!")
        return
    
    print(f"âœ… Using {len(DEEPSEEK_KEYS)} API keys")
    print(f"ğŸ“Š Analyzing {len(CRITICAL_ISSUES)} critical issues in parallel")
    print()
    
    # Execute analysis in parallel
    results = []
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Submit all issues
        futures = []
        for i, issue in enumerate(CRITICAL_ISSUES):
            api_key = DEEPSEEK_KEYS[i % len(DEEPSEEK_KEYS)]
            future = executor.submit(execute_issue_analysis, i, issue, api_key)
            futures.append(future)
        
        # Collect results
        for future in as_completed(futures):
            result = future.result()
            results.append(result)
    
    total_duration = time.time() - start_time
    
    # Statistics
    successful = sum(1 for r in results if r["status"] == "success")
    failed = sum(1 for r in results if r["status"] == "error")
    
    print()
    print("="*80)
    print("ğŸ“Š Analysis Statistics")
    print("="*80)
    print(f"âœ… Successful: {successful}/{len(CRITICAL_ISSUES)}")
    print(f"âŒ Failed: {failed}/{len(CRITICAL_ISSUES)}")
    print(f"â±ï¸  Total duration: {total_duration:.1f}s")
    print(f"ğŸš€ Average speed: {total_duration/len(CRITICAL_ISSUES):.1f}s per issue")
    print()
    
    # Save results
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Full results JSON
    results_path = OUTPUT_DIR / f"deepseek_analysis_{timestamp}.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "api_keys_used": len(DEEPSEEK_KEYS),
            "issues_total": len(CRITICAL_ISSUES),
            "duration_seconds": total_duration,
            "statistics": {
                "successful": successful,
                "failed": failed
            },
            "results": sorted(results, key=lambda r: r["issue_id"])
        }, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Full results: {results_path}")
    
    # Generate comprehensive fix plan
    fix_plan_path = OUTPUT_DIR / f"FIX_PLAN_{timestamp}.md"
    with open(fix_plan_path, 'w', encoding='utf-8') as f:
        f.write(f"# ğŸ”§ Comprehensive Fix Plan for 7 Critical Issues\n\n")
        f.write(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"**Analysis Duration:** {total_duration:.1f}s\n")
        f.write(f"**Success Rate:** {successful}/{len(CRITICAL_ISSUES)} ({successful/len(CRITICAL_ISSUES)*100:.1f}%)\n\n")
        
        f.write(f"## ğŸ“Š Executive Summary\n\n")
        f.write(f"| Priority | Category | Status | Duration |\n")
        f.write(f"|----------|----------|--------|----------|\n")
        for result in sorted(results, key=lambda r: r["issue_id"]):
            status_icon = "âœ…" if result["status"] == "success" else "âŒ"
            f.write(f"| {result['priority']} | {result['category']} | {status_icon} {result['status']} | {result.get('duration', 0):.1f}s |\n")
        
        f.write(f"\n---\n\n")
        
        # Detailed analysis for each issue
        for result in sorted(results, key=lambda r: r["issue_id"]):
            f.write(f"## Issue #{result['issue_id']}: {result['category']}\n\n")
            f.write(f"**Priority:** {result['priority']}\n")
            f.write(f"**Status:** {result['status']}\n")
            f.write(f"**Analysis Duration:** {result.get('duration', 0):.1f}s\n\n")
            
            if result["status"] == "success":
                analysis = result.get("analysis", {})
                
                # Write analysis sections
                f.write(f"### ğŸ“‹ Analysis\n\n")
                f.write(f"```json\n")
                f.write(json.dumps(analysis, indent=2, ensure_ascii=False))
                f.write(f"\n```\n\n")
                
                # Extract key recommendations
                if isinstance(analysis, dict):
                    if "recommended_solution" in analysis:
                        f.write(f"### âœ… Recommended Solution\n\n")
                        f.write(f"{analysis['recommended_solution']}\n\n")
                    
                    if "code_patch" in analysis:
                        f.write(f"### ğŸ’» Code Patch\n\n")
                        f.write(f"```python\n{analysis['code_patch']}\n```\n\n")
                    
                    if "migration_steps" in analysis:
                        f.write(f"### ğŸš€ Migration Steps\n\n")
                        steps = analysis['migration_steps']
                        if isinstance(steps, list):
                            for i, step in enumerate(steps, 1):
                                f.write(f"{i}. {step}\n")
                        else:
                            f.write(f"{steps}\n")
                        f.write(f"\n")
            else:
                f.write(f"### âŒ Error\n\n")
                f.write(f"```\n{result.get('error', 'Unknown error')}\n```\n\n")
            
            f.write(f"---\n\n")
    
    print(f"ğŸ“„ Fix Plan: {fix_plan_path}")
    
    print()
    print("="*80)
    print("âœ… DeepSeek analysis complete!")
    print("="*80)


if __name__ == "__main__":
    main()
