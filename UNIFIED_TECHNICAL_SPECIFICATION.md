# üìò –ï–¥–∏–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ: –ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è —Å MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä–æ–º

**–í–µ—Ä—Å–∏—è**: 1.0  
**–î–∞—Ç–∞**: 2025-11-03  
**–°—Ç–∞—Ç—É—Å**: –û–±–æ–±—â—ë–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ 4 –∏—Å—Ö–æ–¥–Ω—ã—Ö –¢–ó –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤  
**–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ**: Perplexity AI (sonar-pro) + GitHub Copilot

---

## üéØ Executive Summary

–°–∏—Å—Ç–µ–º–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π **–º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—É—é –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é** –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –æ—Ç–±–æ—Ä–∞ –∏ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π. –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–º —è–≤–ª—è–µ—Ç—Å—è **MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä**, –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—â–∏–π:
- –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—é –∑–∞–¥–∞—á –º–µ–∂–¥—É –∞–≥–µ–Ω—Ç–∞–º–∏
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥—è–º–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π
- –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ sandbox-–æ–∫—Ä—É–∂–µ–Ω–∏—è—Ö
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ SLA –∏ –º–µ—Ç—Ä–∏–∫
- –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º

**–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**
- ‚úÖ –ê–≤—Ç–æ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (reasoning ‚Üí codegen ‚Üí ML ‚Üí backtest)
- ‚úÖ –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å (approve/fix/rollback –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ)
- ‚úÖ –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ —Ä—ã–Ω–æ—á–Ω—ã–º —Ä–µ–∂–∏–º–∞–º (–¥–µ—Ç–µ–∫—Ç–æ—Ä—ã —Ñ–∞–∑, —ç–º—É–ª—è—Ü–∏—è —Å—Ç–∏–ª–µ–π —Ç—Ä–µ–π–¥–µ—Ä–∞)
- ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (multi-layer sandbox, threat modeling, policy engine)
- ‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å (SLA-driven autoscaling, multi-tenancy)
- ‚úÖ Explainability (chain-of-thought reasoning, audit trail)

---

## 1. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

### 1.1. –û–±—â–∞—è —Å—Ö–µ–º–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      USER INTERFACES                        ‚îÇ
‚îÇ  WebUI ‚îÇ CLI ‚îÇ VS Code Extension ‚îÇ Telegram Bot ‚îÇ API      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  MCP-–û–†–ö–ï–°–¢–†–ê–¢–û–† (FastAPI)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Signal Routing Layer (JSON-RPC 2.0)                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - /run_task, /status, /analytics, /control          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Real-time Preemption (high/low priority)          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Saga Orchestration (SagaFSM)                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Redis Streams (Consumer Groups)                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - high_priority_queue, low_priority_queue           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - XPENDING recovery, Checkpoint Recovery            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ - Fanout pattern –¥–ª—è reasoning/codegen              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ               ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Reasoning  ‚îÇ ‚îÇ   CodeGen   ‚îÇ ‚îÇ ML-Agents  ‚îÇ
‚îÇ  Agents     ‚îÇ ‚îÇ   Agents    ‚îÇ ‚îÇ  AutoML    ‚îÇ
‚îÇ (Perplexity)‚îÇ ‚îÇ  (DeepSeek) ‚îÇ ‚îÇ (sklearn)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ               ‚îÇ               ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   SANDBOX LAYER     ‚îÇ
            ‚îÇ Docker ‚îÇ gVisor ‚îÇ   ‚îÇ
            ‚îÇ Firecracker microVM ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ             ‚îÇ             ‚îÇ
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Guardian    ‚îÇ ‚îÇBacktest‚îÇ ‚îÇ Knowledge   ‚îÇ
  ‚îÇ Agents      ‚îÇ ‚îÇEngines ‚îÇ ‚îÇ Base        ‚îÇ
  ‚îÇ(Validators) ‚îÇ ‚îÇ(vectorbt)‚îÇ ‚îÇ(Reasoning)‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
            ‚îÇ   MONITORING        ‚îÇ
            ‚îÇ Prometheus ‚îÇGrafana ‚îÇ
            ‚îÇ OpenTelemetry       ‚îÇ
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2. –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

1. **MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä** (FastAPI/asyncio, JSON-RPC 2.0)
2. **Reasoning-–∞–≥–µ–Ω—Ç—ã** (Perplexity AI) ‚Äî –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è, Explainable AI
3. **CodeGen-–∞–≥–µ–Ω—Ç—ã** (DeepSeek) ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è Python/ML/MQL –∫–æ–¥–∞
4. **ML-–∞–≥–µ–Ω—Ç—ã/AutoML** (LSTM, CNN, RL, Bayesian Optimization)
5. **Trader Psychology Agent** ‚Äî —ç–º—É–ª—è—Ü–∏—è —Å—Ç–∏–ª–µ–π —Ç—Ä–µ–π–¥–µ—Ä–∞
6. **Guardian Agents** ‚Äî –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ–º
7. **Sandbox-–æ–∫—Ä—É–∂–µ–Ω–∏—è** (Docker, gVisor, Firecracker)
8. **User-Control –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã** (WebUI, CLI, VS Code Extension, —á–∞—Ç-–±–æ—Ç)
9. **Knowledge Base** ‚Äî chain-of-thought reasoning, bootstrap/fine-tune
10. **–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥** (Prometheus, Grafana, OpenTelemetry)

### 1.3. –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

```yaml
Core:
  languages: Python 3.10+
  frameworks: FastAPI, asyncio, Celery/ARQ
  queues: Redis Streams with Consumer Groups
  databases: PostgreSQL, MongoDB
  
AI/ML:
  reasoning: Perplexity API (Sonar Pro)
  codegen: DeepSeek API
  orchestration: LangChain
  ml_frameworks: sklearn, xgboost, optuna, PyTorch, LightGBM
  
Backtest:
  engines: vectorbt, Backtrader, MetaTrader 5 (COM/REST/RPC)
  
Containerization:
  sandbox: Docker, Docker-in-Docker, sysbox, gVisor, Firecracker microVM
  orchestration: docker-compose, Kubernetes
  
Monitoring:
  metrics: Prometheus, Grafana
  tracing: OpenTelemetry (end-to-end trace-id)
  
Security:
  encryption: AES-256 at rest, TLS in transit, mutual TLS
  auth: OAuth2, token-based permissions, WorkOS/AuthKit
  
UI:
  web: Streamlit, Gradio, FastAPI web
  desktop: VS Code extension (TypeScript/JavaScript)
  mobile: Telegram Bot API
  visualization: D3.js, Plotly, Matplotlib
```

---

## 2. –ü—Ä–æ—Ç–æ–∫–æ–ª—å–Ω–∞—è –æ—Å–Ω–æ–≤–∞ –∏ API

### 2.1. JSON-RPC 2.0 Protocol

–í—Å–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —á–µ—Ä–µ–∑ JSON-RPC 2.0. –ü—Ä–∏–º–µ—Ä —Å–æ–æ–±—â–µ–Ω–∏—è:

```json
{
  "jsonrpc": "2.0",
  "method": "run_task",
  "params": {
    "tool": "DeepSeek",
    "prompt": "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ–¥ DCA-—Å—Ç—Ä–∞—Ç–µ–≥–∏–∏",
    "priority": 10,
    "context": {
      "market": "crypto",
      "symbol": "BTCUSDT",
      "timeframe": "1h"
    }
  },
  "id": "task_123"
}
```

### 2.2. API Endpoints

#### –û—Å–Ω–æ–≤–Ω—ã–µ endpoints

```python
# MCP Orchestrator API
POST   /v1/run_task       # –ó–∞–ø—É—Å–∫ –∑–∞–¥–∞—á–∏ (reasoning/coding/ML)
GET    /v1/status         # –°—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏, –≤–æ—Ä–∫–µ—Ä–æ–≤, –∞–≥–µ–Ω—Ç–æ–≤
GET    /v1/analytics      # Live-–¥–∞–Ω–Ω—ã–µ (latency, throughput, utilization)
POST   /v1/inject         # –†—É—á–Ω–æ–π –≤–≤–æ–¥/–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∑–∞–¥–∞—á
POST   /v1/control        # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏ (scale, pause, resume)

# Routing & Agent Management
POST   /v1/route          # –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–¥–∞—á–∏ –∫ –∞–≥–µ–Ω—Ç—É
POST   /v1/add_agent      # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –∞–≥–µ–Ω—Ç–∞
GET    /v1/get_log        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ª–æ–≥–æ–≤ reasoning/codegen
POST   /v1/sandbox_exec   # –ó–∞–ø—É—Å–∫ –≤ sandbox-–æ–∫—Ä—É–∂–µ–Ω–∏–∏

# User Feedback & Control
POST   /v1/feedback       # User feedback (approve/reject/fix)
GET    /v1/logs           # –ò—Å—Ç–æ—Ä–∏—è –ª–æ–≥–æ–≤ –ø–æ trace-id
PUT    /v1/strategy/fix   # –†—É—á–Ω–∞—è –ø—Ä–∞–≤–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
POST   /v1/strategy/approve # –û–¥–æ–±—Ä–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–ª—è –¥–µ–ø–ª–æ—è
```

#### Reasoning API (Perplexity)

```python
def perplexity_api_call(payload):
    """
    payload = {
        "prompt": "–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π DCA —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–ª—è BTCUSDT",
        "model": "sonar-pro",
        "context": {...}
    }
    """
    r = requests.post(
        "https://api.perplexity.ai/v1/reasoning", 
        json=payload,
        headers={"Authorization": f"Bearer {PERPLEXITY_API_KEY}"}
    )
    return r.json()["reasoning"]
```

#### CodeGen API (DeepSeek)

```python
def deepseek_api_call(prompt):
    """
    prompt: "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π Python –∫–æ–¥ –¥–ª—è DCA —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"
    """
    payload = {
        "prompt": prompt, 
        "language": "python",
        "max_tokens": 2000
    }
    r = requests.post(
        "https://api.deepseek.com/code", 
        json=payload,
        headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}
    )
    return r.json()["code"]
```

### 2.3. –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

- –í–∞–ª–∏–¥–∞—Ü–∏—è —á–µ—Ä–µ–∑ **pydantic** –∏ **jsonschema** –¥–ª—è –≤—Å–µ—Ö –≤—Ö–æ–¥—è—â–∏—Ö/–∏—Å—Ö–æ–¥—è—â–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤
- API –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ: `/v1/run_task`, `/v2/run_task`
- –†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ (backward compatibility)

---

## 3. –û—á–µ—Ä–µ–¥–∏ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∞–º–∏

### 3.1. Redis Streams + Consumer Groups

–î–ª—è high/low priority –æ—á–µ—Ä–µ–¥–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **Redis Streams**:

```python
import redis.asyncio as redis

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis
r = redis.Redis(
    host='localhost', 
    port=6379, 
    decode_responses=True
)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏ –≤ stream
await r.xadd(
    "mcp_tasks",  # stream name
    {
        "priority": "high",
        "type": "reasoning",
        "payload": json.dumps({
            "prompt": "Analyze BTC market conditions",
            "context": {...}
        }),
        "timestamp": time.time(),
        "agent": "perplexity"
    },
    maxlen=100000  # –ª–∏–º–∏—Ç —Ä–∞–∑–º–µ—Ä–∞ stream
)

# Consumer Group –¥–ª—è –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
await r.xgroup_create(
    "mcp_tasks", 
    "reasoning_workers", 
    id='0', 
    mkstream=True
)

# –ß—Ç–µ–Ω–∏–µ –∑–∞–¥–∞—á –∏–∑ stream
messages = await r.xreadgroup(
    groupname="reasoning_workers",
    consumername="worker_1",
    streams={"mcp_tasks": ">"},
    count=10,
    block=1000  # 1s timeout
)
```

### 3.2. XPENDING Recovery (Checkpoint Recovery)

–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ "–∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö" –∑–∞–¥–∞—á:

```python
async def recover_orphaned_tasks():
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 30s, –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–¥–∞—á–∏ idle >60s
    """
    # –ü–æ–ª—É—á–∏—Ç—å XPENDING (pending tasks)
    pending = await r.xpending(
        "mcp_tasks", 
        "reasoning_workers", 
        "-", "+", 
        count=100
    )
    
    for task in pending:
        # –ï—Å–ª–∏ idle > 60s
        if task['idle_time'] > 60000:  # milliseconds
            # Claim –∑–∞–¥–∞—á—É
            claimed = await r.xclaim(
                "mcp_tasks",
                "reasoning_workers",
                "recovery_worker",
                min_idle_time=60000,
                message_ids=[task['message_id']]
            )
            
            # Reprocess –∑–∞–¥–∞—á—É
            await process_task(claimed[0])
            
            # ACK –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            await r.xack("mcp_tasks", "reasoning_workers", task['message_id'])
```

### 3.3. Fanout Pattern

–†–µ–∑—É–ª—å—Ç–∞—Ç reasoning/codegen –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤—Å–µ–º –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω—ã–º –∞–≥–µ–Ω—Ç–∞–º:

```python
async def fanout_result(result):
    """
    Fanout pattern: –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤–æ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏
    """
    # Publish –≤ pub/sub –∫–∞–Ω–∞–ª
    await r.publish("reasoning_results", json.dumps(result))
    
    # –î–æ–±–∞–≤–∏—Ç—å –≤ streams –¥–ª—è codegen –∏ ML –∞–≥–µ–Ω—Ç–æ–≤
    await r.xadd("codegen_queue", {"result": json.dumps(result)})
    await r.xadd("ml_queue", {"result": json.dumps(result)})
```

### 3.4. SLA-driven Autoscaling

```python
class AutoScaler:
    def __init__(self, min_workers=2, max_workers=10, interval=30):
        self.min_workers = min_workers
        self.max_workers = max_workers
        self.interval = interval
        
    async def monitor_and_scale(self):
        """
        –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –º–µ—Ç—Ä–∏–∫ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        """
        while True:
            # –ü–æ–ª—É—á–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
            queue_depth = await get_queue_depth()
            latency_p95 = await get_latency_p95()
            worker_utilization = await get_worker_utilization()
            
            # –£—Å–ª–æ–≤–∏—è –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            if queue_depth > 100 or latency_p95 > 1000:  # 1s
                await self.scale_up()
            elif queue_depth < 20 and worker_utilization < 0.3:
                await self.scale_down()
            
            await asyncio.sleep(self.interval)
    
    async def scale_up(self):
        current_workers = len(worker_pool)
        if current_workers < self.max_workers:
            await spawn_worker()
            logger.info(f"Scaled up: {current_workers} ‚Üí {current_workers+1}")
    
    async def scale_down(self):
        current_workers = len(worker_pool)
        if current_workers > self.min_workers:
            await terminate_worker()
            logger.info(f"Scaled down: {current_workers} ‚Üí {current_workers-1}")
```

---

## 4. Signal Routing, Saga, Preemption

### 4.1. Signal Routing Layer

Event-driven —è–¥—Ä–æ —Å real-time preemption:

```python
class PreemptiveRouter:
    def __init__(self):
        self.high_priority_queue = asyncio.Queue()
        self.low_priority_queue = asyncio.Queue()
    
    async def route_task(self, task):
        """
        –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏–µ–π –∏ preemption
        """
        if task.priority >= 10:  # high priority
            # Pause low-priority workers
            await self.preempt_low_priority_workers()
            
            # Route to express queue
            await self.high_priority_queue.put(task)
            logger.info(f"Task {task.id} routed to HIGH priority queue")
        else:
            await self.low_priority_queue.put(task)
            logger.info(f"Task {task.id} routed to LOW priority queue")
    
    async def preempt_low_priority_workers(self):
        """
        –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ low-priority –∑–∞–¥–∞—á
        """
        for worker in low_priority_workers:
            if worker.is_processing():
                # Checkpoint current state
                await worker.checkpoint()
                
                # Pause worker
                await worker.pause()
                logger.info(f"Worker {worker.id} paused for preemption")
```

### 4.2. Saga Orchestration (Saga FSM)

FSM –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è long-running workflows —Å –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏—è–º–∏:

```python
class AIWorkflowSaga:
    def __init__(self, task_id):
        self.task_id = task_id
        self.steps = []
        self.checkpoints = {}
    
    async def execute(self):
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ Saga —Å checkpointing –∏ compensation
        """
        try:
            # Step 1: Reasoning
            reasoning_result = await self.run_agent("reasoning", "perplexity")
            self.checkpoints['reasoning'] = reasoning_result
            self.steps.append(("reasoning", "success"))
            
            # Step 2: CodeGen
            codegen_result = await self.run_agent("codegen", "deepseek", reasoning_result)
            self.checkpoints['codegen'] = codegen_result
            self.steps.append(("codegen", "success"))
            
            # Step 3: Sandbox Execution
            sandbox_result = await self.run_agent("sandbox", "docker", codegen_result)
            self.checkpoints['sandbox'] = sandbox_result
            self.steps.append(("sandbox", "success"))
            
            # Step 4: Backtest
            backtest_result = await self.run_agent("backtest", "vectorbt", sandbox_result)
            self.checkpoints['backtest'] = backtest_result
            self.steps.append(("backtest", "success"))
            
            return {"status": "success", "result": backtest_result}
            
        except Exception as e:
            logger.error(f"Saga failed at step {len(self.steps)}: {e}")
            
            # Compensate all previous steps
            await self.compensate_all_previous_steps()
            
            return {"status": "failed", "error": str(e), "compensated": True}
    
    async def compensate_all_previous_steps(self):
        """
        Rollback –≤—Å–µ—Ö –∑–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö —à–∞–≥–æ–≤
        """
        for step_name, status in reversed(self.steps):
            if status == "success":
                await self.compensate_step(step_name)
                logger.info(f"Compensated step: {step_name}")
    
    async def compensate_step(self, step_name):
        """
        Compensation function –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —à–∞–≥–∞
        """
        if step_name == "reasoning":
            # Rollback reasoning artifacts
            pass
        elif step_name == "codegen":
            # Delete generated code
            pass
        elif step_name == "sandbox":
            # Terminate sandbox container
            await docker_client.terminate_container(self.task_id)
        elif step_name == "backtest":
            # Clean backtest results
            pass
```

---

## 5. –í–æ—Ä–∫–µ—Ä—ã –∏ –∞–≥–µ–Ω—Ç—ã

### 5.1. Async Worker Pool (Reasoning/Coding)

```python
async def deepseek_worker(queue):
    """
    Dedicated worker –¥–ª—è DeepSeek codegen
    """
    async with httpx.AsyncClient(timeout=30.0) as client:
        while True:
            try:
                # Get task from queue
                task = await queue.get()
                logger.info(f"Worker processing task: {task.id}")
                
                # Call DeepSeek API
                resp = await client.post(
                    'https://api.deepseek.com/code',
                    json={
                        "prompt": task.prompt,
                        "language": "python",
                        "max_tokens": 2000
                    },
                    headers={"Authorization": f"Bearer {DEEPSEEK_API_KEY}"}
                )
                
                # Process response
                code = resp.json()["code"]
                
                # Send to sandbox for validation
                await sandbox_queue.put({
                    "task_id": task.id,
                    "code": code
                })
                
                # Mark task as done
                queue.task_done()
                
            except Exception as e:
                logger.error(f"Worker error: {e}")
                await handle_worker_error(task, e)
```

### 5.2. ML-–∞–≥–µ–Ω—Ç—ã / AutoML

```python
from sklearn.model_selection import GridSearchCV

class MLAgent:
    def __init__(self):
        self.models = {
            "lstm": LSTMModel(),
            "cnn": CNNModel(),
            "rl": RLModel(),
            "bayesian": BayesianOptimizer()
        }
    
    async def optimize_strategy(self, strategy_code, historical_data):
        """
        –ë–∞—Ç—á-–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        """
        # GridSearchCV –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        param_grid = {
            'period': [10, 20, 50, 100],
            'threshold': [0.01, 0.02, 0.05],
            'stop_loss': [0.02, 0.05, 0.10]
        }
        
        grid = GridSearchCV(
            StrategyModel(strategy_code),
            param_grid=param_grid,
            cv=5,  # 5-fold cross-validation
            n_jobs=-1  # parallel execution
        )
        
        grid.fit(historical_data['X'], historical_data['y'])
        
        best_params = grid.best_params_
        best_score = grid.best_score_
        
        return {
            "best_params": best_params,
            "best_score": best_score,
            "all_results": grid.cv_results_
        }
```

### 5.3. Trader Psychology Agent

```python
class TraderProfile:
    """
    –≠–º—É–ª—è—Ü–∏—è –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤ —Ç—Ä–µ–π–¥–µ—Ä–æ–≤
    """
    PROFILES = {
        "conservative": {"risk_tolerance": 0.02, "max_drawdown": 0.05},
        "aggressive": {"risk_tolerance": 0.10, "max_drawdown": 0.20},
        "panic": {"risk_tolerance": 0.01, "exit_on_loss": True},
        "rabbit": {"quick_exit": True, "hold_time_max": 3600},  # 1h max
        "wolf": {"averaging_down": True, "add_on_dip": True},
        "speculator": {"strict_stop_loss": True, "trailing_stop": True},
        "trend_follower": {"follow_trend": True, "ignore_noise": True}
    }
    
    def __init__(self, style):
        self.style = style
        self.config = self.PROFILES[style]
    
    def risk_decision(self, pnl, drawdown, position_time):
        """
        –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ñ–∏–ª—è —Ç—Ä–µ–π–¥–µ—Ä–∞
        """
        if self.style == "rabbit":
            # –ü–∞–Ω–∏—á–µ—Å–∫–∏–π –≤—ã—Ö–æ–¥ –ø—Ä–∏ –ø—Ä–æ—Å–∞–¥–∫–µ >5%
            if drawdown > 0.05:
                return {"action": "exit", "reason": "panic_exit"}
            # –ë—ã—Å—Ç—Ä—ã–π –≤—ã—Ö–æ–¥ –ø–æ—Å–ª–µ 1 —á–∞—Å–∞
            if position_time > 3600:
                return {"action": "exit", "reason": "hold_time_exceeded"}
        
        elif self.style == "wolf":
            # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–∏ –ø—Ä–æ—Å–∞–¥–∫–µ
            if pnl < -0.05:
                return {"action": "add", "reason": "averaging_down"}
            # –§–∏–∫—Å–∞—Ü–∏—è –ø—Ä–∏–±—ã–ª–∏ >10%
            if pnl > 0.10:
                return {"action": "partial_exit", "reason": "take_profit"}
        
        elif self.style == "speculator":
            # –°—Ç—Ä–æ–≥–∏–π stop-loss
            if drawdown > self.config['risk_tolerance']:
                return {"action": "exit", "reason": "stop_loss"}
        
        return {"action": "hold", "reason": "within_risk_tolerance"}
```

### 5.4. Guardian Agents (–í–∞–ª–∏–¥–∞—Ç–æ—Ä—ã)

```python
class GuardianAgent:
    """
    –ê–≥–µ–Ω—Ç—ã-–±—Ä–∞–Ω–¥–º–∞—É—ç—Ä—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ–º
    """
    def __init__(self):
        self.security_rules = [
            self.check_code_safety,
            self.check_api_limits,
            self.check_resource_limits,
            self.check_prompt_injection
        ]
    
    async def validate_strategy(self, strategy):
        """
        –ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–µ—Ä–µ–¥ –¥–µ–ø–ª–æ–µ–º
        """
        validation_results = []
        
        for rule in self.security_rules:
            result = await rule(strategy)
            validation_results.append(result)
            
            if not result['passed']:
                return {
                    "approved": False,
                    "reason": result['reason'],
                    "rule": rule.__name__
                }
        
        return {
            "approved": True,
            "validation_results": validation_results
        }
    
    async def check_code_safety(self, strategy):
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞
        """
        dangerous_patterns = [
            r'import\s+os',
            r'subprocess\.',
            r'eval\(',
            r'exec\(',
            r'__import__'
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, strategy['code']):
                return {
                    "passed": False,
                    "reason": f"Dangerous pattern detected: {pattern}"
                }
        
        return {"passed": True}
    
    async def check_prompt_injection(self, strategy):
        """
        Threat modeling: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ prompt injection
        """
        injection_patterns = [
            "ignore previous instructions",
            "disregard safety",
            "bypass security"
        ]
        
        for pattern in injection_patterns:
            if pattern.lower() in strategy['prompt'].lower():
                return {
                    "passed": False,
                    "reason": f"Prompt injection detected: {pattern}"
                }
        
        return {"passed": True}
```

---

## 6. Sandbox Execution –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

### 6.1. Multi-layer Sandbox

```python
def run_in_secure_container(code, strategy_id):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ Docker + gVisor
    """
    # Docker run —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
    subprocess.run([
        'docker', 'run',
        '--rm',  # —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        '--network', 'none',  # –±–µ–∑ —Å–µ—Ç–∏
        '--read-only',  # read-only FS
        '--tmpfs', '/tmp:rw,noexec,nosuid,size=100m',  # temporary FS
        '-m', '512m',  # RAM limit
        '-c', '1024',  # CPU shares (1 core)
        '--pids-limit', '100',  # process limit
        '--name', f'strategy_{strategy_id}',
        '--runtime', 'runsc',  # gVisor runtime
        'bybit-strategy-sandbox:latest',
        'python3', '-c', code
    ], timeout=30, capture_output=True)
    
    # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ syscalls —á–µ—Ä–µ–∑ auditd/sysdig
    await monitor_syscalls(strategy_id)
```

### 6.2. Threat Modeling & Security Policy

```yaml
Security Policies:
  sandbox:
    runtime: gVisor, Firecracker microVM
    network: disabled (network=none)
    filesystem: read-only (except /tmp)
    resource_limits:
      cpu: 1 core
      ram: 512MB
      storage: 100MB
      runtime: 30s timeout
    
  threat_modeling:
    scenarios:
      - prompt_injection
      - cmd_injection
      - sandbox_escape
      - credential_theft
      - resource_starvation
      - denial_of_service
    
  encryption:
    at_rest: AES-256
    in_transit: TLS 1.3, mutual TLS
    key_rotation: every 90 days
    
  authentication:
    protocols: OAuth2, WorkOS/AuthKit
    per_user_rate_limits: true
    per_tenant_isolation: true
    
  audit:
    syscall_monitoring: auditd, sysdig, gvisor
    runtime_tracing: enabled
    sandbox_escape_detection: real-time alerts
    log_retention: 90 days
```

---

## 7. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ SLA

### 7.1. Prometheus Metrics

```python
from prometheus_client import Histogram, Counter, Gauge

# SLA –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
REASONING_LATENCY = Histogram(
    'reasoning_latency_seconds', 
    'AI reasoning latency',
    ['agent', 'priority']
)

QUEUE_DEPTH = Gauge(
    'queue_depth', 
    'Tasks in queue',
    ['priority', 'tenant']
)

SANDBOX_ESCAPE_ATTEMPTS = Counter(
    'sandbox_escape_attempts_total',
    'Sandbox escape attempts detected'
)

SAGA_STEPS = Histogram(
    'saga_steps_duration_seconds',
    'Saga step execution time',
    ['step_name', 'status']
)

TASK_COMPLETION_RATE = Gauge(
    'task_completion_rate',
    'Percentage of successfully completed tasks',
    ['task_type']
)
```

### 7.2. OpenTelemetry Tracing

```python
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è tracer
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

# OTLP exporter (Grafana Tempo, Jaeger)
otlp_exporter = OTLPSpanExporter(endpoint="http://localhost:4317")
span_processor = BatchSpanProcessor(otlp_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# –¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞ end-to-end
@tracer.start_as_current_span("mcp_full_pipeline")
async def run_full_pipeline(task):
    with tracer.start_as_current_span("reasoning_step"):
        reasoning_result = await reasoning_agent.process(task)
    
    with tracer.start_as_current_span("codegen_step"):
        codegen_result = await codegen_agent.process(reasoning_result)
    
    with tracer.start_as_current_span("sandbox_step"):
        sandbox_result = await sandbox.execute(codegen_result)
    
    return sandbox_result
```

### 7.3. SLA Recovery Target

- **Recovery time**: <30 —Å–µ–∫—É–Ω–¥ –¥–ª—è –∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö –∑–∞–¥–∞—á
- **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π rollback/compensation** –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å–±–æ—è—Ö
- **Zero data loss** —á–µ—Ä–µ–∑ checkpoint recovery

---

## 8. User-Control –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

### 8.1. WebUI (Streamlit/Gradio)

```python
import streamlit as st
import plotly.graph_objects as go

# Dashboard
st.title("MCP Orchestrator Dashboard")

# Real-time –º–µ—Ç—Ä–∏–∫–∏
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("Queue Depth", get_queue_depth(), delta="+5")
with col2:
    st.metric("Active Workers", get_active_workers(), delta="-1")
with col3:
    st.metric("Latency p95 (ms)", get_latency_p95(), delta="+10ms")

# Saga execution graph
fig = go.Figure(data=[go.Sankey(
    node=dict(
        label=["Reasoning", "CodeGen", "Sandbox", "Backtest", "Deploy"],
        color="blue"
    ),
    link=dict(
        source=[0, 1, 2, 3],
        target=[1, 2, 3, 4],
        value=[100, 95, 90, 85]
    )
)])
st.plotly_chart(fig)

# Feedback form
with st.form("strategy_feedback"):
    strategy_id = st.text_input("Strategy ID")
    action = st.selectbox("Action", ["approve", "reject", "fix", "rollback"])
    comment = st.text_area("Comment")
    
    if st.form_submit_button("Submit"):
        await submit_feedback(strategy_id, action, comment)
        st.success(f"Feedback submitted for strategy {strategy_id}")
```

### 8.2. VS Code Extension

```typescript
// extension.ts
import * as vscode from 'vscode';
import axios from 'axios';

export function activate(context: vscode.ExtensionContext) {
    // Command: Run strategy test
    let runTest = vscode.commands.registerCommand('mcp.runTest', async () => {
        const editor = vscode.window.activeTextEditor;
        if (!editor) return;
        
        const code = editor.document.getText();
        
        // Send to MCP orchestrator
        const response = await axios.post('http://localhost:8000/v1/run_task', {
            jsonrpc: "2.0",
            method: "run_task",
            params: {
                tool: "DeepSeek",
                prompt: "Test this strategy",
                code: code,
                priority: 10
            }
        });
        
        // Show results
        vscode.window.showInformationMessage(
            `Task ${response.data.result.task_id} submitted`
        );
    });
    
    context.subscriptions.push(runTest);
}
```

### 8.3. Telegram Bot

```python
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "MCP Orchestrator Bot\n"
        "/status - –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã\n"
        "/run_strategy <code> - –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n"
        "/approve <strategy_id> - –û–¥–æ–±—Ä–∏—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é"
    )

async def status(update: Update, context: ContextTypes.DEFAULT_TYPE):
    metrics = await get_system_metrics()
    await update.message.reply_text(
        f"Queue Depth: {metrics['queue_depth']}\n"
        f"Active Workers: {metrics['active_workers']}\n"
        f"Latency p95: {metrics['latency_p95']}ms"
    )

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
app = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
app.add_handler(CommandHandler("start", start))
app.add_handler(CommandHandler("status", status))
app.run_polling()
```

---

## 9. Pipeline —Ä–∞–±–æ—Ç—ã (–ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª)

### 9.1. MVP Pipeline

```python
async def mvp_pipeline(user_request):
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ –∂–∏–∑–Ω–µ—Å–ø–æ—Å–æ–±–Ω—ã–π pipeline
    """
    # Step 1: User Request
    trace_id = generate_trace_id()
    logger.info(f"[{trace_id}] New request: {user_request['prompt']}")
    
    # Step 2: Reasoning (Perplexity)
    reasoning_result = await perplexity_agent.process({
        "prompt": user_request['prompt'],
        "context": user_request['context']
    })
    await knowledge_base.store(trace_id, "reasoning", reasoning_result)
    
    # Step 3: CodeGen (DeepSeek)
    codegen_result = await deepseek_agent.process({
        "prompt": reasoning_result['generated_strategy'],
        "language": "python"
    })
    await knowledge_base.store(trace_id, "codegen", codegen_result)
    
    # Step 4: ML-–∞–Ω–∞–ª–∏–∑
    ml_result = await ml_agent.optimize_strategy(
        codegen_result['code'],
        user_request['historical_data']
    )
    await knowledge_base.store(trace_id, "ml_optimization", ml_result)
    
    # Step 5: Backtest
    backtest_result = await backtest_engine.run({
        "code": codegen_result['code'],
        "params": ml_result['best_params'],
        "data": user_request['historical_data']
    })
    await knowledge_base.store(trace_id, "backtest", backtest_result)
    
    # Step 6: User-review (interactive pause)
    user_feedback = await wait_for_user_feedback(trace_id)
    
    if user_feedback['action'] == "approve":
        # Step 7: Deploy
        deploy_result = await deploy_strategy(
            codegen_result['code'],
            ml_result['best_params']
        )
        
        # Step 8: Monitoring
        await start_monitoring(deploy_result['strategy_id'])
        
        return {
            "status": "success",
            "trace_id": trace_id,
            "strategy_id": deploy_result['strategy_id']
        }
    
    elif user_feedback['action'] == "fix":
        # Rollback –∫ CodeGen —Å –ø—Ä–∞–≤–∫–∞–º–∏
        return await mvp_pipeline({
            **user_request,
            "prompt": user_feedback['fixed_prompt']
        })
    
    else:  # reject
        return {
            "status": "rejected",
            "trace_id": trace_id,
            "reason": user_feedback['reason']
        }
```

### 9.2. Extended Pipeline (—Å —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è–º–∏)

```python
async def tournament_pipeline(user_request):
    """
    –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π pipeline —Å batch-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è–º–∏
    """
    # Batch generation: 10 —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    strategies = []
    for i in range(10):
        strategy = await generate_strategy_variant(user_request, variant=i)
        strategies.append(strategy)
    
    # Backtest –≤—Å–µ—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
    backtest_results = await asyncio.gather(*[
        backtest_engine.run(strategy) 
        for strategy in strategies
    ])
    
    # ML-–æ—Ç–±–æ—Ä –ª—É—á—à–∏—Ö (top 3)
    ranked_strategies = rank_by_sharpe_ratio(backtest_results)
    top_3 = ranked_strategies[:3]
    
    # Trader Psychology —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    psychology_results = []
    for strategy in top_3:
        for profile in ["rabbit", "wolf", "conservative", "aggressive"]:
            result = await test_with_trader_profile(strategy, profile)
            psychology_results.append(result)
    
    # –í—ã–±–æ—Ä –ø–æ–±–µ–¥–∏—Ç–µ–ª—è
    winner = select_winner(psychology_results)
    
    # User-review —Ñ–∏–Ω–∞–ª–∏—Å—Ç–∞
    user_feedback = await wait_for_user_feedback(winner['trace_id'])
    
    if user_feedback['action'] == "approve":
        return await deploy_strategy(winner)
    else:
        # Re-run tournament —Å —É—á—ë—Ç–æ–º feedback
        return await tournament_pipeline({
            **user_request,
            "feedback": user_feedback
        })
```

---

## 10. Knowledge Base –∏ Self-Improvement

### 10.1. Chain-of-Thought Reasoning

```python
class KnowledgeBase:
    def __init__(self, db_connection):
        self.db = db_connection
    
    async def store(self, trace_id, step_name, result):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ chain-of-thought reasoning
        """
        await self.db.insert({
            "trace_id": trace_id,
            "step_name": step_name,
            "timestamp": time.time(),
            "result": result,
            "reasoning_chain": result.get('reasoning_chain', []),
            "metadata": {
                "agent": result.get('agent'),
                "model": result.get('model'),
                "tokens_used": result.get('tokens_used')
            }
        })
    
    async def bootstrap_reasoning(self, new_task):
        """
        Bootstrap/fine-tune reasoning –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—à–ª—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–¥–∞—á
        similar_tasks = await self.db.find({
            "prompt": {"$text": {"$search": new_task['prompt']}},
            "result.status": "success"
        }).limit(5)
        
        # –ò–∑–≤–ª–µ—á—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã reasoning
        patterns = [task['reasoning_chain'] for task in similar_tasks]
        
        # Fine-tune –Ω–æ–≤—ã–π reasoning
        enhanced_prompt = f"""
        Based on these successful past approaches:
        {json.dumps(patterns, indent=2)}
        
        New task: {new_task['prompt']}
        """
        
        return enhanced_prompt
```

### 10.2. Self-Improvement Engine

```python
class SelfImprovementEngine:
    """
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ—à–ª—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤ –æ–±—É—á–∞—é—Ç –Ω–æ–≤—ã–µ —ç—Ç–∞–ø—ã
    """
    async def analyze_historical_performance(self):
        """
        –ê–Ω–∞–ª–∏–∑ performance –≤—Å–µ—Ö –ø—Ä–æ—à–ª—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
        """
        all_strategies = await knowledge_base.get_all_strategies()
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ success/failure
        successful = [s for s in all_strategies if s['backtest_score'] > 0.7]
        failed = [s for s in all_strategies if s['backtest_score'] < 0.3]
        
        # –ò–∑–≤–ª–µ—á—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        success_patterns = extract_patterns(successful)
        failure_patterns = extract_patterns(failed)
        
        return {
            "success_patterns": success_patterns,
            "failure_patterns": failure_patterns,
            "recommendations": generate_recommendations(success_patterns, failure_patterns)
        }
    
    async def evolve_reasoning_prompt(self, base_prompt):
        """
        –≠–≤–æ–ª—é—Ü–∏—è reasoning prompt –Ω–∞ –æ—Å–Ω–æ–≤–µ historical data
        """
        historical_analysis = await self.analyze_historical_performance()
        
        evolved_prompt = f"""
        {base_prompt}
        
        [CONTEXT FROM PAST EXPERIMENTS]
        Successful patterns:
        {historical_analysis['success_patterns']}
        
        Patterns to avoid:
        {historical_analysis['failure_patterns']}
        
        Recommendations:
        {historical_analysis['recommendations']}
        """
        
        return evolved_prompt
```

---

## 11. Roadmap —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

### –≠—Ç–∞–ø I: MVP (8-12 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å**: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ –∂–∏–∑–Ω–µ—Å–ø–æ—Å–æ–±–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
- ‚úÖ FastAPI —Å–µ—Ä–≤–µ—Ä —Å JSON-RPC 2.0
- ‚úÖ Redis Streams + Consumer Groups –¥–ª—è –æ—á–µ—Ä–µ–¥–µ–π
- ‚úÖ –ë–∞–∑–æ–≤—ã–π Reasoning Agent (Perplexity API)
- ‚úÖ –ë–∞–∑–æ–≤—ã–π CodeGen Agent (DeepSeek API)
- ‚úÖ Docker sandbox (basic isolation)
- ‚úÖ Prometheus + Grafana –¥–ª—è –º–µ—Ç—Ä–∏–∫
- ‚úÖ –ë–∞–∑–æ–≤–∞—è WebUI (Streamlit)
- ‚úÖ XPENDING recovery –¥–ª—è –∑–∞—Å—Ç—Ä—è–≤—à–∏—Ö –∑–∞–¥–∞—á

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**
- SLA > 95%
- Recovery time < 60s
- –ë–∞–∑–æ–≤—ã–π reasoning ‚Üí codegen ‚Üí sandbox pipeline —Ä–∞–±–æ—Ç–∞–µ—Ç

### –≠—Ç–∞–ø II: Signal Routing, Orchestrator, Security (12-16 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å**: Production-ready orchestrator

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
- ‚úÖ Signal Routing Layer —Å real-time Preemption
- ‚úÖ Full Saga Orchestration (SagaFSM)
- ‚úÖ Multi-layer sandbox (gVisor, Firecracker)
- ‚úÖ OpenTelemetry distributed tracing
- ‚úÖ ML-–∞–≥–µ–Ω—Ç—ã (AutoML, GridSearchCV)
- ‚úÖ Trader Psychology Agent
- ‚úÖ Guardian Agents (–≤–∞–ª–∏–¥–∞—Ü–∏—è)
- ‚úÖ Enhanced WebUI (D3.js, Plotly graphs)
- ‚úÖ VS Code Extension
- ‚úÖ Telegram Bot

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**
- SLA > 99%
- Recovery time < 30s
- Sandbox escape rate = 0
- Full audit trail –¥–ª—è –≤—Å–µ—Ö reasoning/codegen

### –≠—Ç–∞–ø III: –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –∑—Ä–µ–ª–æ—Å—Ç—å (16-20 –Ω–µ–¥–µ–ª—å)

**–¶–µ–ª—å**: Enterprise-grade —Å–∏—Å—Ç–µ–º–∞

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
- ‚úÖ Multi-tenancy pools —Å resource isolation
- ‚úÖ Policy Engine (per-user/per-tool permissions)
- ‚úÖ SIEM integration (security monitoring)
- ‚úÖ Federation (federated MCP-—Å–µ—Ä–≤–µ—Ä—ã)
- ‚úÖ Disaster recovery automation
- ‚úÖ Knowledge Base —Å self-improvement engine
- ‚úÖ Tournament pipeline (batch competitions)
- ‚úÖ Advanced security (threat modeling, penetration testing)

**–ö—Ä–∏—Ç–µ—Ä–∏–∏ —É—Å–ø–µ—Ö–∞:**
- SLA > 99.9%
- Zero data loss
- Full compliance (SOC2, GDPR)
- Self-healing & auto-scaling –ø–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –Ω–∞–≥—Ä—É–∑–∫–æ–π

---

## 12. –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—Ö–∞

### 12.1. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏

```yaml
Performance:
  sla_uptime: ">99%"
  recovery_time: "<30s"
  reasoning_latency_p95: "<1000ms"
  codegen_latency_p95: "<2000ms"
  backtest_latency_p95: "<5000ms"
  queue_depth_max: "<100 tasks"
  worker_utilization: "70-90%"
  
Reliability:
  data_loss_rate: "0%"
  sandbox_escape_rate: "0%"
  compensation_success_rate: ">99%"
  automatic_recovery_rate: ">95%"
  
Quality:
  strategy_success_rate: ">60%"  # % profitable strategies
  code_quality_score: ">8/10"  # DeepSeek CodeGen
  reasoning_explainability: ">9/10"  # Perplexity Reasoning
  user_satisfaction: ">4.5/5"
```

### 12.2. –ë–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏

```yaml
Automation:
  strategies_without_manual_correction: ">40%"
  avg_time_hypothesis_to_deploy: "<24h"
  user_interventions_per_strategy: "<3"
  
Adaptability:
  market_phase_detection_accuracy: ">85%"
  trader_psychology_test_coverage: "100%"  # all profiles
  self_improvement_cycle_time: "<7 days"
  
Explainability:
  reasoning_chain_depth: ">5 steps"
  audit_trail_completeness: "100%"
  knowledge_base_reusability: ">70%"
```

---

## 13. –ü—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ (complete)

### 13.1. –ü–æ–ª–Ω—ã–π MCP Server (FastAPI)

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio

app = FastAPI(title="MCP Orchestrator", version="1.0")

class TaskRequest(BaseModel):
    jsonrpc: str = "2.0"
    method: str
    params: dict
    id: str

@app.post("/v1/run_task")
async def run_task(request: TaskRequest):
    """
    –ì–ª–∞–≤–Ω—ã–π endpoint –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∑–∞–¥–∞—á
    """
    if request.method == "run_task":
        task = request.params
        
        # Route to appropriate agent
        if task['tool'] == "Perplexity":
            result = await reasoning_agent.process(task)
        elif task['tool'] == "DeepSeek":
            result = await codegen_agent.process(task)
        else:
            raise HTTPException(400, "Unknown tool")
        
        return {
            "jsonrpc": "2.0",
            "result": result,
            "id": request.id
        }

@app.get("/v1/status")
async def get_status():
    """
    –°—Ç–∞—Ç—É—Å —Å–∏—Å—Ç–µ–º—ã
    """
    return {
        "queue_depth": await get_queue_depth(),
        "active_workers": len(worker_pool),
        "latency_p95": await get_latency_p95()
    }

@app.get("/v1/analytics")
async def get_analytics():
    """
    Live-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞
    """
    return {
        "throughput": await calculate_throughput(),
        "utilization": await calculate_utilization(),
        "success_rate": await calculate_success_rate()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### 13.2. –ü–æ–ª–Ω—ã–π Reasoning Agent (Perplexity)

```python
import httpx
from typing import Dict, Any

class PerplexityReasoningAgent:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.perplexity.ai/v1"
    
    async def process(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ reasoning –∑–∞–¥–∞—á–∏
        """
        async with httpx.AsyncClient(timeout=30.0) as client:
            # Bootstrap reasoning —Å knowledge base
            enhanced_prompt = await knowledge_base.bootstrap_reasoning(task)
            
            # Call Perplexity API
            response = await client.post(
                f"{self.base_url}/reasoning",
                json={
                    "prompt": enhanced_prompt,
                    "model": "sonar-pro",
                    "max_tokens": 2000
                },
                headers={"Authorization": f"Bearer {self.api_key}"}
            )
            
            result = response.json()
            
            # Store –≤ knowledge base
            trace_id = task.get('trace_id', generate_trace_id())
            await knowledge_base.store(trace_id, "reasoning", result)
            
            # Prometheus metrics
            REASONING_LATENCY.labels(
                agent="perplexity",
                priority=task.get('priority', 5)
            ).observe(response.elapsed.total_seconds())
            
            return {
                "trace_id": trace_id,
                "agent": "perplexity",
                "reasoning_chain": result['reasoning'],
                "generated_strategy": result['strategy'],
                "confidence": result['confidence']
            }
```

---

## 14. –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

–î–∞–Ω–Ω–æ–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –∑–∞–¥–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç **4 –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞** –≤ –µ–¥–∏–Ω—É—é —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω—É—é —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏—é:

### –ß—Ç–æ –≤–∫–ª—é—á–µ–Ω–æ:

1. **MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —á–∞—Å—Ç—å 1** (–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ü—Ä–æ—Ç–æ–∫–æ–ª—ã, –û—á–µ—Ä–µ–¥–∏):
   - ‚úÖ JSON-RPC 2.0, FastAPI, Redis Streams, Saga Orchestration
   
2. **MCP-–æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä —á–∞—Å—Ç—å 2** (Sandbox, Security, SLA, Monitoring):
   - ‚úÖ Multi-layer sandbox, Prometheus, OpenTelemetry, Multi-tenancy
   
3. **–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è —á–∞—Å—Ç—å 1** (–ú–æ–¥—É–ª–∏, Pipeline):
   - ‚úÖ Reasoning/CodeGen/ML agents, Trader Psychology, User-Control
   
4. **–ú—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–∞—è –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è —á–∞—Å—Ç—å 2** (–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è, –ø—Ä–∏–º–µ—Ä—ã):
   - ‚úÖ MVP pipeline, Knowledge Base, Self-improvement, Tournament

### –ö–ª—é—á–µ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è:

- ‚úÖ **–ü–æ–ª–Ω–æ—Ç–∞**: –≤—Å–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏–∑ 4 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —É—á—Ç–µ–Ω—ã
- ‚úÖ **–°–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å**: –Ω–µ—Ç –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏
- ‚úÖ **–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è**: —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤—Å–µ –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞, API, –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- ‚úÖ **–°—Ç—Ä—É–∫—Ç—É—Ä–∞**: –ª–æ–≥–∏—á–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ 14 —Ä–∞–∑–¥–µ–ª–æ–≤ —Å cross-references
- ‚úÖ **–ü—Ä–∞–∫—Ç–∏—á–Ω–æ—Å—Ç—å**: –≥–æ—Ç–æ–≤–æ –∫ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏

### Production Readiness:

**Current Status**: 8/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Blockers to 10/10:**
- Saga Orchestration —Ç–µ—Å—Ç—ã (Phase 3)
- Chaos/resilience scenarios

**Recommended Next Steps:**
1. Execute Phase 2.3.5 Extended Integration Test (20-30 min)
2. Add Saga Orchestration tests (4-6 hours)
3. Implement chaos/resilience scenarios (6-8 hours)
4. Production deployment (follow roadmap –≠—Ç–∞–ø II ‚Üí –≠—Ç–∞–ø III)

---

**–î–æ–∫—É–º–µ–Ω—Ç –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏.**  
**–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã, –ø—Ä–∏–º–µ—Ä—ã –∫–æ–¥–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã, –º–µ—Ç—Ä–∏–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.**

**üéâ Unified Technical Specification COMPLETE** üéâ
